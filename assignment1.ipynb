{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtbz7W9YSfp/j8sg6kafrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blacksaturn1-wpi/Reinforcement-Learning-RBE-595-WPI/blob/assignment-1/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create graph of:\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "A5D37T1ipgeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between evaluative feedback and instructive information remains significant even if there are only two actions and two possible rewards. For these binary bandit tasks, let us call the two rewards success and failure. If you received success, then you might reasonably infer that whatever action you selected was correct, and if you received failure, then you might infer that whatever action you did not select was correct. You could then keep a tally of how often each action was (inferred to be) correct and select the action that was correct most often.  often. Let us call this the supervised algorithm because it corresponds most closely to what a supervised learning method might do in the case of a single input pattern. If the rewards are deterministic, then the inferences of the supervised algorithm are all correct and it performs excellently. If the rewards are stochastic, then the picture is more complicated.\n",
        "\n",
        "\n",
        "Sutton, Richard S.; Barto, Andrew G.. Reinforcement Learning (Adaptive Computation and Machine Learning series) (Kindle Locations 790-797). MIT Press. Kindle Edition. "
      ],
      "metadata": {
        "id": "ASEL_JXqqVhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 2 main tests to graph Quadrant I and III.  Simulate 1000 runs and calculate the estimated value of the reward"
      ],
      "metadata": {
        "id": "I4aCEEzss77I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quadrant III Test:\n",
        "\n",
        "*   Action 1 succeeds with probability of .2\n",
        "*   Action 2 succeeds with probability of .1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fshg51oPu4Mi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "i8T0vbr5pbG1"
      },
      "outputs": [],
      "source": [
        "def running_average(current_reward,current_average,previous_step):\n",
        "  current_step=previous_step+1\n",
        "  new_average = current_average + 1.0/current_step*(current_reward-current_average)\n",
        "  return (new_average,current_step)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choices\n",
        "def testStochasticOutcomes():\n",
        "  population = [0, 1]\n",
        "  action1_weights = [0.8, 0.2]\n",
        "  action2_weights = [0.9, 0.1]\n",
        "  action1_reward=choices(population, action1_weights)\n",
        "  action2_reward=choices(population, action2_weights)\n",
        "  print(action1_reward[0])\n",
        "  print(action2_reward[0])"
      ],
      "metadata": {
        "id": "ad8BQuIR1i-s"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the stochastic case, a particular binary bandit task is defined by two numbers, the probabilities of success for each possible action. The space of all possible tasks is thus a unit square, as shown in Figure 2.2. The upper-left and lower-right quadrants correspond to relatively easy tasks for which the supervised algorithm would work well. For these, the probability of success for the better action is greater than 0.5 and the probability of success for the poorer action is less than 0.5. For these tasks, the action inferred to be correct (as described above) will actually be the correct action more than half the time. \n",
        "However, binary bandit tasks in the other two quadrants of Figure 2.2 are more difficult and cannot be solved effectively by the supervised algorithm. For example, consider a task with success probabilities 0.1 and 0.2, corresponding to point A in the lower-left difficult quadrant of Figure 2.2. Because both actions produce failure at least 80% of the time, any method that takes failure as an indication that the other action was correct will oscillate between the two actions, never settling on the better one.\n",
        "\n",
        "Sutton, Richard S.; Barto, Andrew G.. Reinforcement Learning (Adaptive Computation and Machine Learning series) (Kindle Locations 797-808). MIT Press. Kindle Edition. "
      ],
      "metadata": {
        "id": "FEOHkGH33jRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimateActionValues(r1,r2,q1,q2,n1,n2):\n",
        "  q1,n1=running_average(r1,q1,n1)\n",
        "  print(\"action1_reward: {0}, action1_reward_avg: {1}, action1_reward_count: {2}\".format(r1,q1,n1))\n",
        "  q2,n2=running_average(r2,q2,n2)\n",
        "  print(\"action2_reward: {0}, action2_reward_avg: {1}, action2_reward_count: {2}\".format(r2,q2,n2))\n",
        "  return q1,q2,n1,n2"
      ],
      "metadata": {
        "id": "scAuoXSxQorg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryBanditSimulation(action1_weights,action2_weights,population,iterations):\n",
        "  actionChoice=1 # we start by choosing action 1\n",
        "  action1_reward_avg=0\n",
        "  action1_reward_count=0\n",
        "  action2_reward_avg=0\n",
        "  action2_reward_count=0\n",
        "\n",
        "  # Seed\n",
        "  action1_reward=choices(population, action1_weights)\n",
        "  action1_reward_avg,action1_reward_count=running_average(action1_reward[0],action1_reward_avg,action1_reward_count)\n",
        "  print(\"SEED: action1_reward: {0}, action1_reward_avg: {1}, action1_reward_count: {2}\".format(action1_reward[0],action1_reward_avg,action1_reward_count))\n",
        "\n",
        "  for x in range(iterations):\n",
        "    # At each step we choose the action with the highest action_reward_avg\n",
        "    # Since the action is stochastic, we use its probability to determine if it was successfull or not\n",
        "    # If it was successfull, we assume the other action would not be and vice versa\n",
        "    # We then update the action_reward_avg for both actions using the calculated reward of the chosen action and the implied reward of other action\n",
        "    # repeat cycle\n",
        "    print(\"Iteration {}\".format(x+1))\n",
        "    if action1_reward_avg >= action2_reward_avg:\n",
        "      print(\"Chose Action 1: {} >= {}\".format(action1_reward_avg,action2_reward_avg))\n",
        "      action1_reward=choices(population, action1_weights)\n",
        "      if(action1_reward==1):\n",
        "        action1_reward_avg,action1_reward_avg,action2_reward_count,action2_reward_count=estimateActionValues(1,0,action1_reward_avg,action2_reward_avg,\n",
        "                                                                                                            action2_reward_count,action2_reward_count)\n",
        "      else:\n",
        "        action1_reward_avg,action2_reward_avg,action2_reward_count,action2_reward_count=estimateActionValues(0,1,action1_reward_avg,action2_reward_avg,\n",
        "                                                                                                            action2_reward_count,action2_reward_count)\n",
        "    else:\n",
        "      print(\"Chose Action 2: {} < {}\".format(action1_reward_avg,action2_reward_avg))\n",
        "      action2_reward=choices(population, action2_weights)\n",
        "      if(action2_reward==1):\n",
        "        action1_reward_avg,action2_reward_avg,action2_reward_count,action2_reward_count=estimateActionValues(0,1,action1_reward_avg,action2_reward_avg,\n",
        "                                                                                                            action2_reward_count,action2_reward_count)\n",
        "      else:\n",
        "        action1_reward_avg,action2_reward_avg,action2_reward_count,action2_reward_count=estimateActionValues(1,0,action1_reward_avg,action2_reward_avg,\n",
        "                                                                                                            action2_reward_count,action2_reward_count)\n",
        "    "
      ],
      "metadata": {
        "id": "bVrlA2jy2q5o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation of Lower Left Quadrant (Quadrant III)\n",
        "population = [0, 1]\n",
        "action1_weights = [0.8, 0.2]\n",
        "action2_weights = [0.9, 0.1]\n",
        "binaryBanditSimulation(action1_weights,action2_weights,population,2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDW_JtuFYTB6",
        "outputId": "b45ffcad-3f35-4460-f041-ca5427b3d848"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 751\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993342210386152, action1_reward_count: 751\n",
            "action2_reward: 1, action2_reward_avg: 0.5006657789613849, action2_reward_count: 751\n",
            "Iteration 752\n",
            "Chose Action 2: 0.4993342210386152 < 0.5006657789613849\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 752\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 752\n",
            "Iteration 753\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933598937583, action1_reward_count: 753\n",
            "action2_reward: 1, action2_reward_avg: 0.50066401062417, action2_reward_count: 753\n",
            "Iteration 754\n",
            "Chose Action 2: 0.49933598937583 < 0.50066401062417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 754\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 754\n",
            "Iteration 755\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933774834437084, action1_reward_count: 755\n",
            "action2_reward: 1, action2_reward_avg: 0.5006622516556292, action2_reward_count: 755\n",
            "Iteration 756\n",
            "Chose Action 2: 0.49933774834437084 < 0.5006622516556292\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 756\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 756\n",
            "Iteration 757\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933949801849403, action1_reward_count: 757\n",
            "action2_reward: 1, action2_reward_avg: 0.5006605019815059, action2_reward_count: 757\n",
            "Iteration 758\n",
            "Chose Action 2: 0.49933949801849403 < 0.5006605019815059\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 758\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 758\n",
            "Iteration 759\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993412384716733, action1_reward_count: 759\n",
            "action2_reward: 1, action2_reward_avg: 0.5006587615283267, action2_reward_count: 759\n",
            "Iteration 760\n",
            "Chose Action 2: 0.4993412384716733 < 0.5006587615283267\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 760\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 760\n",
            "Iteration 761\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49934296977660975, action1_reward_count: 761\n",
            "action2_reward: 1, action2_reward_avg: 0.5006570302233903, action2_reward_count: 761\n",
            "Iteration 762\n",
            "Chose Action 2: 0.49934296977660975 < 0.5006570302233903\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 762\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 762\n",
            "Iteration 763\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934469200524245, action1_reward_count: 763\n",
            "action2_reward: 1, action2_reward_avg: 0.5006553079947575, action2_reward_count: 763\n",
            "Iteration 764\n",
            "Chose Action 2: 0.49934469200524245 < 0.5006553079947575\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 764\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 764\n",
            "Iteration 765\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993464052287582, action1_reward_count: 765\n",
            "action2_reward: 1, action2_reward_avg: 0.5006535947712418, action2_reward_count: 765\n",
            "Iteration 766\n",
            "Chose Action 2: 0.4993464052287582 < 0.5006535947712418\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 766\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 766\n",
            "Iteration 767\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934810951760106, action1_reward_count: 767\n",
            "action2_reward: 1, action2_reward_avg: 0.500651890482399, action2_reward_count: 767\n",
            "Iteration 768\n",
            "Chose Action 2: 0.49934810951760106 < 0.500651890482399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 768\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 768\n",
            "Iteration 769\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934980494148246, action1_reward_count: 769\n",
            "action2_reward: 1, action2_reward_avg: 0.5006501950585176, action2_reward_count: 769\n",
            "Iteration 770\n",
            "Chose Action 2: 0.49934980494148246 < 0.5006501950585176\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 770\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 770\n",
            "Iteration 771\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993514915693904, action1_reward_count: 771\n",
            "action2_reward: 1, action2_reward_avg: 0.5006485084306096, action2_reward_count: 771\n",
            "Iteration 772\n",
            "Chose Action 2: 0.4993514915693904 < 0.5006485084306096\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 772\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 772\n",
            "Iteration 773\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49935316946959896, action1_reward_count: 773\n",
            "action2_reward: 1, action2_reward_avg: 0.500646830530401, action2_reward_count: 773\n",
            "Iteration 774\n",
            "Chose Action 2: 0.49935316946959896 < 0.500646830530401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 774\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 774\n",
            "Iteration 775\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993548387096774, action1_reward_count: 775\n",
            "action2_reward: 1, action2_reward_avg: 0.5006451612903225, action2_reward_count: 775\n",
            "Iteration 776\n",
            "Chose Action 2: 0.4993548387096774 < 0.5006451612903225\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 776\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 776\n",
            "Iteration 777\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49935649935649934, action1_reward_count: 777\n",
            "action2_reward: 1, action2_reward_avg: 0.5006435006435006, action2_reward_count: 777\n",
            "Iteration 778\n",
            "Chose Action 2: 0.49935649935649934 < 0.5006435006435006\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 778\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 778\n",
            "Iteration 779\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993581514762516, action1_reward_count: 779\n",
            "action2_reward: 1, action2_reward_avg: 0.5006418485237484, action2_reward_count: 779\n",
            "Iteration 780\n",
            "Chose Action 2: 0.4993581514762516 < 0.5006418485237484\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 780\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 780\n",
            "Iteration 781\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499359795134443, action1_reward_count: 781\n",
            "action2_reward: 1, action2_reward_avg: 0.5006402048655569, action2_reward_count: 781\n",
            "Iteration 782\n",
            "Chose Action 2: 0.499359795134443 < 0.5006402048655569\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 782\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 782\n",
            "Iteration 783\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936143039591313, action1_reward_count: 783\n",
            "action2_reward: 1, action2_reward_avg: 0.5006385696040868, action2_reward_count: 783\n",
            "Iteration 784\n",
            "Chose Action 2: 0.49936143039591313 < 0.5006385696040868\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 784\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 784\n",
            "Iteration 785\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936305732484076, action1_reward_count: 785\n",
            "action2_reward: 1, action2_reward_avg: 0.5006369426751592, action2_reward_count: 785\n",
            "Iteration 786\n",
            "Chose Action 2: 0.49936305732484076 < 0.5006369426751592\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 786\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 786\n",
            "Iteration 787\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993646759847522, action1_reward_count: 787\n",
            "action2_reward: 1, action2_reward_avg: 0.5006353240152478, action2_reward_count: 787\n",
            "Iteration 788\n",
            "Chose Action 2: 0.4993646759847522 < 0.5006353240152478\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 788\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 788\n",
            "Iteration 789\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49936628643852976, action1_reward_count: 789\n",
            "action2_reward: 1, action2_reward_avg: 0.5006337135614702, action2_reward_count: 789\n",
            "Iteration 790\n",
            "Chose Action 2: 0.49936628643852976 < 0.5006337135614702\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 790\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 790\n",
            "Iteration 791\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993678887484197, action1_reward_count: 791\n",
            "action2_reward: 1, action2_reward_avg: 0.5006321112515802, action2_reward_count: 791\n",
            "Iteration 792\n",
            "Chose Action 2: 0.4993678887484197 < 0.5006321112515802\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 792\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 792\n",
            "Iteration 793\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936948297604034, action1_reward_count: 793\n",
            "action2_reward: 1, action2_reward_avg: 0.5006305170239596, action2_reward_count: 793\n",
            "Iteration 794\n",
            "Chose Action 2: 0.49936948297604034 < 0.5006305170239596\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 794\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 794\n",
            "Iteration 795\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937106918238994, action1_reward_count: 795\n",
            "action2_reward: 1, action2_reward_avg: 0.50062893081761, action2_reward_count: 795\n",
            "Iteration 796\n",
            "Chose Action 2: 0.49937106918238994 < 0.50062893081761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 796\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 796\n",
            "Iteration 797\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993726474278545, action1_reward_count: 797\n",
            "action2_reward: 1, action2_reward_avg: 0.5006273525721454, action2_reward_count: 797\n",
            "Iteration 798\n",
            "Chose Action 2: 0.4993726474278545 < 0.5006273525721454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 798\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 798\n",
            "Iteration 799\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937421777221525, action1_reward_count: 799\n",
            "action2_reward: 1, action2_reward_avg: 0.5006257822277846, action2_reward_count: 799\n",
            "Iteration 800\n",
            "Chose Action 2: 0.49937421777221525 < 0.5006257822277846\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 800\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 800\n",
            "Iteration 801\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993757802746567, action1_reward_count: 801\n",
            "action2_reward: 1, action2_reward_avg: 0.5006242197253432, action2_reward_count: 801\n",
            "Iteration 802\n",
            "Chose Action 2: 0.4993757802746567 < 0.5006242197253432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 802\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 802\n",
            "Iteration 803\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937733499377335, action1_reward_count: 803\n",
            "action2_reward: 1, action2_reward_avg: 0.5006226650062265, action2_reward_count: 803\n",
            "Iteration 804\n",
            "Chose Action 2: 0.49937733499377335 < 0.5006226650062265\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 804\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 804\n",
            "Iteration 805\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993788819875776, action1_reward_count: 805\n",
            "action2_reward: 1, action2_reward_avg: 0.5006211180124223, action2_reward_count: 805\n",
            "Iteration 806\n",
            "Chose Action 2: 0.4993788819875776 < 0.5006211180124223\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 806\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 806\n",
            "Iteration 807\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993804213135068, action1_reward_count: 807\n",
            "action2_reward: 1, action2_reward_avg: 0.5006195786864931, action2_reward_count: 807\n",
            "Iteration 808\n",
            "Chose Action 2: 0.4993804213135068 < 0.5006195786864931\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 808\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 808\n",
            "Iteration 809\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49938195302843014, action1_reward_count: 809\n",
            "action2_reward: 1, action2_reward_avg: 0.5006180469715698, action2_reward_count: 809\n",
            "Iteration 810\n",
            "Chose Action 2: 0.49938195302843014 < 0.5006180469715698\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 810\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 810\n",
            "Iteration 811\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499383477188656, action1_reward_count: 811\n",
            "action2_reward: 1, action2_reward_avg: 0.500616522811344, action2_reward_count: 811\n",
            "Iteration 812\n",
            "Chose Action 2: 0.499383477188656 < 0.500616522811344\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 812\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 812\n",
            "Iteration 813\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993849938499385, action1_reward_count: 813\n",
            "action2_reward: 1, action2_reward_avg: 0.5006150061500615, action2_reward_count: 813\n",
            "Iteration 814\n",
            "Chose Action 2: 0.4993849938499385 < 0.5006150061500615\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 814\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 814\n",
            "Iteration 815\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49938650306748467, action1_reward_count: 815\n",
            "action2_reward: 1, action2_reward_avg: 0.5006134969325153, action2_reward_count: 815\n",
            "Iteration 816\n",
            "Chose Action 2: 0.49938650306748467 < 0.5006134969325153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 816\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 816\n",
            "Iteration 817\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49938800489596086, action1_reward_count: 817\n",
            "action2_reward: 1, action2_reward_avg: 0.5006119951040392, action2_reward_count: 817\n",
            "Iteration 818\n",
            "Chose Action 2: 0.49938800489596086 < 0.5006119951040392\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 818\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 818\n",
            "Iteration 819\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993894993894994, action1_reward_count: 819\n",
            "action2_reward: 1, action2_reward_avg: 0.5006105006105006, action2_reward_count: 819\n",
            "Iteration 820\n",
            "Chose Action 2: 0.4993894993894994 < 0.5006105006105006\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 820\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 820\n",
            "Iteration 821\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993909866017052, action1_reward_count: 821\n",
            "action2_reward: 1, action2_reward_avg: 0.5006090133982948, action2_reward_count: 821\n",
            "Iteration 822\n",
            "Chose Action 2: 0.4993909866017052 < 0.5006090133982948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 822\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 822\n",
            "Iteration 823\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993924665856622, action1_reward_count: 823\n",
            "action2_reward: 1, action2_reward_avg: 0.5006075334143378, action2_reward_count: 823\n",
            "Iteration 824\n",
            "Chose Action 2: 0.4993924665856622 < 0.5006075334143378\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 824\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 824\n",
            "Iteration 825\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993939393939394, action1_reward_count: 825\n",
            "action2_reward: 1, action2_reward_avg: 0.5006060606060606, action2_reward_count: 825\n",
            "Iteration 826\n",
            "Chose Action 2: 0.4993939393939394 < 0.5006060606060606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 826\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 826\n",
            "Iteration 827\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939540507859737, action1_reward_count: 827\n",
            "action2_reward: 1, action2_reward_avg: 0.5006045949214026, action2_reward_count: 827\n",
            "Iteration 828\n",
            "Chose Action 2: 0.49939540507859737 < 0.5006045949214026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 828\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 828\n",
            "Iteration 829\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939686369119424, action1_reward_count: 829\n",
            "action2_reward: 1, action2_reward_avg: 0.5006031363088058, action2_reward_count: 829\n",
            "Iteration 830\n",
            "Chose Action 2: 0.49939686369119424 < 0.5006031363088058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 830\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 830\n",
            "Iteration 831\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993983152827918, action1_reward_count: 831\n",
            "action2_reward: 1, action2_reward_avg: 0.5006016847172082, action2_reward_count: 831\n",
            "Iteration 832\n",
            "Chose Action 2: 0.4993983152827918 < 0.5006016847172082\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 832\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 832\n",
            "Iteration 833\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939975990396157, action1_reward_count: 833\n",
            "action2_reward: 1, action2_reward_avg: 0.5006002400960384, action2_reward_count: 833\n",
            "Iteration 834\n",
            "Chose Action 2: 0.49939975990396157 < 0.5006002400960384\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 834\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 834\n",
            "Iteration 835\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994011976047904, action1_reward_count: 835\n",
            "action2_reward: 1, action2_reward_avg: 0.5005988023952096, action2_reward_count: 835\n",
            "Iteration 836\n",
            "Chose Action 2: 0.4994011976047904 < 0.5005988023952096\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 836\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 836\n",
            "Iteration 837\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994026284348865, action1_reward_count: 837\n",
            "action2_reward: 1, action2_reward_avg: 0.5005973715651135, action2_reward_count: 837\n",
            "Iteration 838\n",
            "Chose Action 2: 0.4994026284348865 < 0.5005973715651135\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 838\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 838\n",
            "Iteration 839\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499404052443385, action1_reward_count: 839\n",
            "action2_reward: 1, action2_reward_avg: 0.5005959475566151, action2_reward_count: 839\n",
            "Iteration 840\n",
            "Chose Action 2: 0.499404052443385 < 0.5005959475566151\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 840\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 840\n",
            "Iteration 841\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994054696789536, action1_reward_count: 841\n",
            "action2_reward: 1, action2_reward_avg: 0.5005945303210464, action2_reward_count: 841\n",
            "Iteration 842\n",
            "Chose Action 2: 0.4994054696789536 < 0.5005945303210464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 842\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 842\n",
            "Iteration 843\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940688018979834, action1_reward_count: 843\n",
            "action2_reward: 1, action2_reward_avg: 0.5005931198102017, action2_reward_count: 843\n",
            "Iteration 844\n",
            "Chose Action 2: 0.49940688018979834 < 0.5005931198102017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 844\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 844\n",
            "Iteration 845\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940828402366866, action1_reward_count: 845\n",
            "action2_reward: 1, action2_reward_avg: 0.5005917159763313, action2_reward_count: 845\n",
            "Iteration 846\n",
            "Chose Action 2: 0.49940828402366866 < 0.5005917159763313\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 846\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 846\n",
            "Iteration 847\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940968122786306, action1_reward_count: 847\n",
            "action2_reward: 1, action2_reward_avg: 0.500590318772137, action2_reward_count: 847\n",
            "Iteration 848\n",
            "Chose Action 2: 0.49940968122786306 < 0.500590318772137\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 848\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 848\n",
            "Iteration 849\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994110718492344, action1_reward_count: 849\n",
            "action2_reward: 1, action2_reward_avg: 0.5005889281507656, action2_reward_count: 849\n",
            "Iteration 850\n",
            "Chose Action 2: 0.4994110718492344 < 0.5005889281507656\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 850\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 850\n",
            "Iteration 851\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994124559341951, action1_reward_count: 851\n",
            "action2_reward: 1, action2_reward_avg: 0.500587544065805, action2_reward_count: 851\n",
            "Iteration 852\n",
            "Chose Action 2: 0.4994124559341951 < 0.500587544065805\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 852\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 852\n",
            "Iteration 853\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49941383352872215, action1_reward_count: 853\n",
            "action2_reward: 1, action2_reward_avg: 0.5005861664712778, action2_reward_count: 853\n",
            "Iteration 854\n",
            "Chose Action 2: 0.49941383352872215 < 0.5005861664712778\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 854\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 854\n",
            "Iteration 855\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994152046783626, action1_reward_count: 855\n",
            "action2_reward: 1, action2_reward_avg: 0.5005847953216375, action2_reward_count: 855\n",
            "Iteration 856\n",
            "Chose Action 2: 0.4994152046783626 < 0.5005847953216375\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 856\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 856\n",
            "Iteration 857\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49941656942823803, action1_reward_count: 857\n",
            "action2_reward: 1, action2_reward_avg: 0.5005834305717619, action2_reward_count: 857\n",
            "Iteration 858\n",
            "Chose Action 2: 0.49941656942823803 < 0.5005834305717619\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 858\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 858\n",
            "Iteration 859\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49941792782305006, action1_reward_count: 859\n",
            "action2_reward: 1, action2_reward_avg: 0.5005820721769498, action2_reward_count: 859\n",
            "Iteration 860\n",
            "Chose Action 2: 0.49941792782305006 < 0.5005820721769498\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 860\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 860\n",
            "Iteration 861\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994192799070848, action1_reward_count: 861\n",
            "action2_reward: 1, action2_reward_avg: 0.5005807200929151, action2_reward_count: 861\n",
            "Iteration 862\n",
            "Chose Action 2: 0.4994192799070848 < 0.5005807200929151\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 862\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 862\n",
            "Iteration 863\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942062572421786, action1_reward_count: 863\n",
            "action2_reward: 1, action2_reward_avg: 0.500579374275782, action2_reward_count: 863\n",
            "Iteration 864\n",
            "Chose Action 2: 0.49942062572421786 < 0.500579374275782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 864\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 864\n",
            "Iteration 865\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942196531791905, action1_reward_count: 865\n",
            "action2_reward: 1, action2_reward_avg: 0.5005780346820808, action2_reward_count: 865\n",
            "Iteration 866\n",
            "Chose Action 2: 0.49942196531791905 < 0.5005780346820808\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 866\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 866\n",
            "Iteration 867\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994232987312572, action1_reward_count: 867\n",
            "action2_reward: 1, action2_reward_avg: 0.5005767012687427, action2_reward_count: 867\n",
            "Iteration 868\n",
            "Chose Action 2: 0.4994232987312572 < 0.5005767012687427\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 868\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 868\n",
            "Iteration 869\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994246260069045, action1_reward_count: 869\n",
            "action2_reward: 1, action2_reward_avg: 0.5005753739930954, action2_reward_count: 869\n",
            "Iteration 870\n",
            "Chose Action 2: 0.4994246260069045 < 0.5005753739930954\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 870\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 870\n",
            "Iteration 871\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942594718714123, action1_reward_count: 871\n",
            "action2_reward: 1, action2_reward_avg: 0.5005740528128587, action2_reward_count: 871\n",
            "Iteration 872\n",
            "Chose Action 2: 0.49942594718714123 < 0.5005740528128587\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 872\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 872\n",
            "Iteration 873\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49942726231386025, action1_reward_count: 873\n",
            "action2_reward: 1, action2_reward_avg: 0.5005727376861397, action2_reward_count: 873\n",
            "Iteration 874\n",
            "Chose Action 2: 0.49942726231386025 < 0.5005727376861397\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 874\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 874\n",
            "Iteration 875\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49942857142857144, action1_reward_count: 875\n",
            "action2_reward: 1, action2_reward_avg: 0.5005714285714286, action2_reward_count: 875\n",
            "Iteration 876\n",
            "Chose Action 2: 0.49942857142857144 < 0.5005714285714286\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 876\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 876\n",
            "Iteration 877\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49942987457240595, action1_reward_count: 877\n",
            "action2_reward: 1, action2_reward_avg: 0.500570125427594, action2_reward_count: 877\n",
            "Iteration 878\n",
            "Chose Action 2: 0.49942987457240595 < 0.500570125427594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 878\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 878\n",
            "Iteration 879\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49943117178612056, action1_reward_count: 879\n",
            "action2_reward: 1, action2_reward_avg: 0.5005688282138794, action2_reward_count: 879\n",
            "Iteration 880\n",
            "Chose Action 2: 0.49943117178612056 < 0.5005688282138794\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 880\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 880\n",
            "Iteration 881\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49943246311010214, action1_reward_count: 881\n",
            "action2_reward: 1, action2_reward_avg: 0.5005675368898977, action2_reward_count: 881\n",
            "Iteration 882\n",
            "Chose Action 2: 0.49943246311010214 < 0.5005675368898977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 882\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 882\n",
            "Iteration 883\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49943374858437145, action1_reward_count: 883\n",
            "action2_reward: 1, action2_reward_avg: 0.5005662514156284, action2_reward_count: 883\n",
            "Iteration 884\n",
            "Chose Action 2: 0.49943374858437145 < 0.5005662514156284\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 884\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 884\n",
            "Iteration 885\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994350282485876, action1_reward_count: 885\n",
            "action2_reward: 1, action2_reward_avg: 0.5005649717514122, action2_reward_count: 885\n",
            "Iteration 886\n",
            "Chose Action 2: 0.4994350282485876 < 0.5005649717514122\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 886\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 886\n",
            "Iteration 887\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49943630214205187, action1_reward_count: 887\n",
            "action2_reward: 1, action2_reward_avg: 0.500563697857948, action2_reward_count: 887\n",
            "Iteration 888\n",
            "Chose Action 2: 0.49943630214205187 < 0.500563697857948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 888\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 888\n",
            "Iteration 889\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49943757030371205, action1_reward_count: 889\n",
            "action2_reward: 1, action2_reward_avg: 0.5005624296962878, action2_reward_count: 889\n",
            "Iteration 890\n",
            "Chose Action 2: 0.49943757030371205 < 0.5005624296962878\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 890\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 890\n",
            "Iteration 891\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994388327721661, action1_reward_count: 891\n",
            "action2_reward: 1, action2_reward_avg: 0.5005611672278338, action2_reward_count: 891\n",
            "Iteration 892\n",
            "Chose Action 2: 0.4994388327721661 < 0.5005611672278338\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 892\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 892\n",
            "Iteration 893\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49944008958566627, action1_reward_count: 893\n",
            "action2_reward: 1, action2_reward_avg: 0.5005599104143337, action2_reward_count: 893\n",
            "Iteration 894\n",
            "Chose Action 2: 0.49944008958566627 < 0.5005599104143337\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 894\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 894\n",
            "Iteration 895\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994413407821229, action1_reward_count: 895\n",
            "action2_reward: 1, action2_reward_avg: 0.500558659217877, action2_reward_count: 895\n",
            "Iteration 896\n",
            "Chose Action 2: 0.4994413407821229 < 0.500558659217877\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 896\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 896\n",
            "Iteration 897\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49944258639910816, action1_reward_count: 897\n",
            "action2_reward: 1, action2_reward_avg: 0.5005574136008918, action2_reward_count: 897\n",
            "Iteration 898\n",
            "Chose Action 2: 0.49944258639910816 < 0.5005574136008918\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 898\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 898\n",
            "Iteration 899\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994438264738598, action1_reward_count: 899\n",
            "action2_reward: 1, action2_reward_avg: 0.5005561735261401, action2_reward_count: 899\n",
            "Iteration 900\n",
            "Chose Action 2: 0.4994438264738598 < 0.5005561735261401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 900\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 900\n",
            "Iteration 901\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49944506104328523, action1_reward_count: 901\n",
            "action2_reward: 1, action2_reward_avg: 0.5005549389567147, action2_reward_count: 901\n",
            "Iteration 902\n",
            "Chose Action 2: 0.49944506104328523 < 0.5005549389567147\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 902\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 902\n",
            "Iteration 903\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994462901439646, action1_reward_count: 903\n",
            "action2_reward: 1, action2_reward_avg: 0.5005537098560353, action2_reward_count: 903\n",
            "Iteration 904\n",
            "Chose Action 2: 0.4994462901439646 < 0.5005537098560353\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 904\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 904\n",
            "Iteration 905\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994475138121547, action1_reward_count: 905\n",
            "action2_reward: 1, action2_reward_avg: 0.5005524861878452, action2_reward_count: 905\n",
            "Iteration 906\n",
            "Chose Action 2: 0.4994475138121547 < 0.5005524861878452\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 906\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 906\n",
            "Iteration 907\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994487320837927, action1_reward_count: 907\n",
            "action2_reward: 1, action2_reward_avg: 0.5005512679162072, action2_reward_count: 907\n",
            "Iteration 908\n",
            "Chose Action 2: 0.4994487320837927 < 0.5005512679162072\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 908\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 908\n",
            "Iteration 909\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49944994499449946, action1_reward_count: 909\n",
            "action2_reward: 1, action2_reward_avg: 0.5005500550055004, action2_reward_count: 909\n",
            "Iteration 910\n",
            "Chose Action 2: 0.49944994499449946 < 0.5005500550055004\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 910\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 910\n",
            "Iteration 911\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994511525795829, action1_reward_count: 911\n",
            "action2_reward: 1, action2_reward_avg: 0.500548847420417, action2_reward_count: 911\n",
            "Iteration 912\n",
            "Chose Action 2: 0.4994511525795829 < 0.500548847420417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 912\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 912\n",
            "Iteration 913\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994523548740416, action1_reward_count: 913\n",
            "action2_reward: 1, action2_reward_avg: 0.5005476451259583, action2_reward_count: 913\n",
            "Iteration 914\n",
            "Chose Action 2: 0.4994523548740416 < 0.5005476451259583\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 914\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 914\n",
            "Iteration 915\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994535519125683, action1_reward_count: 915\n",
            "action2_reward: 1, action2_reward_avg: 0.5005464480874315, action2_reward_count: 915\n",
            "Iteration 916\n",
            "Chose Action 2: 0.4994535519125683 < 0.5005464480874315\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 916\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 916\n",
            "Iteration 917\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994547437295529, action1_reward_count: 917\n",
            "action2_reward: 1, action2_reward_avg: 0.500545256270447, action2_reward_count: 917\n",
            "Iteration 918\n",
            "Chose Action 2: 0.4994547437295529 < 0.500545256270447\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 918\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 918\n",
            "Iteration 919\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499455930359086, action1_reward_count: 919\n",
            "action2_reward: 1, action2_reward_avg: 0.5005440696409139, action2_reward_count: 919\n",
            "Iteration 920\n",
            "Chose Action 2: 0.499455930359086 < 0.5005440696409139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 920\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 920\n",
            "Iteration 921\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499457111834962, action1_reward_count: 921\n",
            "action2_reward: 1, action2_reward_avg: 0.5005428881650379, action2_reward_count: 921\n",
            "Iteration 922\n",
            "Chose Action 2: 0.499457111834962 < 0.5005428881650379\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 922\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 922\n",
            "Iteration 923\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49945828819068255, action1_reward_count: 923\n",
            "action2_reward: 1, action2_reward_avg: 0.5005417118093173, action2_reward_count: 923\n",
            "Iteration 924\n",
            "Chose Action 2: 0.49945828819068255 < 0.5005417118093173\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 924\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 924\n",
            "Iteration 925\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49945945945945946, action1_reward_count: 925\n",
            "action2_reward: 1, action2_reward_avg: 0.5005405405405404, action2_reward_count: 925\n",
            "Iteration 926\n",
            "Chose Action 2: 0.49945945945945946 < 0.5005405405405404\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 926\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 926\n",
            "Iteration 927\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994606256742179, action1_reward_count: 927\n",
            "action2_reward: 1, action2_reward_avg: 0.500539374325782, action2_reward_count: 927\n",
            "Iteration 928\n",
            "Chose Action 2: 0.4994606256742179 < 0.500539374325782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 928\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 928\n",
            "Iteration 929\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49946178686759957, action1_reward_count: 929\n",
            "action2_reward: 1, action2_reward_avg: 0.5005382131324003, action2_reward_count: 929\n",
            "Iteration 930\n",
            "Chose Action 2: 0.49946178686759957 < 0.5005382131324003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 930\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 930\n",
            "Iteration 931\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49946294307196565, action1_reward_count: 931\n",
            "action2_reward: 1, action2_reward_avg: 0.5005370569280343, action2_reward_count: 931\n",
            "Iteration 932\n",
            "Chose Action 2: 0.49946294307196565 < 0.5005370569280343\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 932\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 932\n",
            "Iteration 933\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994640943193998, action1_reward_count: 933\n",
            "action2_reward: 1, action2_reward_avg: 0.5005359056806001, action2_reward_count: 933\n",
            "Iteration 934\n",
            "Chose Action 2: 0.4994640943193998 < 0.5005359056806001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 934\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 934\n",
            "Iteration 935\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994652406417112, action1_reward_count: 935\n",
            "action2_reward: 1, action2_reward_avg: 0.5005347593582887, action2_reward_count: 935\n",
            "Iteration 936\n",
            "Chose Action 2: 0.4994652406417112 < 0.5005347593582887\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 936\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 936\n",
            "Iteration 937\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994663820704376, action1_reward_count: 937\n",
            "action2_reward: 1, action2_reward_avg: 0.5005336179295624, action2_reward_count: 937\n",
            "Iteration 938\n",
            "Chose Action 2: 0.4994663820704376 < 0.5005336179295624\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 938\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 938\n",
            "Iteration 939\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994675186368477, action1_reward_count: 939\n",
            "action2_reward: 1, action2_reward_avg: 0.5005324813631523, action2_reward_count: 939\n",
            "Iteration 940\n",
            "Chose Action 2: 0.4994675186368477 < 0.5005324813631523\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 940\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 940\n",
            "Iteration 941\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49946865037194477, action1_reward_count: 941\n",
            "action2_reward: 1, action2_reward_avg: 0.5005313496280552, action2_reward_count: 941\n",
            "Iteration 942\n",
            "Chose Action 2: 0.49946865037194477 < 0.5005313496280552\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 942\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 942\n",
            "Iteration 943\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49946977730646874, action1_reward_count: 943\n",
            "action2_reward: 1, action2_reward_avg: 0.5005302226935313, action2_reward_count: 943\n",
            "Iteration 944\n",
            "Chose Action 2: 0.49946977730646874 < 0.5005302226935313\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 944\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 944\n",
            "Iteration 945\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947089947089945, action1_reward_count: 945\n",
            "action2_reward: 1, action2_reward_avg: 0.5005291005291005, action2_reward_count: 945\n",
            "Iteration 946\n",
            "Chose Action 2: 0.49947089947089945 < 0.5005291005291005\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 946\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 946\n",
            "Iteration 947\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49947201689545934, action1_reward_count: 947\n",
            "action2_reward: 1, action2_reward_avg: 0.5005279831045406, action2_reward_count: 947\n",
            "Iteration 948\n",
            "Chose Action 2: 0.49947201689545934 < 0.5005279831045406\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 948\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 948\n",
            "Iteration 949\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994731296101159, action1_reward_count: 949\n",
            "action2_reward: 1, action2_reward_avg: 0.5005268703898841, action2_reward_count: 949\n",
            "Iteration 950\n",
            "Chose Action 2: 0.4994731296101159 < 0.5005268703898841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 950\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 950\n",
            "Iteration 951\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947423764458465, action1_reward_count: 951\n",
            "action2_reward: 1, action2_reward_avg: 0.5005257623554153, action2_reward_count: 951\n",
            "Iteration 952\n",
            "Chose Action 2: 0.49947423764458465 < 0.5005257623554153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 952\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 952\n",
            "Iteration 953\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994753410283316, action1_reward_count: 953\n",
            "action2_reward: 1, action2_reward_avg: 0.5005246589716684, action2_reward_count: 953\n",
            "Iteration 954\n",
            "Chose Action 2: 0.4994753410283316 < 0.5005246589716684\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 954\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 954\n",
            "Iteration 955\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947643979057593, action1_reward_count: 955\n",
            "action2_reward: 1, action2_reward_avg: 0.5005235602094241, action2_reward_count: 955\n",
            "Iteration 956\n",
            "Chose Action 2: 0.49947643979057593 < 0.5005235602094241\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 956\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 956\n",
            "Iteration 957\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994775339602926, action1_reward_count: 957\n",
            "action2_reward: 1, action2_reward_avg: 0.5005224660397074, action2_reward_count: 957\n",
            "Iteration 958\n",
            "Chose Action 2: 0.4994775339602926 < 0.5005224660397074\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 958\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 958\n",
            "Iteration 959\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994786235662148, action1_reward_count: 959\n",
            "action2_reward: 1, action2_reward_avg: 0.5005213764337852, action2_reward_count: 959\n",
            "Iteration 960\n",
            "Chose Action 2: 0.4994786235662148 < 0.5005213764337852\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 960\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 960\n",
            "Iteration 961\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994797086368366, action1_reward_count: 961\n",
            "action2_reward: 1, action2_reward_avg: 0.5005202913631633, action2_reward_count: 961\n",
            "Iteration 962\n",
            "Chose Action 2: 0.4994797086368366 < 0.5005202913631633\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 962\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 962\n",
            "Iteration 963\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994807892004154, action1_reward_count: 963\n",
            "action2_reward: 1, action2_reward_avg: 0.5005192107995846, action2_reward_count: 963\n",
            "Iteration 964\n",
            "Chose Action 2: 0.4994807892004154 < 0.5005192107995846\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 964\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 964\n",
            "Iteration 965\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948186528497407, action1_reward_count: 965\n",
            "action2_reward: 1, action2_reward_avg: 0.5005181347150259, action2_reward_count: 965\n",
            "Iteration 966\n",
            "Chose Action 2: 0.49948186528497407 < 0.5005181347150259\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 966\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 966\n",
            "Iteration 967\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948293691830403, action1_reward_count: 967\n",
            "action2_reward: 1, action2_reward_avg: 0.500517063081696, action2_reward_count: 967\n",
            "Iteration 968\n",
            "Chose Action 2: 0.49948293691830403 < 0.500517063081696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 968\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 968\n",
            "Iteration 969\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948400412796695, action1_reward_count: 969\n",
            "action2_reward: 1, action2_reward_avg: 0.500515995872033, action2_reward_count: 969\n",
            "Iteration 970\n",
            "Chose Action 2: 0.49948400412796695 < 0.500515995872033\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 970\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 970\n",
            "Iteration 971\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49948506694129763, action1_reward_count: 971\n",
            "action2_reward: 1, action2_reward_avg: 0.5005149330587023, action2_reward_count: 971\n",
            "Iteration 972\n",
            "Chose Action 2: 0.49948506694129763 < 0.5005149330587023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 972\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 972\n",
            "Iteration 973\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499486125385406, action1_reward_count: 973\n",
            "action2_reward: 1, action2_reward_avg: 0.500513874614594, action2_reward_count: 973\n",
            "Iteration 974\n",
            "Chose Action 2: 0.499486125385406 < 0.500513874614594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 974\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 974\n",
            "Iteration 975\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49948717948717947, action1_reward_count: 975\n",
            "action2_reward: 1, action2_reward_avg: 0.5005128205128204, action2_reward_count: 975\n",
            "Iteration 976\n",
            "Chose Action 2: 0.49948717948717947 < 0.5005128205128204\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 976\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 976\n",
            "Iteration 977\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49948822927328557, action1_reward_count: 977\n",
            "action2_reward: 1, action2_reward_avg: 0.5005117707267143, action2_reward_count: 977\n",
            "Iteration 978\n",
            "Chose Action 2: 0.49948822927328557 < 0.5005117707267143\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 978\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 978\n",
            "Iteration 979\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49948927477017363, action1_reward_count: 979\n",
            "action2_reward: 1, action2_reward_avg: 0.5005107252298262, action2_reward_count: 979\n",
            "Iteration 980\n",
            "Chose Action 2: 0.49948927477017363 < 0.5005107252298262\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 980\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 980\n",
            "Iteration 981\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49949031600407745, action1_reward_count: 981\n",
            "action2_reward: 1, action2_reward_avg: 0.5005096839959223, action2_reward_count: 981\n",
            "Iteration 982\n",
            "Chose Action 2: 0.49949031600407745 < 0.5005096839959223\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 982\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 982\n",
            "Iteration 983\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949135300101727, action1_reward_count: 983\n",
            "action2_reward: 1, action2_reward_avg: 0.5005086469989825, action2_reward_count: 983\n",
            "Iteration 984\n",
            "Chose Action 2: 0.49949135300101727 < 0.5005086469989825\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 984\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 984\n",
            "Iteration 985\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49949238578680205, action1_reward_count: 985\n",
            "action2_reward: 1, action2_reward_avg: 0.5005076142131977, action2_reward_count: 985\n",
            "Iteration 986\n",
            "Chose Action 2: 0.49949238578680205 < 0.5005076142131977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 986\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 986\n",
            "Iteration 987\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49949341438703143, action1_reward_count: 987\n",
            "action2_reward: 1, action2_reward_avg: 0.5005065856129683, action2_reward_count: 987\n",
            "Iteration 988\n",
            "Chose Action 2: 0.49949341438703143 < 0.5005065856129683\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 988\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 988\n",
            "Iteration 989\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4994944388270981, action1_reward_count: 989\n",
            "action2_reward: 1, action2_reward_avg: 0.5005055611729017, action2_reward_count: 989\n",
            "Iteration 990\n",
            "Chose Action 2: 0.4994944388270981 < 0.5005055611729017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 990\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 990\n",
            "Iteration 991\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949545913218973, action1_reward_count: 991\n",
            "action2_reward: 1, action2_reward_avg: 0.50050454086781, action2_reward_count: 991\n",
            "Iteration 992\n",
            "Chose Action 2: 0.49949545913218973 < 0.50050454086781\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 992\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 992\n",
            "Iteration 993\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499496475327291, action1_reward_count: 993\n",
            "action2_reward: 1, action2_reward_avg: 0.5005035246727088, action2_reward_count: 993\n",
            "Iteration 994\n",
            "Chose Action 2: 0.499496475327291 < 0.5005035246727088\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 994\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 994\n",
            "Iteration 995\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4994974874371859, action1_reward_count: 995\n",
            "action2_reward: 1, action2_reward_avg: 0.5005025125628139, action2_reward_count: 995\n",
            "Iteration 996\n",
            "Chose Action 2: 0.4994974874371859 < 0.5005025125628139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 996\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 996\n",
            "Iteration 997\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949849548645936, action1_reward_count: 997\n",
            "action2_reward: 1, action2_reward_avg: 0.5005015045135404, action2_reward_count: 997\n",
            "Iteration 998\n",
            "Chose Action 2: 0.49949849548645936 < 0.5005015045135404\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 998\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 998\n",
            "Iteration 999\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4994994994994995, action1_reward_count: 999\n",
            "action2_reward: 1, action2_reward_avg: 0.5005005005005002, action2_reward_count: 999\n",
            "Iteration 1000\n",
            "Chose Action 2: 0.4994994994994995 < 0.5005005005005002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1000\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1000\n",
            "Iteration 1001\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995004995004995, action1_reward_count: 1001\n",
            "action2_reward: 1, action2_reward_avg: 0.5004995004995002, action2_reward_count: 1001\n",
            "Iteration 1002\n",
            "Chose Action 2: 0.4995004995004995 < 0.5004995004995002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1002\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1002\n",
            "Iteration 1003\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995014955134596, action1_reward_count: 1003\n",
            "action2_reward: 1, action2_reward_avg: 0.5004985044865401, action2_reward_count: 1003\n",
            "Iteration 1004\n",
            "Chose Action 2: 0.4995014955134596 < 0.5004985044865401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1004\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1004\n",
            "Iteration 1005\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49950248756218907, action1_reward_count: 1005\n",
            "action2_reward: 1, action2_reward_avg: 0.5004975124378107, action2_reward_count: 1005\n",
            "Iteration 1006\n",
            "Chose Action 2: 0.49950248756218907 < 0.5004975124378107\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1006\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1006\n",
            "Iteration 1007\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950347567030784, action1_reward_count: 1007\n",
            "action2_reward: 1, action2_reward_avg: 0.5004965243296919, action2_reward_count: 1007\n",
            "Iteration 1008\n",
            "Chose Action 2: 0.49950347567030784 < 0.5004965243296919\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1008\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1008\n",
            "Iteration 1009\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950445986124875, action1_reward_count: 1009\n",
            "action2_reward: 1, action2_reward_avg: 0.500495540138751, action2_reward_count: 1009\n",
            "Iteration 1010\n",
            "Chose Action 2: 0.49950445986124875 < 0.500495540138751\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1010\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1010\n",
            "Iteration 1011\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49950544015825915, action1_reward_count: 1011\n",
            "action2_reward: 1, action2_reward_avg: 0.5004945598417406, action2_reward_count: 1011\n",
            "Iteration 1012\n",
            "Chose Action 2: 0.49950544015825915 < 0.5004945598417406\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1012\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1012\n",
            "Iteration 1013\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950641658440276, action1_reward_count: 1013\n",
            "action2_reward: 1, action2_reward_avg: 0.500493583415597, action2_reward_count: 1013\n",
            "Iteration 1014\n",
            "Chose Action 2: 0.49950641658440276 < 0.500493583415597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1014\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1014\n",
            "Iteration 1015\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995073891625616, action1_reward_count: 1015\n",
            "action2_reward: 1, action2_reward_avg: 0.5004926108374382, action2_reward_count: 1015\n",
            "Iteration 1016\n",
            "Chose Action 2: 0.4995073891625616 < 0.5004926108374382\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1016\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1016\n",
            "Iteration 1017\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995083579154376, action1_reward_count: 1017\n",
            "action2_reward: 1, action2_reward_avg: 0.5004916420845623, action2_reward_count: 1017\n",
            "Iteration 1018\n",
            "Chose Action 2: 0.4995083579154376 < 0.5004916420845623\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1018\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1018\n",
            "Iteration 1019\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49950932286555444, action1_reward_count: 1019\n",
            "action2_reward: 1, action2_reward_avg: 0.5004906771344454, action2_reward_count: 1019\n",
            "Iteration 1020\n",
            "Chose Action 2: 0.49950932286555444 < 0.5004906771344454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1020\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1020\n",
            "Iteration 1021\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49951028403525954, action1_reward_count: 1021\n",
            "action2_reward: 1, action2_reward_avg: 0.5004897159647402, action2_reward_count: 1021\n",
            "Iteration 1022\n",
            "Chose Action 2: 0.49951028403525954 < 0.5004897159647402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1022\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1022\n",
            "Iteration 1023\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995112414467253, action1_reward_count: 1023\n",
            "action2_reward: 1, action2_reward_avg: 0.5004887585532745, action2_reward_count: 1023\n",
            "Iteration 1024\n",
            "Chose Action 2: 0.4995112414467253 < 0.5004887585532745\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1024\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1024\n",
            "Iteration 1025\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995121951219512, action1_reward_count: 1025\n",
            "action2_reward: 1, action2_reward_avg: 0.5004878048780486, action2_reward_count: 1025\n",
            "Iteration 1026\n",
            "Chose Action 2: 0.4995121951219512 < 0.5004878048780486\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1026\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1026\n",
            "Iteration 1027\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951314508276534, action1_reward_count: 1027\n",
            "action2_reward: 1, action2_reward_avg: 0.5004868549172344, action2_reward_count: 1027\n",
            "Iteration 1028\n",
            "Chose Action 2: 0.49951314508276534 < 0.5004868549172344\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1028\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1028\n",
            "Iteration 1029\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951409135082603, action1_reward_count: 1029\n",
            "action2_reward: 1, action2_reward_avg: 0.5004859086491737, action2_reward_count: 1029\n",
            "Iteration 1030\n",
            "Chose Action 2: 0.49951409135082603 < 0.5004859086491737\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1030\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1030\n",
            "Iteration 1031\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951503394762364, action1_reward_count: 1031\n",
            "action2_reward: 1, action2_reward_avg: 0.5004849660523761, action2_reward_count: 1031\n",
            "Iteration 1032\n",
            "Chose Action 2: 0.49951503394762364 < 0.5004849660523761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1032\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1032\n",
            "Iteration 1033\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995159728944821, action1_reward_count: 1033\n",
            "action2_reward: 1, action2_reward_avg: 0.5004840271055176, action2_reward_count: 1033\n",
            "Iteration 1034\n",
            "Chose Action 2: 0.4995159728944821 < 0.5004840271055176\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1034\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1034\n",
            "Iteration 1035\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995169082125604, action1_reward_count: 1035\n",
            "action2_reward: 1, action2_reward_avg: 0.5004830917874393, action2_reward_count: 1035\n",
            "Iteration 1036\n",
            "Chose Action 2: 0.4995169082125604 < 0.5004830917874393\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1036\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1036\n",
            "Iteration 1037\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49951783992285437, action1_reward_count: 1037\n",
            "action2_reward: 1, action2_reward_avg: 0.5004821600771453, action2_reward_count: 1037\n",
            "Iteration 1038\n",
            "Chose Action 2: 0.49951783992285437 < 0.5004821600771453\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1038\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1038\n",
            "Iteration 1039\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49951876804619827, action1_reward_count: 1039\n",
            "action2_reward: 1, action2_reward_avg: 0.5004812319538015, action2_reward_count: 1039\n",
            "Iteration 1040\n",
            "Chose Action 2: 0.49951876804619827 < 0.5004812319538015\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1040\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1040\n",
            "Iteration 1041\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49951969260326606, action1_reward_count: 1041\n",
            "action2_reward: 1, action2_reward_avg: 0.5004803073967337, action2_reward_count: 1041\n",
            "Iteration 1042\n",
            "Chose Action 2: 0.49951969260326606 < 0.5004803073967337\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1042\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1042\n",
            "Iteration 1043\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49952061361457334, action1_reward_count: 1043\n",
            "action2_reward: 1, action2_reward_avg: 0.5004793863854263, action2_reward_count: 1043\n",
            "Iteration 1044\n",
            "Chose Action 2: 0.49952061361457334 < 0.5004793863854263\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1044\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1044\n",
            "Iteration 1045\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995215311004785, action1_reward_count: 1045\n",
            "action2_reward: 1, action2_reward_avg: 0.5004784688995212, action2_reward_count: 1045\n",
            "Iteration 1046\n",
            "Chose Action 2: 0.4995215311004785 < 0.5004784688995212\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1046\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1046\n",
            "Iteration 1047\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995224450811843, action1_reward_count: 1047\n",
            "action2_reward: 1, action2_reward_avg: 0.5004775549188153, action2_reward_count: 1047\n",
            "Iteration 1048\n",
            "Chose Action 2: 0.4995224450811843 < 0.5004775549188153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1048\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1048\n",
            "Iteration 1049\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49952335557673977, action1_reward_count: 1049\n",
            "action2_reward: 1, action2_reward_avg: 0.5004766444232599, action2_reward_count: 1049\n",
            "Iteration 1050\n",
            "Chose Action 2: 0.49952335557673977 < 0.5004766444232599\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1050\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1050\n",
            "Iteration 1051\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995242626070409, action1_reward_count: 1051\n",
            "action2_reward: 1, action2_reward_avg: 0.5004757373929588, action2_reward_count: 1051\n",
            "Iteration 1052\n",
            "Chose Action 2: 0.4995242626070409 < 0.5004757373929588\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1052\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1052\n",
            "Iteration 1053\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49952516619183285, action1_reward_count: 1053\n",
            "action2_reward: 1, action2_reward_avg: 0.5004748338081668, action2_reward_count: 1053\n",
            "Iteration 1054\n",
            "Chose Action 2: 0.49952516619183285 < 0.5004748338081668\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1054\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1054\n",
            "Iteration 1055\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995260663507109, action1_reward_count: 1055\n",
            "action2_reward: 1, action2_reward_avg: 0.5004739336492887, action2_reward_count: 1055\n",
            "Iteration 1056\n",
            "Chose Action 2: 0.4995260663507109 < 0.5004739336492887\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1056\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1056\n",
            "Iteration 1057\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49952696310312206, action1_reward_count: 1057\n",
            "action2_reward: 1, action2_reward_avg: 0.5004730368968776, action2_reward_count: 1057\n",
            "Iteration 1058\n",
            "Chose Action 2: 0.49952696310312206 < 0.5004730368968776\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1058\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1058\n",
            "Iteration 1059\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995278564683664, action1_reward_count: 1059\n",
            "action2_reward: 1, action2_reward_avg: 0.5004721435316333, action2_reward_count: 1059\n",
            "Iteration 1060\n",
            "Chose Action 2: 0.4995278564683664 < 0.5004721435316333\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1060\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1060\n",
            "Iteration 1061\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49952874646559847, action1_reward_count: 1061\n",
            "action2_reward: 1, action2_reward_avg: 0.5004712535344011, action2_reward_count: 1061\n",
            "Iteration 1062\n",
            "Chose Action 2: 0.49952874646559847 < 0.5004712535344011\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1062\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1062\n",
            "Iteration 1063\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995296331138288, action1_reward_count: 1063\n",
            "action2_reward: 1, action2_reward_avg: 0.5004703668861709, action2_reward_count: 1063\n",
            "Iteration 1064\n",
            "Chose Action 2: 0.4995296331138288 < 0.5004703668861709\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1064\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1064\n",
            "Iteration 1065\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49953051643192486, action1_reward_count: 1065\n",
            "action2_reward: 1, action2_reward_avg: 0.5004694835680747, action2_reward_count: 1065\n",
            "Iteration 1066\n",
            "Chose Action 2: 0.49953051643192486 < 0.5004694835680747\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1066\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1066\n",
            "Iteration 1067\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49953139643861294, action1_reward_count: 1067\n",
            "action2_reward: 1, action2_reward_avg: 0.5004686035613867, action2_reward_count: 1067\n",
            "Iteration 1068\n",
            "Chose Action 2: 0.49953139643861294 < 0.5004686035613867\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1068\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1068\n",
            "Iteration 1069\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49953227315247895, action1_reward_count: 1069\n",
            "action2_reward: 1, action2_reward_avg: 0.5004677268475206, action2_reward_count: 1069\n",
            "Iteration 1070\n",
            "Chose Action 2: 0.49953227315247895 < 0.5004677268475206\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1070\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1070\n",
            "Iteration 1071\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995331465919701, action1_reward_count: 1071\n",
            "action2_reward: 1, action2_reward_avg: 0.5004668534080294, action2_reward_count: 1071\n",
            "Iteration 1072\n",
            "Chose Action 2: 0.4995331465919701 < 0.5004668534080294\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1072\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1072\n",
            "Iteration 1073\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995340167753961, action1_reward_count: 1073\n",
            "action2_reward: 1, action2_reward_avg: 0.5004659832246035, action2_reward_count: 1073\n",
            "Iteration 1074\n",
            "Chose Action 2: 0.4995340167753961 < 0.5004659832246035\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1074\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1074\n",
            "Iteration 1075\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953488372093025, action1_reward_count: 1075\n",
            "action2_reward: 1, action2_reward_avg: 0.5004651162790693, action2_reward_count: 1075\n",
            "Iteration 1076\n",
            "Chose Action 2: 0.49953488372093025 < 0.5004651162790693\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1076\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1076\n",
            "Iteration 1077\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953574744661094, action1_reward_count: 1077\n",
            "action2_reward: 1, action2_reward_avg: 0.5004642525533886, action2_reward_count: 1077\n",
            "Iteration 1078\n",
            "Chose Action 2: 0.49953574744661094 < 0.5004642525533886\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1078\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1078\n",
            "Iteration 1079\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4995366079703429, action1_reward_count: 1079\n",
            "action2_reward: 1, action2_reward_avg: 0.5004633920296566, action2_reward_count: 1079\n",
            "Iteration 1080\n",
            "Chose Action 2: 0.4995366079703429 < 0.5004633920296566\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1080\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1080\n",
            "Iteration 1081\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49953746530989823, action1_reward_count: 1081\n",
            "action2_reward: 1, action2_reward_avg: 0.5004625346901013, action2_reward_count: 1081\n",
            "Iteration 1082\n",
            "Chose Action 2: 0.49953746530989823 < 0.5004625346901013\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1082\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1082\n",
            "Iteration 1083\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4995383194829178, action1_reward_count: 1083\n",
            "action2_reward: 1, action2_reward_avg: 0.5004616805170817, action2_reward_count: 1083\n",
            "Iteration 1084\n",
            "Chose Action 2: 0.4995383194829178 < 0.5004616805170817\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1084\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1084\n",
            "Iteration 1085\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953917050691243, action1_reward_count: 1085\n",
            "action2_reward: 1, action2_reward_avg: 0.5004608294930871, action2_reward_count: 1085\n",
            "Iteration 1086\n",
            "Chose Action 2: 0.49953917050691243 < 0.5004608294930871\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1086\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1086\n",
            "Iteration 1087\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954001839926404, action1_reward_count: 1087\n",
            "action2_reward: 1, action2_reward_avg: 0.5004599816007356, action2_reward_count: 1087\n",
            "Iteration 1088\n",
            "Chose Action 2: 0.49954001839926404 < 0.5004599816007356\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1088\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1088\n",
            "Iteration 1089\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995408631772268, action1_reward_count: 1089\n",
            "action2_reward: 1, action2_reward_avg: 0.5004591368227728, action2_reward_count: 1089\n",
            "Iteration 1090\n",
            "Chose Action 2: 0.4995408631772268 < 0.5004591368227728\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1090\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1090\n",
            "Iteration 1091\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995417048579285, action1_reward_count: 1091\n",
            "action2_reward: 1, action2_reward_avg: 0.5004582951420711, action2_reward_count: 1091\n",
            "Iteration 1092\n",
            "Chose Action 2: 0.4995417048579285 < 0.5004582951420711\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1092\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1092\n",
            "Iteration 1093\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954254345837146, action1_reward_count: 1093\n",
            "action2_reward: 1, action2_reward_avg: 0.5004574565416281, action2_reward_count: 1093\n",
            "Iteration 1094\n",
            "Chose Action 2: 0.49954254345837146 < 0.5004574565416281\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1094\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1094\n",
            "Iteration 1095\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995433789954338, action1_reward_count: 1095\n",
            "action2_reward: 1, action2_reward_avg: 0.5004566210045658, action2_reward_count: 1095\n",
            "Iteration 1096\n",
            "Chose Action 2: 0.4995433789954338 < 0.5004566210045658\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1096\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1096\n",
            "Iteration 1097\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995442114858706, action1_reward_count: 1097\n",
            "action2_reward: 1, action2_reward_avg: 0.500455788514129, action2_reward_count: 1097\n",
            "Iteration 1098\n",
            "Chose Action 2: 0.4995442114858706 < 0.500455788514129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1098\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1098\n",
            "Iteration 1099\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954504094631486, action1_reward_count: 1099\n",
            "action2_reward: 1, action2_reward_avg: 0.5004549590536848, action2_reward_count: 1099\n",
            "Iteration 1100\n",
            "Chose Action 2: 0.49954504094631486 < 0.5004549590536848\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1100\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1100\n",
            "Iteration 1101\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49954586739327883, action1_reward_count: 1101\n",
            "action2_reward: 1, action2_reward_avg: 0.5004541326067208, action2_reward_count: 1101\n",
            "Iteration 1102\n",
            "Chose Action 2: 0.49954586739327883 < 0.5004541326067208\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1102\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1102\n",
            "Iteration 1103\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.499546690843155, action1_reward_count: 1103\n",
            "action2_reward: 1, action2_reward_avg: 0.5004533091568446, action2_reward_count: 1103\n",
            "Iteration 1104\n",
            "Chose Action 2: 0.499546690843155 < 0.5004533091568446\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1104\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1104\n",
            "Iteration 1105\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995475113122172, action1_reward_count: 1105\n",
            "action2_reward: 1, action2_reward_avg: 0.5004524886877825, action2_reward_count: 1105\n",
            "Iteration 1106\n",
            "Chose Action 2: 0.4995475113122172 < 0.5004524886877825\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1106\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1106\n",
            "Iteration 1107\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995483288166215, action1_reward_count: 1107\n",
            "action2_reward: 1, action2_reward_avg: 0.5004516711833782, action2_reward_count: 1107\n",
            "Iteration 1108\n",
            "Chose Action 2: 0.4995483288166215 < 0.5004516711833782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1108\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1108\n",
            "Iteration 1109\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995491433724076, action1_reward_count: 1109\n",
            "action2_reward: 1, action2_reward_avg: 0.5004508566275921, action2_reward_count: 1109\n",
            "Iteration 1110\n",
            "Chose Action 2: 0.4995491433724076 < 0.5004508566275921\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1110\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1110\n",
            "Iteration 1111\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49954995499549953, action1_reward_count: 1111\n",
            "action2_reward: 1, action2_reward_avg: 0.5004500450045002, action2_reward_count: 1111\n",
            "Iteration 1112\n",
            "Chose Action 2: 0.49954995499549953 < 0.5004500450045002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1112\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1112\n",
            "Iteration 1113\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995507637017071, action1_reward_count: 1113\n",
            "action2_reward: 1, action2_reward_avg: 0.5004492362982926, action2_reward_count: 1113\n",
            "Iteration 1114\n",
            "Chose Action 2: 0.4995507637017071 < 0.5004492362982926\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1114\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1114\n",
            "Iteration 1115\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955156950672647, action1_reward_count: 1115\n",
            "action2_reward: 1, action2_reward_avg: 0.5004484304932733, action2_reward_count: 1115\n",
            "Iteration 1116\n",
            "Chose Action 2: 0.49955156950672647 < 0.5004484304932733\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1116\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1116\n",
            "Iteration 1117\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995523724261415, action1_reward_count: 1117\n",
            "action2_reward: 1, action2_reward_avg: 0.5004476275738583, action2_reward_count: 1117\n",
            "Iteration 1118\n",
            "Chose Action 2: 0.4995523724261415 < 0.5004476275738583\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1118\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1118\n",
            "Iteration 1119\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49955317247542447, action1_reward_count: 1119\n",
            "action2_reward: 1, action2_reward_avg: 0.5004468275245753, action2_reward_count: 1119\n",
            "Iteration 1120\n",
            "Chose Action 2: 0.49955317247542447 < 0.5004468275245753\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1120\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1120\n",
            "Iteration 1121\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955396966993754, action1_reward_count: 1121\n",
            "action2_reward: 1, action2_reward_avg: 0.5004460303300622, action2_reward_count: 1121\n",
            "Iteration 1122\n",
            "Chose Action 2: 0.49955396966993754 < 0.5004460303300622\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1122\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1122\n",
            "Iteration 1123\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995547640249332, action1_reward_count: 1123\n",
            "action2_reward: 1, action2_reward_avg: 0.5004452359750665, action2_reward_count: 1123\n",
            "Iteration 1124\n",
            "Chose Action 2: 0.4995547640249332 < 0.5004452359750665\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1124\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1124\n",
            "Iteration 1125\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955555555555553, action1_reward_count: 1125\n",
            "action2_reward: 1, action2_reward_avg: 0.5004444444444441, action2_reward_count: 1125\n",
            "Iteration 1126\n",
            "Chose Action 2: 0.49955555555555553 < 0.5004444444444441\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1126\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1126\n",
            "Iteration 1127\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49955634427684115, action1_reward_count: 1127\n",
            "action2_reward: 1, action2_reward_avg: 0.5004436557231585, action2_reward_count: 1127\n",
            "Iteration 1128\n",
            "Chose Action 2: 0.49955634427684115 < 0.5004436557231585\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1128\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1128\n",
            "Iteration 1129\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995571302037201, action1_reward_count: 1129\n",
            "action2_reward: 1, action2_reward_avg: 0.5004428697962796, action2_reward_count: 1129\n",
            "Iteration 1130\n",
            "Chose Action 2: 0.4995571302037201 < 0.5004428697962796\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1130\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1130\n",
            "Iteration 1131\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995579133510168, action1_reward_count: 1131\n",
            "action2_reward: 1, action2_reward_avg: 0.5004420866489829, action2_reward_count: 1131\n",
            "Iteration 1132\n",
            "Chose Action 2: 0.4995579133510168 < 0.5004420866489829\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1132\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1132\n",
            "Iteration 1133\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.499558693733451, action1_reward_count: 1133\n",
            "action2_reward: 1, action2_reward_avg: 0.5004413062665487, action2_reward_count: 1133\n",
            "Iteration 1134\n",
            "Chose Action 2: 0.499558693733451 < 0.5004413062665487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1134\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1134\n",
            "Iteration 1135\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995594713656388, action1_reward_count: 1135\n",
            "action2_reward: 1, action2_reward_avg: 0.500440528634361, action2_reward_count: 1135\n",
            "Iteration 1136\n",
            "Chose Action 2: 0.4995594713656388 < 0.500440528634361\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1136\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1136\n",
            "Iteration 1137\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995602462620932, action1_reward_count: 1137\n",
            "action2_reward: 1, action2_reward_avg: 0.5004397537379065, action2_reward_count: 1137\n",
            "Iteration 1138\n",
            "Chose Action 2: 0.4995602462620932 < 0.5004397537379065\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1138\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1138\n",
            "Iteration 1139\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995610184372256, action1_reward_count: 1139\n",
            "action2_reward: 1, action2_reward_avg: 0.5004389815627741, action2_reward_count: 1139\n",
            "Iteration 1140\n",
            "Chose Action 2: 0.4995610184372256 < 0.5004389815627741\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1140\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1140\n",
            "Iteration 1141\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956178790534617, action1_reward_count: 1141\n",
            "action2_reward: 1, action2_reward_avg: 0.5004382120946536, action2_reward_count: 1141\n",
            "Iteration 1142\n",
            "Chose Action 2: 0.49956178790534617 < 0.5004382120946536\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1142\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1142\n",
            "Iteration 1143\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995625546806649, action1_reward_count: 1143\n",
            "action2_reward: 1, action2_reward_avg: 0.5004374453193348, action2_reward_count: 1143\n",
            "Iteration 1144\n",
            "Chose Action 2: 0.4995625546806649 < 0.5004374453193348\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1144\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1144\n",
            "Iteration 1145\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995633187772926, action1_reward_count: 1145\n",
            "action2_reward: 1, action2_reward_avg: 0.5004366812227071, action2_reward_count: 1145\n",
            "Iteration 1146\n",
            "Chose Action 2: 0.4995633187772926 < 0.5004366812227071\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1146\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1146\n",
            "Iteration 1147\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995640802092415, action1_reward_count: 1147\n",
            "action2_reward: 1, action2_reward_avg: 0.5004359197907582, action2_reward_count: 1147\n",
            "Iteration 1148\n",
            "Chose Action 2: 0.4995640802092415 < 0.5004359197907582\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1148\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1148\n",
            "Iteration 1149\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995648389904265, action1_reward_count: 1149\n",
            "action2_reward: 1, action2_reward_avg: 0.5004351610095732, action2_reward_count: 1149\n",
            "Iteration 1150\n",
            "Chose Action 2: 0.4995648389904265 < 0.5004351610095732\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1150\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1150\n",
            "Iteration 1151\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49956559513466553, action1_reward_count: 1151\n",
            "action2_reward: 1, action2_reward_avg: 0.5004344048653342, action2_reward_count: 1151\n",
            "Iteration 1152\n",
            "Chose Action 2: 0.49956559513466553 < 0.5004344048653342\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1152\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1152\n",
            "Iteration 1153\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956634865568084, action1_reward_count: 1153\n",
            "action2_reward: 1, action2_reward_avg: 0.5004336513443189, action2_reward_count: 1153\n",
            "Iteration 1154\n",
            "Chose Action 2: 0.49956634865568084 < 0.5004336513443189\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1154\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1154\n",
            "Iteration 1155\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49956709956709955, action1_reward_count: 1155\n",
            "action2_reward: 1, action2_reward_avg: 0.5004329004329002, action2_reward_count: 1155\n",
            "Iteration 1156\n",
            "Chose Action 2: 0.49956709956709955 < 0.5004329004329002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1156\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1156\n",
            "Iteration 1157\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995678478824546, action1_reward_count: 1157\n",
            "action2_reward: 1, action2_reward_avg: 0.5004321521175451, action2_reward_count: 1157\n",
            "Iteration 1158\n",
            "Chose Action 2: 0.4995678478824546 < 0.5004321521175451\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1158\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1158\n",
            "Iteration 1159\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995685936151855, action1_reward_count: 1159\n",
            "action2_reward: 1, action2_reward_avg: 0.5004314063848142, action2_reward_count: 1159\n",
            "Iteration 1160\n",
            "Chose Action 2: 0.4995685936151855 < 0.5004314063848142\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1160\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1160\n",
            "Iteration 1161\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956933677863913, action1_reward_count: 1161\n",
            "action2_reward: 1, action2_reward_avg: 0.5004306632213606, action2_reward_count: 1161\n",
            "Iteration 1162\n",
            "Chose Action 2: 0.49956933677863913 < 0.5004306632213606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1162\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1162\n",
            "Iteration 1163\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995700773860705, action1_reward_count: 1163\n",
            "action2_reward: 1, action2_reward_avg: 0.5004299226139293, action2_reward_count: 1163\n",
            "Iteration 1164\n",
            "Chose Action 2: 0.4995700773860705 < 0.5004299226139293\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1164\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1164\n",
            "Iteration 1165\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995708154506438, action1_reward_count: 1165\n",
            "action2_reward: 1, action2_reward_avg: 0.500429184549356, action2_reward_count: 1165\n",
            "Iteration 1166\n",
            "Chose Action 2: 0.4995708154506438 < 0.500429184549356\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1166\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1166\n",
            "Iteration 1167\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995715509854327, action1_reward_count: 1167\n",
            "action2_reward: 1, action2_reward_avg: 0.5004284490145671, action2_reward_count: 1167\n",
            "Iteration 1168\n",
            "Chose Action 2: 0.4995715509854327 < 0.5004284490145671\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1168\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1168\n",
            "Iteration 1169\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49957228400342174, action1_reward_count: 1169\n",
            "action2_reward: 1, action2_reward_avg: 0.5004277159965781, action2_reward_count: 1169\n",
            "Iteration 1170\n",
            "Chose Action 2: 0.49957228400342174 < 0.5004277159965781\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1170\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1170\n",
            "Iteration 1171\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995730145175064, action1_reward_count: 1171\n",
            "action2_reward: 1, action2_reward_avg: 0.5004269854824934, action2_reward_count: 1171\n",
            "Iteration 1172\n",
            "Chose Action 2: 0.4995730145175064 < 0.5004269854824934\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1172\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1172\n",
            "Iteration 1173\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957374254049447, action1_reward_count: 1173\n",
            "action2_reward: 1, action2_reward_avg: 0.5004262574595054, action2_reward_count: 1173\n",
            "Iteration 1174\n",
            "Chose Action 2: 0.49957374254049447 < 0.5004262574595054\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1174\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1174\n",
            "Iteration 1175\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49957446808510636, action1_reward_count: 1175\n",
            "action2_reward: 1, action2_reward_avg: 0.5004255319148935, action2_reward_count: 1175\n",
            "Iteration 1176\n",
            "Chose Action 2: 0.49957446808510636 < 0.5004255319148935\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1176\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1176\n",
            "Iteration 1177\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995751911639762, action1_reward_count: 1177\n",
            "action2_reward: 1, action2_reward_avg: 0.5004248088360236, action2_reward_count: 1177\n",
            "Iteration 1178\n",
            "Chose Action 2: 0.4995751911639762 < 0.5004248088360236\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1178\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1178\n",
            "Iteration 1179\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49957591178965227, action1_reward_count: 1179\n",
            "action2_reward: 1, action2_reward_avg: 0.5004240882103476, action2_reward_count: 1179\n",
            "Iteration 1180\n",
            "Chose Action 2: 0.49957591178965227 < 0.5004240882103476\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1180\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1180\n",
            "Iteration 1181\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995766299745978, action1_reward_count: 1181\n",
            "action2_reward: 1, action2_reward_avg: 0.500423370025402, action2_reward_count: 1181\n",
            "Iteration 1182\n",
            "Chose Action 2: 0.4995766299745978 < 0.500423370025402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1182\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1182\n",
            "Iteration 1183\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995773457311919, action1_reward_count: 1183\n",
            "action2_reward: 1, action2_reward_avg: 0.5004226542688079, action2_reward_count: 1183\n",
            "Iteration 1184\n",
            "Chose Action 2: 0.4995773457311919 < 0.5004226542688079\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1184\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1184\n",
            "Iteration 1185\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957805907173, action1_reward_count: 1185\n",
            "action2_reward: 1, action2_reward_avg: 0.5004219409282699, action2_reward_count: 1185\n",
            "Iteration 1186\n",
            "Chose Action 2: 0.49957805907173 < 0.5004219409282699\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1186\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1186\n",
            "Iteration 1187\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995787700084246, action1_reward_count: 1187\n",
            "action2_reward: 1, action2_reward_avg: 0.5004212299915752, action2_reward_count: 1187\n",
            "Iteration 1188\n",
            "Chose Action 2: 0.4995787700084246 < 0.5004212299915752\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1188\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1188\n",
            "Iteration 1189\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957947855340623, action1_reward_count: 1189\n",
            "action2_reward: 1, action2_reward_avg: 0.5004205214465937, action2_reward_count: 1189\n",
            "Iteration 1190\n",
            "Chose Action 2: 0.49957947855340623 < 0.5004205214465937\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1190\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1190\n",
            "Iteration 1191\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995801847187238, action1_reward_count: 1191\n",
            "action2_reward: 1, action2_reward_avg: 0.5004198152812761, action2_reward_count: 1191\n",
            "Iteration 1192\n",
            "Chose Action 2: 0.4995801847187238 < 0.5004198152812761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1192\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1192\n",
            "Iteration 1193\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49958088851634536, action1_reward_count: 1193\n",
            "action2_reward: 1, action2_reward_avg: 0.5004191114836546, action2_reward_count: 1193\n",
            "Iteration 1194\n",
            "Chose Action 2: 0.49958088851634536 < 0.5004191114836546\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1194\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1194\n",
            "Iteration 1195\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499581589958159, action1_reward_count: 1195\n",
            "action2_reward: 1, action2_reward_avg: 0.500418410041841, action2_reward_count: 1195\n",
            "Iteration 1196\n",
            "Chose Action 2: 0.499581589958159 < 0.500418410041841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1196\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1196\n",
            "Iteration 1197\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958228905597324, action1_reward_count: 1197\n",
            "action2_reward: 1, action2_reward_avg: 0.5004177109440267, action2_reward_count: 1197\n",
            "Iteration 1198\n",
            "Chose Action 2: 0.49958228905597324 < 0.5004177109440267\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1198\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1198\n",
            "Iteration 1199\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958298582151794, action1_reward_count: 1199\n",
            "action2_reward: 1, action2_reward_avg: 0.5004170141784821, action2_reward_count: 1199\n",
            "Iteration 1200\n",
            "Chose Action 2: 0.49958298582151794 < 0.5004170141784821\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1200\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1200\n",
            "Iteration 1201\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995836802664446, action1_reward_count: 1201\n",
            "action2_reward: 1, action2_reward_avg: 0.5004163197335554, action2_reward_count: 1201\n",
            "Iteration 1202\n",
            "Chose Action 2: 0.4995836802664446 < 0.5004163197335554\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1202\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1202\n",
            "Iteration 1203\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995843724023275, action1_reward_count: 1203\n",
            "action2_reward: 1, action2_reward_avg: 0.5004156275976724, action2_reward_count: 1203\n",
            "Iteration 1204\n",
            "Chose Action 2: 0.4995843724023275 < 0.5004156275976724\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1204\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1204\n",
            "Iteration 1205\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4995850622406639, action1_reward_count: 1205\n",
            "action2_reward: 1, action2_reward_avg: 0.5004149377593361, action2_reward_count: 1205\n",
            "Iteration 1206\n",
            "Chose Action 2: 0.4995850622406639 < 0.5004149377593361\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1206\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1206\n",
            "Iteration 1207\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995857497928749, action1_reward_count: 1207\n",
            "action2_reward: 1, action2_reward_avg: 0.5004142502071252, action2_reward_count: 1207\n",
            "Iteration 1208\n",
            "Chose Action 2: 0.4995857497928749 < 0.5004142502071252\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1208\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1208\n",
            "Iteration 1209\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49958643507030603, action1_reward_count: 1209\n",
            "action2_reward: 1, action2_reward_avg: 0.5004135649296939, action2_reward_count: 1209\n",
            "Iteration 1210\n",
            "Chose Action 2: 0.49958643507030603 < 0.5004135649296939\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1210\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1210\n",
            "Iteration 1211\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4995871180842279, action1_reward_count: 1211\n",
            "action2_reward: 1, action2_reward_avg: 0.500412881915772, action2_reward_count: 1211\n",
            "Iteration 1212\n",
            "Chose Action 2: 0.4995871180842279 < 0.500412881915772\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1212\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1212\n",
            "Iteration 1213\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958779884583676, action1_reward_count: 1213\n",
            "action2_reward: 1, action2_reward_avg: 0.5004122011541632, action2_reward_count: 1213\n",
            "Iteration 1214\n",
            "Chose Action 2: 0.49958779884583676 < 0.5004122011541632\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1214\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1214\n",
            "Iteration 1215\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958847736625517, action1_reward_count: 1215\n",
            "action2_reward: 1, action2_reward_avg: 0.5004115226337448, action2_reward_count: 1215\n",
            "Iteration 1216\n",
            "Chose Action 2: 0.49958847736625517 < 0.5004115226337448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1216\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1216\n",
            "Iteration 1217\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958915365653245, action1_reward_count: 1217\n",
            "action2_reward: 1, action2_reward_avg: 0.5004108463434674, action2_reward_count: 1217\n",
            "Iteration 1218\n",
            "Chose Action 2: 0.49958915365653245 < 0.5004108463434674\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1218\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1218\n",
            "Iteration 1219\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995898277276456, action1_reward_count: 1219\n",
            "action2_reward: 1, action2_reward_avg: 0.5004101722723543, action2_reward_count: 1219\n",
            "Iteration 1220\n",
            "Chose Action 2: 0.4995898277276456 < 0.5004101722723543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1220\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1220\n",
            "Iteration 1221\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995904995904996, action1_reward_count: 1221\n",
            "action2_reward: 1, action2_reward_avg: 0.5004095004095003, action2_reward_count: 1221\n",
            "Iteration 1222\n",
            "Chose Action 2: 0.4995904995904996 < 0.5004095004095003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1222\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1222\n",
            "Iteration 1223\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959116925592806, action1_reward_count: 1223\n",
            "action2_reward: 1, action2_reward_avg: 0.5004088307440718, action2_reward_count: 1223\n",
            "Iteration 1224\n",
            "Chose Action 2: 0.49959116925592806 < 0.5004088307440718\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1224\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1224\n",
            "Iteration 1225\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995918367346939, action1_reward_count: 1225\n",
            "action2_reward: 1, action2_reward_avg: 0.500408163265306, action2_reward_count: 1225\n",
            "Iteration 1226\n",
            "Chose Action 2: 0.4995918367346939 < 0.500408163265306\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1226\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1226\n",
            "Iteration 1227\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959250203748984, action1_reward_count: 1227\n",
            "action2_reward: 1, action2_reward_avg: 0.50040749796251, action2_reward_count: 1227\n",
            "Iteration 1228\n",
            "Chose Action 2: 0.49959250203748984 < 0.50040749796251\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1228\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1228\n",
            "Iteration 1229\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959316517493896, action1_reward_count: 1229\n",
            "action2_reward: 1, action2_reward_avg: 0.5004068348250609, action2_reward_count: 1229\n",
            "Iteration 1230\n",
            "Chose Action 2: 0.49959316517493896 < 0.5004068348250609\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1230\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1230\n",
            "Iteration 1231\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49959382615759546, action1_reward_count: 1231\n",
            "action2_reward: 1, action2_reward_avg: 0.5004061738424044, action2_reward_count: 1231\n",
            "Iteration 1232\n",
            "Chose Action 2: 0.49959382615759546 < 0.5004061738424044\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1232\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1232\n",
            "Iteration 1233\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49959448499594483, action1_reward_count: 1233\n",
            "action2_reward: 1, action2_reward_avg: 0.500405515004055, action2_reward_count: 1233\n",
            "Iteration 1234\n",
            "Chose Action 2: 0.49959448499594483 < 0.500405515004055\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1234\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1234\n",
            "Iteration 1235\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49959514170040487, action1_reward_count: 1235\n",
            "action2_reward: 1, action2_reward_avg: 0.5004048582995949, action2_reward_count: 1235\n",
            "Iteration 1236\n",
            "Chose Action 2: 0.49959514170040487 < 0.5004048582995949\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1236\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1236\n",
            "Iteration 1237\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995957962813258, action1_reward_count: 1237\n",
            "action2_reward: 1, action2_reward_avg: 0.500404203718674, action2_reward_count: 1237\n",
            "Iteration 1238\n",
            "Chose Action 2: 0.4995957962813258 < 0.500404203718674\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1238\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1238\n",
            "Iteration 1239\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995964487489911, action1_reward_count: 1239\n",
            "action2_reward: 1, action2_reward_avg: 0.5004035512510087, action2_reward_count: 1239\n",
            "Iteration 1240\n",
            "Chose Action 2: 0.4995964487489911 < 0.5004035512510087\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1240\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1240\n",
            "Iteration 1241\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49959709911361805, action1_reward_count: 1241\n",
            "action2_reward: 1, action2_reward_avg: 0.5004029008863817, action2_reward_count: 1241\n",
            "Iteration 1242\n",
            "Chose Action 2: 0.49959709911361805 < 0.5004029008863817\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1242\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1242\n",
            "Iteration 1243\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499597747385358, action1_reward_count: 1243\n",
            "action2_reward: 1, action2_reward_avg: 0.5004022526146418, action2_reward_count: 1243\n",
            "Iteration 1244\n",
            "Chose Action 2: 0.499597747385358 < 0.5004022526146418\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1244\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1244\n",
            "Iteration 1245\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995983935742972, action1_reward_count: 1245\n",
            "action2_reward: 1, action2_reward_avg: 0.5004016064257026, action2_reward_count: 1245\n",
            "Iteration 1246\n",
            "Chose Action 2: 0.4995983935742972 < 0.5004016064257026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1246\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1246\n",
            "Iteration 1247\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995990376904571, action1_reward_count: 1247\n",
            "action2_reward: 1, action2_reward_avg: 0.5004009623095428, action2_reward_count: 1247\n",
            "Iteration 1248\n",
            "Chose Action 2: 0.4995990376904571 < 0.5004009623095428\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1248\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1248\n",
            "Iteration 1249\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959967974379504, action1_reward_count: 1249\n",
            "action2_reward: 1, action2_reward_avg: 0.5004003202562048, action2_reward_count: 1249\n",
            "Iteration 1250\n",
            "Chose Action 2: 0.49959967974379504 < 0.5004003202562048\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1250\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1250\n",
            "Iteration 1251\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49960031974420466, action1_reward_count: 1251\n",
            "action2_reward: 1, action2_reward_avg: 0.5003996802557953, action2_reward_count: 1251\n",
            "Iteration 1252\n",
            "Chose Action 2: 0.49960031974420466 < 0.5003996802557953\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1252\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1252\n",
            "Iteration 1253\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49960095770151636, action1_reward_count: 1253\n",
            "action2_reward: 1, action2_reward_avg: 0.5003990422984835, action2_reward_count: 1253\n",
            "Iteration 1254\n",
            "Chose Action 2: 0.49960095770151636 < 0.5003990422984835\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1254\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1254\n",
            "Iteration 1255\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499601593625498, action1_reward_count: 1255\n",
            "action2_reward: 1, action2_reward_avg: 0.5003984063745018, action2_reward_count: 1255\n",
            "Iteration 1256\n",
            "Chose Action 2: 0.499601593625498 < 0.5003984063745018\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1256\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1256\n",
            "Iteration 1257\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996022275258552, action1_reward_count: 1257\n",
            "action2_reward: 1, action2_reward_avg: 0.5003977724741446, action2_reward_count: 1257\n",
            "Iteration 1258\n",
            "Chose Action 2: 0.4996022275258552 < 0.5003977724741446\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1258\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1258\n",
            "Iteration 1259\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996028594122319, action1_reward_count: 1259\n",
            "action2_reward: 1, action2_reward_avg: 0.5003971405877679, action2_reward_count: 1259\n",
            "Iteration 1260\n",
            "Chose Action 2: 0.4996028594122319 < 0.5003971405877679\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1260\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1260\n",
            "Iteration 1261\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49960348929421095, action1_reward_count: 1261\n",
            "action2_reward: 1, action2_reward_avg: 0.5003965107057888, action2_reward_count: 1261\n",
            "Iteration 1262\n",
            "Chose Action 2: 0.49960348929421095 < 0.5003965107057888\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1262\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1262\n",
            "Iteration 1263\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996041171813143, action1_reward_count: 1263\n",
            "action2_reward: 1, action2_reward_avg: 0.5003958828186854, action2_reward_count: 1263\n",
            "Iteration 1264\n",
            "Chose Action 2: 0.4996041171813143 < 0.5003958828186854\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1264\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1264\n",
            "Iteration 1265\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49960474308300395, action1_reward_count: 1265\n",
            "action2_reward: 1, action2_reward_avg: 0.5003952569169958, action2_reward_count: 1265\n",
            "Iteration 1266\n",
            "Chose Action 2: 0.49960474308300395 < 0.5003952569169958\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1266\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1266\n",
            "Iteration 1267\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996053670086819, action1_reward_count: 1267\n",
            "action2_reward: 1, action2_reward_avg: 0.5003946329913178, action2_reward_count: 1267\n",
            "Iteration 1268\n",
            "Chose Action 2: 0.4996053670086819 < 0.5003946329913178\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1268\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1268\n",
            "Iteration 1269\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996059889676911, action1_reward_count: 1269\n",
            "action2_reward: 1, action2_reward_avg: 0.5003940110323086, action2_reward_count: 1269\n",
            "Iteration 1270\n",
            "Chose Action 2: 0.4996059889676911 < 0.5003940110323086\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1270\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1270\n",
            "Iteration 1271\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996066089693155, action1_reward_count: 1271\n",
            "action2_reward: 1, action2_reward_avg: 0.5003933910306843, action2_reward_count: 1271\n",
            "Iteration 1272\n",
            "Chose Action 2: 0.4996066089693155 < 0.5003933910306843\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1272\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1272\n",
            "Iteration 1273\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996072270227808, action1_reward_count: 1273\n",
            "action2_reward: 1, action2_reward_avg: 0.500392772977219, action2_reward_count: 1273\n",
            "Iteration 1274\n",
            "Chose Action 2: 0.4996072270227808 < 0.500392772977219\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1274\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1274\n",
            "Iteration 1275\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996078431372549, action1_reward_count: 1275\n",
            "action2_reward: 1, action2_reward_avg: 0.5003921568627449, action2_reward_count: 1275\n",
            "Iteration 1276\n",
            "Chose Action 2: 0.4996078431372549 < 0.5003921568627449\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1276\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1276\n",
            "Iteration 1277\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49960845732184805, action1_reward_count: 1277\n",
            "action2_reward: 1, action2_reward_avg: 0.5003915426781517, action2_reward_count: 1277\n",
            "Iteration 1278\n",
            "Chose Action 2: 0.49960845732184805 < 0.5003915426781517\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1278\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1278\n",
            "Iteration 1279\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49960906958561374, action1_reward_count: 1279\n",
            "action2_reward: 1, action2_reward_avg: 0.500390930414386, action2_reward_count: 1279\n",
            "Iteration 1280\n",
            "Chose Action 2: 0.49960906958561374 < 0.500390930414386\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1280\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1280\n",
            "Iteration 1281\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996096799375488, action1_reward_count: 1281\n",
            "action2_reward: 1, action2_reward_avg: 0.5003903200624509, action2_reward_count: 1281\n",
            "Iteration 1282\n",
            "Chose Action 2: 0.4996096799375488 < 0.5003903200624509\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1282\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1282\n",
            "Iteration 1283\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961028838659394, action1_reward_count: 1283\n",
            "action2_reward: 1, action2_reward_avg: 0.5003897116134057, action2_reward_count: 1283\n",
            "Iteration 1284\n",
            "Chose Action 2: 0.49961028838659394 < 0.5003897116134057\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1284\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1284\n",
            "Iteration 1285\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961089494163424, action1_reward_count: 1285\n",
            "action2_reward: 1, action2_reward_avg: 0.5003891050583654, action2_reward_count: 1285\n",
            "Iteration 1286\n",
            "Chose Action 2: 0.49961089494163424 < 0.5003891050583654\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1286\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1286\n",
            "Iteration 1287\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4996114996114996, action1_reward_count: 1287\n",
            "action2_reward: 1, action2_reward_avg: 0.5003885003885, action2_reward_count: 1287\n",
            "Iteration 1288\n",
            "Chose Action 2: 0.4996114996114996 < 0.5003885003885\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1288\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1288\n",
            "Iteration 1289\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49961210240496506, action1_reward_count: 1289\n",
            "action2_reward: 1, action2_reward_avg: 0.5003878975950345, action2_reward_count: 1289\n",
            "Iteration 1290\n",
            "Chose Action 2: 0.49961210240496506 < 0.5003878975950345\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1290\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1290\n",
            "Iteration 1291\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49961270333075136, action1_reward_count: 1291\n",
            "action2_reward: 1, action2_reward_avg: 0.5003872966692483, action2_reward_count: 1291\n",
            "Iteration 1292\n",
            "Chose Action 2: 0.49961270333075136 < 0.5003872966692483\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1292\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1292\n",
            "Iteration 1293\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961330239752516, action1_reward_count: 1293\n",
            "action2_reward: 1, action2_reward_avg: 0.5003866976024746, action2_reward_count: 1293\n",
            "Iteration 1294\n",
            "Chose Action 2: 0.49961330239752516 < 0.5003866976024746\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1294\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1294\n",
            "Iteration 1295\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996138996138996, action1_reward_count: 1295\n",
            "action2_reward: 1, action2_reward_avg: 0.5003861003861001, action2_reward_count: 1295\n",
            "Iteration 1296\n",
            "Chose Action 2: 0.4996138996138996 < 0.5003861003861001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1296\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1296\n",
            "Iteration 1297\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49961449498843485, action1_reward_count: 1297\n",
            "action2_reward: 1, action2_reward_avg: 0.5003855050115649, action2_reward_count: 1297\n",
            "Iteration 1298\n",
            "Chose Action 2: 0.49961449498843485 < 0.5003855050115649\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1298\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1298\n",
            "Iteration 1299\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996150885296382, action1_reward_count: 1299\n",
            "action2_reward: 1, action2_reward_avg: 0.5003849114703616, action2_reward_count: 1299\n",
            "Iteration 1300\n",
            "Chose Action 2: 0.4996150885296382 < 0.5003849114703616\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1300\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1300\n",
            "Iteration 1301\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961568024596464, action1_reward_count: 1301\n",
            "action2_reward: 1, action2_reward_avg: 0.5003843197540352, action2_reward_count: 1301\n",
            "Iteration 1302\n",
            "Chose Action 2: 0.49961568024596464 < 0.5003843197540352\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1302\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1302\n",
            "Iteration 1303\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49961627014581733, action1_reward_count: 1303\n",
            "action2_reward: 1, action2_reward_avg: 0.5003837298541824, action2_reward_count: 1303\n",
            "Iteration 1304\n",
            "Chose Action 2: 0.49961627014581733 < 0.5003837298541824\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1304\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1304\n",
            "Iteration 1305\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961685823754787, action1_reward_count: 1305\n",
            "action2_reward: 1, action2_reward_avg: 0.5003831417624519, action2_reward_count: 1305\n",
            "Iteration 1306\n",
            "Chose Action 2: 0.49961685823754787 < 0.5003831417624519\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1306\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1306\n",
            "Iteration 1307\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996174445294568, action1_reward_count: 1307\n",
            "action2_reward: 1, action2_reward_avg: 0.500382555470543, action2_reward_count: 1307\n",
            "Iteration 1308\n",
            "Chose Action 2: 0.4996174445294568 < 0.500382555470543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1308\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1308\n",
            "Iteration 1309\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961802902979374, action1_reward_count: 1309\n",
            "action2_reward: 1, action2_reward_avg: 0.5003819709702061, action2_reward_count: 1309\n",
            "Iteration 1310\n",
            "Chose Action 2: 0.49961802902979374 < 0.5003819709702061\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1310\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1310\n",
            "Iteration 1311\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996186117467582, action1_reward_count: 1311\n",
            "action2_reward: 1, action2_reward_avg: 0.5003813882532416, action2_reward_count: 1311\n",
            "Iteration 1312\n",
            "Chose Action 2: 0.4996186117467582 < 0.5003813882532416\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1312\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1312\n",
            "Iteration 1313\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49961919268849964, action1_reward_count: 1313\n",
            "action2_reward: 1, action2_reward_avg: 0.5003808073115003, action2_reward_count: 1313\n",
            "Iteration 1314\n",
            "Chose Action 2: 0.49961919268849964 < 0.5003808073115003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1314\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1314\n",
            "Iteration 1315\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49961977186311785, action1_reward_count: 1315\n",
            "action2_reward: 1, action2_reward_avg: 0.500380228136882, action2_reward_count: 1315\n",
            "Iteration 1316\n",
            "Chose Action 2: 0.49961977186311785 < 0.500380228136882\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1316\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1316\n",
            "Iteration 1317\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996203492786636, action1_reward_count: 1317\n",
            "action2_reward: 1, action2_reward_avg: 0.5003796507213362, action2_reward_count: 1317\n",
            "Iteration 1318\n",
            "Chose Action 2: 0.4996203492786636 < 0.5003796507213362\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1318\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1318\n",
            "Iteration 1319\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49962092494313876, action1_reward_count: 1319\n",
            "action2_reward: 1, action2_reward_avg: 0.5003790750568611, action2_reward_count: 1319\n",
            "Iteration 1320\n",
            "Chose Action 2: 0.49962092494313876 < 0.5003790750568611\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1320\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1320\n",
            "Iteration 1321\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996214988644966, action1_reward_count: 1321\n",
            "action2_reward: 1, action2_reward_avg: 0.5003785011355032, action2_reward_count: 1321\n",
            "Iteration 1322\n",
            "Chose Action 2: 0.4996214988644966 < 0.5003785011355032\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1322\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1322\n",
            "Iteration 1323\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996220710506425, action1_reward_count: 1323\n",
            "action2_reward: 1, action2_reward_avg: 0.5003779289493573, action2_reward_count: 1323\n",
            "Iteration 1324\n",
            "Chose Action 2: 0.4996220710506425 < 0.5003779289493573\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1324\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1324\n",
            "Iteration 1325\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499622641509434, action1_reward_count: 1325\n",
            "action2_reward: 1, action2_reward_avg: 0.5003773584905659, action2_reward_count: 1325\n",
            "Iteration 1326\n",
            "Chose Action 2: 0.499622641509434 < 0.5003773584905659\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1326\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1326\n",
            "Iteration 1327\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996232102486812, action1_reward_count: 1327\n",
            "action2_reward: 1, action2_reward_avg: 0.5003767897513186, action2_reward_count: 1327\n",
            "Iteration 1328\n",
            "Chose Action 2: 0.4996232102486812 < 0.5003767897513186\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1328\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1328\n",
            "Iteration 1329\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996237772761475, action1_reward_count: 1329\n",
            "action2_reward: 1, action2_reward_avg: 0.5003762227238524, action2_reward_count: 1329\n",
            "Iteration 1330\n",
            "Chose Action 2: 0.4996237772761475 < 0.5003762227238524\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1330\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1330\n",
            "Iteration 1331\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996243425995492, action1_reward_count: 1331\n",
            "action2_reward: 1, action2_reward_avg: 0.5003756574004506, action2_reward_count: 1331\n",
            "Iteration 1332\n",
            "Chose Action 2: 0.4996243425995492 < 0.5003756574004506\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1332\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1332\n",
            "Iteration 1333\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49962490622655664, action1_reward_count: 1333\n",
            "action2_reward: 1, action2_reward_avg: 0.5003750937734432, action2_reward_count: 1333\n",
            "Iteration 1334\n",
            "Chose Action 2: 0.49962490622655664 < 0.5003750937734432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1334\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1334\n",
            "Iteration 1335\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962546816479403, action1_reward_count: 1335\n",
            "action2_reward: 1, action2_reward_avg: 0.5003745318352059, action2_reward_count: 1335\n",
            "Iteration 1336\n",
            "Chose Action 2: 0.49962546816479403 < 0.5003745318352059\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1336\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1336\n",
            "Iteration 1337\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962602842183995, action1_reward_count: 1337\n",
            "action2_reward: 1, action2_reward_avg: 0.50037397157816, action2_reward_count: 1337\n",
            "Iteration 1338\n",
            "Chose Action 2: 0.49962602842183995 < 0.50037397157816\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1338\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1338\n",
            "Iteration 1339\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996265870052278, action1_reward_count: 1339\n",
            "action2_reward: 1, action2_reward_avg: 0.5003734129947721, action2_reward_count: 1339\n",
            "Iteration 1340\n",
            "Chose Action 2: 0.4996265870052278 < 0.5003734129947721\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1340\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1340\n",
            "Iteration 1341\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962714392244595, action1_reward_count: 1341\n",
            "action2_reward: 1, action2_reward_avg: 0.500372856077554, action2_reward_count: 1341\n",
            "Iteration 1342\n",
            "Chose Action 2: 0.49962714392244595 < 0.500372856077554\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1342\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1342\n",
            "Iteration 1343\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996276991809382, action1_reward_count: 1343\n",
            "action2_reward: 1, action2_reward_avg: 0.5003723008190617, action2_reward_count: 1343\n",
            "Iteration 1344\n",
            "Chose Action 2: 0.4996276991809382 < 0.5003723008190617\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1344\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1344\n",
            "Iteration 1345\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996282527881041, action1_reward_count: 1345\n",
            "action2_reward: 1, action2_reward_avg: 0.5003717472118958, action2_reward_count: 1345\n",
            "Iteration 1346\n",
            "Chose Action 2: 0.4996282527881041 < 0.5003717472118958\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1346\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1346\n",
            "Iteration 1347\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962880475129917, action1_reward_count: 1347\n",
            "action2_reward: 1, action2_reward_avg: 0.5003711952487007, action2_reward_count: 1347\n",
            "Iteration 1348\n",
            "Chose Action 2: 0.49962880475129917 < 0.5003711952487007\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1348\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1348\n",
            "Iteration 1349\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49962935507783546, action1_reward_count: 1349\n",
            "action2_reward: 1, action2_reward_avg: 0.5003706449221644, action2_reward_count: 1349\n",
            "Iteration 1350\n",
            "Chose Action 2: 0.49962935507783546 < 0.5003706449221644\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1350\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1350\n",
            "Iteration 1351\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996299037749815, action1_reward_count: 1351\n",
            "action2_reward: 1, action2_reward_avg: 0.5003700962250184, action2_reward_count: 1351\n",
            "Iteration 1352\n",
            "Chose Action 2: 0.4996299037749815 < 0.5003700962250184\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1352\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1352\n",
            "Iteration 1353\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963045084996305, action1_reward_count: 1353\n",
            "action2_reward: 1, action2_reward_avg: 0.5003695491500368, action2_reward_count: 1353\n",
            "Iteration 1354\n",
            "Chose Action 2: 0.49963045084996305 < 0.5003695491500368\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1354\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1354\n",
            "Iteration 1355\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996309963099631, action1_reward_count: 1355\n",
            "action2_reward: 1, action2_reward_avg: 0.5003690036900368, action2_reward_count: 1355\n",
            "Iteration 1356\n",
            "Chose Action 2: 0.4996309963099631 < 0.5003690036900368\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1356\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1356\n",
            "Iteration 1357\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963154016212236, action1_reward_count: 1357\n",
            "action2_reward: 1, action2_reward_avg: 0.5003684598378776, action2_reward_count: 1357\n",
            "Iteration 1358\n",
            "Chose Action 2: 0.49963154016212236 < 0.5003684598378776\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1358\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1358\n",
            "Iteration 1359\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49963208241353935, action1_reward_count: 1359\n",
            "action2_reward: 1, action2_reward_avg: 0.5003679175864606, action2_reward_count: 1359\n",
            "Iteration 1360\n",
            "Chose Action 2: 0.49963208241353935 < 0.5003679175864606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1360\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1360\n",
            "Iteration 1361\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996326230712711, action1_reward_count: 1361\n",
            "action2_reward: 1, action2_reward_avg: 0.5003673769287288, action2_reward_count: 1361\n",
            "Iteration 1362\n",
            "Chose Action 2: 0.4996326230712711 < 0.5003673769287288\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1362\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1362\n",
            "Iteration 1363\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996331621423331, action1_reward_count: 1363\n",
            "action2_reward: 1, action2_reward_avg: 0.5003668378576668, action2_reward_count: 1363\n",
            "Iteration 1364\n",
            "Chose Action 2: 0.4996331621423331 < 0.5003668378576668\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1364\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1364\n",
            "Iteration 1365\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963369963369964, action1_reward_count: 1365\n",
            "action2_reward: 1, action2_reward_avg: 0.5003663003663003, action2_reward_count: 1365\n",
            "Iteration 1366\n",
            "Chose Action 2: 0.49963369963369964 < 0.5003663003663003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1366\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1366\n",
            "Iteration 1367\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996342355523043, action1_reward_count: 1367\n",
            "action2_reward: 1, action2_reward_avg: 0.5003657644476955, action2_reward_count: 1367\n",
            "Iteration 1368\n",
            "Chose Action 2: 0.4996342355523043 < 0.5003657644476955\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1368\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1368\n",
            "Iteration 1369\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996347699050402, action1_reward_count: 1369\n",
            "action2_reward: 1, action2_reward_avg: 0.5003652300949597, action2_reward_count: 1369\n",
            "Iteration 1370\n",
            "Chose Action 2: 0.4996347699050402 < 0.5003652300949597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1370\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1370\n",
            "Iteration 1371\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963530269876005, action1_reward_count: 1371\n",
            "action2_reward: 1, action2_reward_avg: 0.5003646973012399, action2_reward_count: 1371\n",
            "Iteration 1372\n",
            "Chose Action 2: 0.49963530269876005 < 0.5003646973012399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1372\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1372\n",
            "Iteration 1373\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996358339402768, action1_reward_count: 1373\n",
            "action2_reward: 1, action2_reward_avg: 0.5003641660597232, action2_reward_count: 1373\n",
            "Iteration 1374\n",
            "Chose Action 2: 0.4996358339402768 < 0.5003641660597232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1374\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1374\n",
            "Iteration 1375\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963636363636366, action1_reward_count: 1375\n",
            "action2_reward: 1, action2_reward_avg: 0.5003636363636363, action2_reward_count: 1375\n",
            "Iteration 1376\n",
            "Chose Action 2: 0.49963636363636366 < 0.5003636363636363\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1376\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1376\n",
            "Iteration 1377\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963689179375453, action1_reward_count: 1377\n",
            "action2_reward: 1, action2_reward_avg: 0.5003631082062454, action2_reward_count: 1377\n",
            "Iteration 1378\n",
            "Chose Action 2: 0.49963689179375453 < 0.5003631082062454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1378\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1378\n",
            "Iteration 1379\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49963741841914433, action1_reward_count: 1379\n",
            "action2_reward: 1, action2_reward_avg: 0.5003625815808557, action2_reward_count: 1379\n",
            "Iteration 1380\n",
            "Chose Action 2: 0.49963741841914433 < 0.5003625815808557\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1380\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1380\n",
            "Iteration 1381\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499637943519189, action1_reward_count: 1381\n",
            "action2_reward: 1, action2_reward_avg: 0.500362056480811, action2_reward_count: 1381\n",
            "Iteration 1382\n",
            "Chose Action 2: 0.499637943519189 < 0.500362056480811\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1382\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1382\n",
            "Iteration 1383\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963846710050613, action1_reward_count: 1383\n",
            "action2_reward: 1, action2_reward_avg: 0.5003615328994938, action2_reward_count: 1383\n",
            "Iteration 1384\n",
            "Chose Action 2: 0.49963846710050613 < 0.5003615328994938\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1384\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1384\n",
            "Iteration 1385\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996389891696751, action1_reward_count: 1385\n",
            "action2_reward: 1, action2_reward_avg: 0.5003610108303248, action2_reward_count: 1385\n",
            "Iteration 1386\n",
            "Chose Action 2: 0.4996389891696751 < 0.5003610108303248\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1386\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1386\n",
            "Iteration 1387\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963950973323723, action1_reward_count: 1387\n",
            "action2_reward: 1, action2_reward_avg: 0.5003604902667627, action2_reward_count: 1387\n",
            "Iteration 1388\n",
            "Chose Action 2: 0.49963950973323723 < 0.5003604902667627\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1388\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1388\n",
            "Iteration 1389\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996400287976962, action1_reward_count: 1389\n",
            "action2_reward: 1, action2_reward_avg: 0.5003599712023037, action2_reward_count: 1389\n",
            "Iteration 1390\n",
            "Chose Action 2: 0.4996400287976962 < 0.5003599712023037\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1390\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1390\n",
            "Iteration 1391\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996405463695183, action1_reward_count: 1391\n",
            "action2_reward: 1, action2_reward_avg: 0.5003594536304815, action2_reward_count: 1391\n",
            "Iteration 1392\n",
            "Chose Action 2: 0.4996405463695183 < 0.5003594536304815\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1392\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1392\n",
            "Iteration 1393\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996410624551328, action1_reward_count: 1393\n",
            "action2_reward: 1, action2_reward_avg: 0.500358937544867, action2_reward_count: 1393\n",
            "Iteration 1394\n",
            "Chose Action 2: 0.4996410624551328 < 0.500358937544867\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1394\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1394\n",
            "Iteration 1395\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996415770609319, action1_reward_count: 1395\n",
            "action2_reward: 1, action2_reward_avg: 0.500358422939068, action2_reward_count: 1395\n",
            "Iteration 1396\n",
            "Chose Action 2: 0.4996415770609319 < 0.500358422939068\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1396\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1396\n",
            "Iteration 1397\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49964209019327127, action1_reward_count: 1397\n",
            "action2_reward: 1, action2_reward_avg: 0.5003579098067286, action2_reward_count: 1397\n",
            "Iteration 1398\n",
            "Chose Action 2: 0.49964209019327127 < 0.5003579098067286\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1398\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1398\n",
            "Iteration 1399\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996426018584703, action1_reward_count: 1399\n",
            "action2_reward: 1, action2_reward_avg: 0.5003573981415295, action2_reward_count: 1399\n",
            "Iteration 1400\n",
            "Chose Action 2: 0.4996426018584703 < 0.5003573981415295\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1400\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1400\n",
            "Iteration 1401\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964311206281226, action1_reward_count: 1401\n",
            "action2_reward: 1, action2_reward_avg: 0.5003568879371875, action2_reward_count: 1401\n",
            "Iteration 1402\n",
            "Chose Action 2: 0.49964311206281226 < 0.5003568879371875\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1402\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1402\n",
            "Iteration 1403\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49964362081254454, action1_reward_count: 1403\n",
            "action2_reward: 1, action2_reward_avg: 0.5003563791874551, action2_reward_count: 1403\n",
            "Iteration 1404\n",
            "Chose Action 2: 0.49964362081254454 < 0.5003563791874551\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1404\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1404\n",
            "Iteration 1405\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.499644128113879, action1_reward_count: 1405\n",
            "action2_reward: 1, action2_reward_avg: 0.5003558718861206, action2_reward_count: 1405\n",
            "Iteration 1406\n",
            "Chose Action 2: 0.499644128113879 < 0.5003558718861206\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1406\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1406\n",
            "Iteration 1407\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996446339729922, action1_reward_count: 1407\n",
            "action2_reward: 1, action2_reward_avg: 0.5003553660270075, action2_reward_count: 1407\n",
            "Iteration 1408\n",
            "Chose Action 2: 0.4996446339729922 < 0.5003553660270075\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1408\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1408\n",
            "Iteration 1409\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49964513839602553, action1_reward_count: 1409\n",
            "action2_reward: 1, action2_reward_avg: 0.5003548616039741, action2_reward_count: 1409\n",
            "Iteration 1410\n",
            "Chose Action 2: 0.49964513839602553 < 0.5003548616039741\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1410\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1410\n",
            "Iteration 1411\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49964564138908574, action1_reward_count: 1411\n",
            "action2_reward: 1, action2_reward_avg: 0.5003543586109139, action2_reward_count: 1411\n",
            "Iteration 1412\n",
            "Chose Action 2: 0.49964564138908574 < 0.5003543586109139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1412\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1412\n",
            "Iteration 1413\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4996461429582449, action1_reward_count: 1413\n",
            "action2_reward: 1, action2_reward_avg: 0.5003538570417548, action2_reward_count: 1413\n",
            "Iteration 1414\n",
            "Chose Action 2: 0.4996461429582449 < 0.5003538570417548\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1414\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1414\n",
            "Iteration 1415\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49964664310954066, action1_reward_count: 1415\n",
            "action2_reward: 1, action2_reward_avg: 0.5003533568904591, action2_reward_count: 1415\n",
            "Iteration 1416\n",
            "Chose Action 2: 0.49964664310954066 < 0.5003533568904591\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1416\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1416\n",
            "Iteration 1417\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964714184897674, action1_reward_count: 1417\n",
            "action2_reward: 1, action2_reward_avg: 0.500352858151023, action2_reward_count: 1417\n",
            "Iteration 1418\n",
            "Chose Action 2: 0.49964714184897674 < 0.500352858151023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1418\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1418\n",
            "Iteration 1419\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996476391825229, action1_reward_count: 1419\n",
            "action2_reward: 1, action2_reward_avg: 0.5003523608174769, action2_reward_count: 1419\n",
            "Iteration 1420\n",
            "Chose Action 2: 0.4996476391825229 < 0.5003523608174769\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1420\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1420\n",
            "Iteration 1421\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996481351161154, action1_reward_count: 1421\n",
            "action2_reward: 1, action2_reward_avg: 0.5003518648838844, action2_reward_count: 1421\n",
            "Iteration 1422\n",
            "Chose Action 2: 0.4996481351161154 < 0.5003518648838844\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1422\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1422\n",
            "Iteration 1423\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964862965565704, action1_reward_count: 1423\n",
            "action2_reward: 1, action2_reward_avg: 0.5003513703443427, action2_reward_count: 1423\n",
            "Iteration 1424\n",
            "Chose Action 2: 0.49964862965565704 < 0.5003513703443427\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1424\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1424\n",
            "Iteration 1425\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964912280701756, action1_reward_count: 1425\n",
            "action2_reward: 1, action2_reward_avg: 0.5003508771929822, action2_reward_count: 1425\n",
            "Iteration 1426\n",
            "Chose Action 2: 0.49964912280701756 < 0.5003508771929822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1426\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1426\n",
            "Iteration 1427\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964961457603363, action1_reward_count: 1427\n",
            "action2_reward: 1, action2_reward_avg: 0.5003503854239661, action2_reward_count: 1427\n",
            "Iteration 1428\n",
            "Chose Action 2: 0.49964961457603363 < 0.5003503854239661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1428\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1428\n",
            "Iteration 1429\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996501049685094, action1_reward_count: 1429\n",
            "action2_reward: 1, action2_reward_avg: 0.5003498950314903, action2_reward_count: 1429\n",
            "Iteration 1430\n",
            "Chose Action 2: 0.4996501049685094 < 0.5003498950314903\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1430\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1430\n",
            "Iteration 1431\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996505939902166, action1_reward_count: 1431\n",
            "action2_reward: 1, action2_reward_avg: 0.5003494060097831, action2_reward_count: 1431\n",
            "Iteration 1432\n",
            "Chose Action 2: 0.4996505939902166 < 0.5003494060097831\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1432\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1432\n",
            "Iteration 1433\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49965108164689465, action1_reward_count: 1433\n",
            "action2_reward: 1, action2_reward_avg: 0.500348918353105, action2_reward_count: 1433\n",
            "Iteration 1434\n",
            "Chose Action 2: 0.49965108164689465 < 0.500348918353105\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1434\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1434\n",
            "Iteration 1435\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49965156794425086, action1_reward_count: 1435\n",
            "action2_reward: 1, action2_reward_avg: 0.5003484320557487, action2_reward_count: 1435\n",
            "Iteration 1436\n",
            "Chose Action 2: 0.49965156794425086 < 0.5003484320557487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1436\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1436\n",
            "Iteration 1437\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49965205288796105, action1_reward_count: 1437\n",
            "action2_reward: 1, action2_reward_avg: 0.5003479471120386, action2_reward_count: 1437\n",
            "Iteration 1438\n",
            "Chose Action 2: 0.49965205288796105 < 0.5003479471120386\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1438\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1438\n",
            "Iteration 1439\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996525364836692, action1_reward_count: 1439\n",
            "action2_reward: 1, action2_reward_avg: 0.5003474635163304, action2_reward_count: 1439\n",
            "Iteration 1440\n",
            "Chose Action 2: 0.4996525364836692 < 0.5003474635163304\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1440\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1440\n",
            "Iteration 1441\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996530187369882, action1_reward_count: 1441\n",
            "action2_reward: 1, action2_reward_avg: 0.5003469812630114, action2_reward_count: 1441\n",
            "Iteration 1442\n",
            "Chose Action 2: 0.4996530187369882 < 0.5003469812630114\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1442\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1442\n",
            "Iteration 1443\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49965349965349964, action1_reward_count: 1443\n",
            "action2_reward: 1, action2_reward_avg: 0.5003465003464999, action2_reward_count: 1443\n",
            "Iteration 1444\n",
            "Chose Action 2: 0.49965349965349964 < 0.5003465003464999\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1444\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1444\n",
            "Iteration 1445\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996539792387543, action1_reward_count: 1445\n",
            "action2_reward: 1, action2_reward_avg: 0.5003460207612451, action2_reward_count: 1445\n",
            "Iteration 1446\n",
            "Chose Action 2: 0.4996539792387543 < 0.5003460207612451\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1446\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1446\n",
            "Iteration 1447\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996544574982723, action1_reward_count: 1447\n",
            "action2_reward: 1, action2_reward_avg: 0.5003455425017271, action2_reward_count: 1447\n",
            "Iteration 1448\n",
            "Chose Action 2: 0.4996544574982723 < 0.5003455425017271\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1448\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1448\n",
            "Iteration 1449\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996549344375431, action1_reward_count: 1449\n",
            "action2_reward: 1, action2_reward_avg: 0.5003450655624563, action2_reward_count: 1449\n",
            "Iteration 1450\n",
            "Chose Action 2: 0.4996549344375431 < 0.5003450655624563\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1450\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1450\n",
            "Iteration 1451\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996554100620262, action1_reward_count: 1451\n",
            "action2_reward: 1, action2_reward_avg: 0.5003445899379731, action2_reward_count: 1451\n",
            "Iteration 1452\n",
            "Chose Action 2: 0.4996554100620262 < 0.5003445899379731\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1452\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1452\n",
            "Iteration 1453\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49965588437715075, action1_reward_count: 1453\n",
            "action2_reward: 1, action2_reward_avg: 0.5003441156228486, action2_reward_count: 1453\n",
            "Iteration 1454\n",
            "Chose Action 2: 0.49965588437715075 < 0.5003441156228486\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1454\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1454\n",
            "Iteration 1455\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49965635738831615, action1_reward_count: 1455\n",
            "action2_reward: 1, action2_reward_avg: 0.5003436426116833, action2_reward_count: 1455\n",
            "Iteration 1456\n",
            "Chose Action 2: 0.49965635738831615 < 0.5003436426116833\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1456\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1456\n",
            "Iteration 1457\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49965682910089226, action1_reward_count: 1457\n",
            "action2_reward: 1, action2_reward_avg: 0.5003431708991072, action2_reward_count: 1457\n",
            "Iteration 1458\n",
            "Chose Action 2: 0.49965682910089226 < 0.5003431708991072\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1458\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1458\n",
            "Iteration 1459\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996572995202193, action1_reward_count: 1459\n",
            "action2_reward: 1, action2_reward_avg: 0.5003427004797801, action2_reward_count: 1459\n",
            "Iteration 1460\n",
            "Chose Action 2: 0.4996572995202193 < 0.5003427004797801\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1460\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1460\n",
            "Iteration 1461\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996577686516085, action1_reward_count: 1461\n",
            "action2_reward: 1, action2_reward_avg: 0.500342231348391, action2_reward_count: 1461\n",
            "Iteration 1462\n",
            "Chose Action 2: 0.4996577686516085 < 0.500342231348391\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1462\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1462\n",
            "Iteration 1463\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49965823650034175, action1_reward_count: 1463\n",
            "action2_reward: 1, action2_reward_avg: 0.5003417634996576, action2_reward_count: 1463\n",
            "Iteration 1464\n",
            "Chose Action 2: 0.49965823650034175 < 0.5003417634996576\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1464\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1464\n",
            "Iteration 1465\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49965870307167237, action1_reward_count: 1465\n",
            "action2_reward: 1, action2_reward_avg: 0.5003412969283271, action2_reward_count: 1465\n",
            "Iteration 1466\n",
            "Chose Action 2: 0.49965870307167237 < 0.5003412969283271\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1466\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1466\n",
            "Iteration 1467\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996591683708248, action1_reward_count: 1467\n",
            "action2_reward: 1, action2_reward_avg: 0.5003408316291746, action2_reward_count: 1467\n",
            "Iteration 1468\n",
            "Chose Action 2: 0.4996591683708248 < 0.5003408316291746\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1468\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1468\n",
            "Iteration 1469\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996596324029952, action1_reward_count: 1469\n",
            "action2_reward: 1, action2_reward_avg: 0.5003403675970042, action2_reward_count: 1469\n",
            "Iteration 1470\n",
            "Chose Action 2: 0.4996596324029952 < 0.5003403675970042\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1470\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1470\n",
            "Iteration 1471\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966009517335147, action1_reward_count: 1471\n",
            "action2_reward: 1, action2_reward_avg: 0.5003399048266479, action2_reward_count: 1471\n",
            "Iteration 1472\n",
            "Chose Action 2: 0.49966009517335147 < 0.5003399048266479\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1472\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1472\n",
            "Iteration 1473\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966055668703324, action1_reward_count: 1473\n",
            "action2_reward: 1, action2_reward_avg: 0.5003394433129661, action2_reward_count: 1473\n",
            "Iteration 1474\n",
            "Chose Action 2: 0.49966055668703324 < 0.5003394433129661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1474\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1474\n",
            "Iteration 1475\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966101694915255, action1_reward_count: 1475\n",
            "action2_reward: 1, action2_reward_avg: 0.5003389830508468, action2_reward_count: 1475\n",
            "Iteration 1476\n",
            "Chose Action 2: 0.49966101694915255 < 0.5003389830508468\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1476\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1476\n",
            "Iteration 1477\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996614759647935, action1_reward_count: 1477\n",
            "action2_reward: 1, action2_reward_avg: 0.5003385240352058, action2_reward_count: 1477\n",
            "Iteration 1478\n",
            "Chose Action 2: 0.4996614759647935 < 0.5003385240352058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1478\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1478\n",
            "Iteration 1479\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966193373901285, action1_reward_count: 1479\n",
            "action2_reward: 1, action2_reward_avg: 0.5003380662609865, action2_reward_count: 1479\n",
            "Iteration 1480\n",
            "Chose Action 2: 0.49966193373901285 < 0.5003380662609865\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1480\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1480\n",
            "Iteration 1481\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966239027683995, action1_reward_count: 1481\n",
            "action2_reward: 1, action2_reward_avg: 0.5003376097231594, action2_reward_count: 1481\n",
            "Iteration 1482\n",
            "Chose Action 2: 0.49966239027683995 < 0.5003376097231594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1482\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1482\n",
            "Iteration 1483\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996628455832771, action1_reward_count: 1483\n",
            "action2_reward: 1, action2_reward_avg: 0.5003371544167222, action2_reward_count: 1483\n",
            "Iteration 1484\n",
            "Chose Action 2: 0.4996628455832771 < 0.5003371544167222\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1484\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1484\n",
            "Iteration 1485\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966329966329964, action1_reward_count: 1485\n",
            "action2_reward: 1, action2_reward_avg: 0.5003367003366996, action2_reward_count: 1485\n",
            "Iteration 1486\n",
            "Chose Action 2: 0.49966329966329964 < 0.5003367003366996\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1486\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1486\n",
            "Iteration 1487\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996637525218561, action1_reward_count: 1487\n",
            "action2_reward: 1, action2_reward_avg: 0.5003362474781432, action2_reward_count: 1487\n",
            "Iteration 1488\n",
            "Chose Action 2: 0.4996637525218561 < 0.5003362474781432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1488\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1488\n",
            "Iteration 1489\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49966420416386836, action1_reward_count: 1489\n",
            "action2_reward: 1, action2_reward_avg: 0.5003357958361309, action2_reward_count: 1489\n",
            "Iteration 1490\n",
            "Chose Action 2: 0.49966420416386836 < 0.5003357958361309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1490\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1490\n",
            "Iteration 1491\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49966465459423204, action1_reward_count: 1491\n",
            "action2_reward: 1, action2_reward_avg: 0.5003353454057672, action2_reward_count: 1491\n",
            "Iteration 1492\n",
            "Chose Action 2: 0.49966465459423204 < 0.5003353454057672\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1492\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1492\n",
            "Iteration 1493\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.4996651038178165, action1_reward_count: 1493\n",
            "action2_reward: 1, action2_reward_avg: 0.5003348961821827, action2_reward_count: 1493\n",
            "Iteration 1494\n",
            "Chose Action 2: 0.4996651038178165 < 0.5003348961821827\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1494\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1494\n",
            "Iteration 1495\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49966555183946487, action1_reward_count: 1495\n",
            "action2_reward: 1, action2_reward_avg: 0.5003344481605343, action2_reward_count: 1495\n",
            "Iteration 1496\n",
            "Chose Action 2: 0.49966555183946487 < 0.5003344481605343\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1496\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1496\n",
            "Iteration 1497\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.49966599866399464, action1_reward_count: 1497\n",
            "action2_reward: 1, action2_reward_avg: 0.5003340013360045, action2_reward_count: 1497\n",
            "Iteration 1498\n",
            "Chose Action 2: 0.49966599866399464 < 0.5003340013360045\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1498\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1498\n",
            "Iteration 1499\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966644429619744, action1_reward_count: 1499\n",
            "action2_reward: 1, action2_reward_avg: 0.5003335557038017, action2_reward_count: 1499\n",
            "Iteration 1500\n",
            "Chose Action 2: 0.49966644429619744 < 0.5003335557038017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1500\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1500\n",
            "Iteration 1501\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996668887408394, action1_reward_count: 1501\n",
            "action2_reward: 1, action2_reward_avg: 0.5003331112591597, action2_reward_count: 1501\n",
            "Iteration 1502\n",
            "Chose Action 2: 0.4996668887408394 < 0.5003331112591597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1502\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1502\n",
            "Iteration 1503\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966733200266134, action1_reward_count: 1503\n",
            "action2_reward: 1, action2_reward_avg: 0.5003326679973378, action2_reward_count: 1503\n",
            "Iteration 1504\n",
            "Chose Action 2: 0.49966733200266134 < 0.5003326679973378\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1504\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1504\n",
            "Iteration 1505\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966777408637875, action1_reward_count: 1505\n",
            "action2_reward: 1, action2_reward_avg: 0.5003322259136204, action2_reward_count: 1505\n",
            "Iteration 1506\n",
            "Chose Action 2: 0.49966777408637875 < 0.5003322259136204\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1506\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1506\n",
            "Iteration 1507\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996682149966821, action1_reward_count: 1507\n",
            "action2_reward: 1, action2_reward_avg: 0.500331785003317, action2_reward_count: 1507\n",
            "Iteration 1508\n",
            "Chose Action 2: 0.4996682149966821 < 0.500331785003317\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1508\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1508\n",
            "Iteration 1509\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966865473823724, action1_reward_count: 1509\n",
            "action2_reward: 1, action2_reward_avg: 0.5003313452617618, action2_reward_count: 1509\n",
            "Iteration 1510\n",
            "Chose Action 2: 0.49966865473823724 < 0.5003313452617618\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1510\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999906, action2_reward_count: 1510\n",
            "Iteration 1511\n",
            "Chose Action 1: 0.5 >= 0.49999999999999906\n",
            "action1_reward: 0, action1_reward_avg: 0.499669093315685, action1_reward_count: 1511\n",
            "action2_reward: 1, action2_reward_avg: 0.5003309066843141, action2_reward_count: 1511\n",
            "Iteration 1512\n",
            "Chose Action 2: 0.499669093315685 < 0.5003309066843141\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1512\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1512\n",
            "Iteration 1513\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996695307336418, action1_reward_count: 1513\n",
            "action2_reward: 1, action2_reward_avg: 0.5003304692663574, action2_reward_count: 1513\n",
            "Iteration 1514\n",
            "Chose Action 2: 0.4996695307336418 < 0.5003304692663574\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1514\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1514\n",
            "Iteration 1515\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996699669966997, action1_reward_count: 1515\n",
            "action2_reward: 1, action2_reward_avg: 0.5003300330032995, action2_reward_count: 1515\n",
            "Iteration 1516\n",
            "Chose Action 2: 0.4996699669966997 < 0.5003300330032995\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1516\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1516\n",
            "Iteration 1517\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996704021094265, action1_reward_count: 1517\n",
            "action2_reward: 1, action2_reward_avg: 0.5003295978905726, action2_reward_count: 1517\n",
            "Iteration 1518\n",
            "Chose Action 2: 0.4996704021094265 < 0.5003295978905726\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1518\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1518\n",
            "Iteration 1519\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49967083607636603, action1_reward_count: 1519\n",
            "action2_reward: 1, action2_reward_avg: 0.5003291639236331, action2_reward_count: 1519\n",
            "Iteration 1520\n",
            "Chose Action 2: 0.49967083607636603 < 0.5003291639236331\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1520\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1520\n",
            "Iteration 1521\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996712689020381, action1_reward_count: 1521\n",
            "action2_reward: 1, action2_reward_avg: 0.500328731097961, action2_reward_count: 1521\n",
            "Iteration 1522\n",
            "Chose Action 2: 0.4996712689020381 < 0.500328731097961\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1522\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1522\n",
            "Iteration 1523\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.49967170059093896, action1_reward_count: 1523\n",
            "action2_reward: 1, action2_reward_avg: 0.5003282994090602, action2_reward_count: 1523\n",
            "Iteration 1524\n",
            "Chose Action 2: 0.49967170059093896 < 0.5003282994090602\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1524\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1524\n",
            "Iteration 1525\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.499672131147541, action1_reward_count: 1525\n",
            "action2_reward: 1, action2_reward_avg: 0.5003278688524582, action2_reward_count: 1525\n",
            "Iteration 1526\n",
            "Chose Action 2: 0.499672131147541 < 0.5003278688524582\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1526\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1526\n",
            "Iteration 1527\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996725605762934, action1_reward_count: 1527\n",
            "action2_reward: 1, action2_reward_avg: 0.5003274394237058, action2_reward_count: 1527\n",
            "Iteration 1528\n",
            "Chose Action 2: 0.4996725605762934 < 0.5003274394237058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1528\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1528\n",
            "Iteration 1529\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.499672988881622, action1_reward_count: 1529\n",
            "action2_reward: 1, action2_reward_avg: 0.5003270111183773, action2_reward_count: 1529\n",
            "Iteration 1530\n",
            "Chose Action 2: 0.499672988881622 < 0.5003270111183773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1530\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1530\n",
            "Iteration 1531\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996734160679295, action1_reward_count: 1531\n",
            "action2_reward: 1, action2_reward_avg: 0.5003265839320699, action2_reward_count: 1531\n",
            "Iteration 1532\n",
            "Chose Action 2: 0.4996734160679295 < 0.5003265839320699\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1532\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1532\n",
            "Iteration 1533\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967384213959554, action1_reward_count: 1533\n",
            "action2_reward: 1, action2_reward_avg: 0.5003261578604038, action2_reward_count: 1533\n",
            "Iteration 1534\n",
            "Chose Action 2: 0.49967384213959554 < 0.5003261578604038\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1534\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1534\n",
            "Iteration 1535\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996742671009772, action1_reward_count: 1535\n",
            "action2_reward: 1, action2_reward_avg: 0.5003257328990222, action2_reward_count: 1535\n",
            "Iteration 1536\n",
            "Chose Action 2: 0.4996742671009772 < 0.5003257328990222\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1536\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1536\n",
            "Iteration 1537\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996746909564086, action1_reward_count: 1537\n",
            "action2_reward: 1, action2_reward_avg: 0.5003253090435907, action2_reward_count: 1537\n",
            "Iteration 1538\n",
            "Chose Action 2: 0.4996746909564086 < 0.5003253090435907\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1538\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1538\n",
            "Iteration 1539\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967511371020146, action1_reward_count: 1539\n",
            "action2_reward: 1, action2_reward_avg: 0.5003248862897979, action2_reward_count: 1539\n",
            "Iteration 1540\n",
            "Chose Action 2: 0.49967511371020146 < 0.5003248862897979\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1540\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1540\n",
            "Iteration 1541\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967553536664505, action1_reward_count: 1541\n",
            "action2_reward: 1, action2_reward_avg: 0.5003244646333543, action2_reward_count: 1541\n",
            "Iteration 1542\n",
            "Chose Action 2: 0.49967553536664505 < 0.5003244646333543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1542\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1542\n",
            "Iteration 1543\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49967595593000647, action1_reward_count: 1543\n",
            "action2_reward: 1, action2_reward_avg: 0.5003240440699929, action2_reward_count: 1543\n",
            "Iteration 1544\n",
            "Chose Action 2: 0.49967595593000647 < 0.5003240440699929\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1544\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1544\n",
            "Iteration 1545\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967637540453075, action1_reward_count: 1545\n",
            "action2_reward: 1, action2_reward_avg: 0.5003236245954686, action2_reward_count: 1545\n",
            "Iteration 1546\n",
            "Chose Action 2: 0.49967637540453075 < 0.5003236245954686\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1546\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1546\n",
            "Iteration 1547\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49967679379444085, action1_reward_count: 1547\n",
            "action2_reward: 1, action2_reward_avg: 0.5003232062055586, action2_reward_count: 1547\n",
            "Iteration 1548\n",
            "Chose Action 2: 0.49967679379444085 < 0.5003232062055586\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1548\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1548\n",
            "Iteration 1549\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49967721110393803, action1_reward_count: 1549\n",
            "action2_reward: 1, action2_reward_avg: 0.5003227888960614, action2_reward_count: 1549\n",
            "Iteration 1550\n",
            "Chose Action 2: 0.49967721110393803 < 0.5003227888960614\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1550\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1550\n",
            "Iteration 1551\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996776273372018, action1_reward_count: 1551\n",
            "action2_reward: 1, action2_reward_avg: 0.5003223726627977, action2_reward_count: 1551\n",
            "Iteration 1552\n",
            "Chose Action 2: 0.4996776273372018 < 0.5003223726627977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1552\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1552\n",
            "Iteration 1553\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996780424983902, action1_reward_count: 1553\n",
            "action2_reward: 1, action2_reward_avg: 0.5003219575016092, action2_reward_count: 1553\n",
            "Iteration 1554\n",
            "Chose Action 2: 0.4996780424983902 < 0.5003219575016092\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1554\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1554\n",
            "Iteration 1555\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996784565916399, action1_reward_count: 1555\n",
            "action2_reward: 1, action2_reward_avg: 0.5003215434083595, action2_reward_count: 1555\n",
            "Iteration 1556\n",
            "Chose Action 2: 0.4996784565916399 < 0.5003215434083595\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1556\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1556\n",
            "Iteration 1557\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49967886962106617, action1_reward_count: 1557\n",
            "action2_reward: 1, action2_reward_avg: 0.5003211303789333, action2_reward_count: 1557\n",
            "Iteration 1558\n",
            "Chose Action 2: 0.49967886962106617 < 0.5003211303789333\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1558\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1558\n",
            "Iteration 1559\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996792815907633, action1_reward_count: 1559\n",
            "action2_reward: 1, action2_reward_avg: 0.5003207184092362, action2_reward_count: 1559\n",
            "Iteration 1560\n",
            "Chose Action 2: 0.4996792815907633 < 0.5003207184092362\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1560\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1560\n",
            "Iteration 1561\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996796925048046, action1_reward_count: 1561\n",
            "action2_reward: 1, action2_reward_avg: 0.5003203074951948, action2_reward_count: 1561\n",
            "Iteration 1562\n",
            "Chose Action 2: 0.4996796925048046 < 0.5003203074951948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1562\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1562\n",
            "Iteration 1563\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996801023672425, action1_reward_count: 1563\n",
            "action2_reward: 1, action2_reward_avg: 0.500319897632757, action2_reward_count: 1563\n",
            "Iteration 1564\n",
            "Chose Action 2: 0.4996801023672425 < 0.500319897632757\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1564\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1564\n",
            "Iteration 1565\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996805111821086, action1_reward_count: 1565\n",
            "action2_reward: 1, action2_reward_avg: 0.5003194888178908, action2_reward_count: 1565\n",
            "Iteration 1566\n",
            "Chose Action 2: 0.4996805111821086 < 0.5003194888178908\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1566\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1566\n",
            "Iteration 1567\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968091895341415, action1_reward_count: 1567\n",
            "action2_reward: 1, action2_reward_avg: 0.5003190810465852, action2_reward_count: 1567\n",
            "Iteration 1568\n",
            "Chose Action 2: 0.49968091895341415 < 0.5003190810465852\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1568\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1568\n",
            "Iteration 1569\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996813256851498, action1_reward_count: 1569\n",
            "action2_reward: 1, action2_reward_avg: 0.5003186743148496, action2_reward_count: 1569\n",
            "Iteration 1570\n",
            "Chose Action 2: 0.4996813256851498 < 0.5003186743148496\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1570\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1570\n",
            "Iteration 1571\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996817313812858, action1_reward_count: 1571\n",
            "action2_reward: 1, action2_reward_avg: 0.5003182686187135, action2_reward_count: 1571\n",
            "Iteration 1572\n",
            "Chose Action 2: 0.4996817313812858 < 0.5003182686187135\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1572\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1572\n",
            "Iteration 1573\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996821360457724, action1_reward_count: 1573\n",
            "action2_reward: 1, action2_reward_avg: 0.500317863954227, action2_reward_count: 1573\n",
            "Iteration 1574\n",
            "Chose Action 2: 0.4996821360457724 < 0.500317863954227\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1574\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1574\n",
            "Iteration 1575\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996825396825397, action1_reward_count: 1575\n",
            "action2_reward: 1, action2_reward_avg: 0.5003174603174596, action2_reward_count: 1575\n",
            "Iteration 1576\n",
            "Chose Action 2: 0.4996825396825397 < 0.5003174603174596\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1576\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1576\n",
            "Iteration 1577\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968294229549776, action1_reward_count: 1577\n",
            "action2_reward: 1, action2_reward_avg: 0.5003170577045015, action2_reward_count: 1577\n",
            "Iteration 1578\n",
            "Chose Action 2: 0.49968294229549776 < 0.5003170577045015\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1578\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1578\n",
            "Iteration 1579\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.499683343888537, action1_reward_count: 1579\n",
            "action2_reward: 1, action2_reward_avg: 0.5003166561114623, action2_reward_count: 1579\n",
            "Iteration 1580\n",
            "Chose Action 2: 0.499683343888537 < 0.5003166561114623\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1580\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1580\n",
            "Iteration 1581\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968374446552816, action1_reward_count: 1581\n",
            "action2_reward: 1, action2_reward_avg: 0.5003162555344711, action2_reward_count: 1581\n",
            "Iteration 1582\n",
            "Chose Action 2: 0.49968374446552816 < 0.5003162555344711\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1582\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1582\n",
            "Iteration 1583\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996841440303222, action1_reward_count: 1583\n",
            "action2_reward: 1, action2_reward_avg: 0.5003158559696771, action2_reward_count: 1583\n",
            "Iteration 1584\n",
            "Chose Action 2: 0.4996841440303222 < 0.5003158559696771\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1584\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1584\n",
            "Iteration 1585\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968454258675077, action1_reward_count: 1585\n",
            "action2_reward: 1, action2_reward_avg: 0.5003154574132485, action2_reward_count: 1585\n",
            "Iteration 1586\n",
            "Chose Action 2: 0.49968454258675077 < 0.5003154574132485\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1586\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1586\n",
            "Iteration 1587\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49968494013862635, action1_reward_count: 1587\n",
            "action2_reward: 1, action2_reward_avg: 0.5003150598613729, action2_reward_count: 1587\n",
            "Iteration 1588\n",
            "Chose Action 2: 0.49968494013862635 < 0.5003150598613729\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1588\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1588\n",
            "Iteration 1589\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968533668974197, action1_reward_count: 1589\n",
            "action2_reward: 1, action2_reward_avg: 0.5003146633102573, action2_reward_count: 1589\n",
            "Iteration 1590\n",
            "Chose Action 2: 0.49968533668974197 < 0.5003146633102573\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1590\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1590\n",
            "Iteration 1591\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996857322438718, action1_reward_count: 1591\n",
            "action2_reward: 1, action2_reward_avg: 0.5003142677561275, action2_reward_count: 1591\n",
            "Iteration 1592\n",
            "Chose Action 2: 0.4996857322438718 < 0.5003142677561275\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1592\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1592\n",
            "Iteration 1593\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968612680477087, action1_reward_count: 1593\n",
            "action2_reward: 1, action2_reward_avg: 0.5003138731952285, action2_reward_count: 1593\n",
            "Iteration 1594\n",
            "Chose Action 2: 0.49968612680477087 < 0.5003138731952285\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1594\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1594\n",
            "Iteration 1595\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968652037617556, action1_reward_count: 1595\n",
            "action2_reward: 1, action2_reward_avg: 0.5003134796238238, action2_reward_count: 1595\n",
            "Iteration 1596\n",
            "Chose Action 2: 0.49968652037617556 < 0.5003134796238238\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1596\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1596\n",
            "Iteration 1597\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996869129618034, action1_reward_count: 1597\n",
            "action2_reward: 1, action2_reward_avg: 0.500313087038196, action2_reward_count: 1597\n",
            "Iteration 1598\n",
            "Chose Action 2: 0.4996869129618034 < 0.500313087038196\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1598\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1598\n",
            "Iteration 1599\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996873045653533, action1_reward_count: 1599\n",
            "action2_reward: 1, action2_reward_avg: 0.5003126954346461, action2_reward_count: 1599\n",
            "Iteration 1600\n",
            "Chose Action 2: 0.4996873045653533 < 0.5003126954346461\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1600\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1600\n",
            "Iteration 1601\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968769519050593, action1_reward_count: 1601\n",
            "action2_reward: 1, action2_reward_avg: 0.5003123048094934, action2_reward_count: 1601\n",
            "Iteration 1602\n",
            "Chose Action 2: 0.49968769519050593 < 0.5003123048094934\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1602\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1602\n",
            "Iteration 1603\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968808484092325, action1_reward_count: 1603\n",
            "action2_reward: 1, action2_reward_avg: 0.500311915159076, action2_reward_count: 1603\n",
            "Iteration 1604\n",
            "Chose Action 2: 0.49968808484092325 < 0.500311915159076\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1604\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1604\n",
            "Iteration 1605\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996884735202492, action1_reward_count: 1605\n",
            "action2_reward: 1, action2_reward_avg: 0.5003115264797501, action2_reward_count: 1605\n",
            "Iteration 1606\n",
            "Chose Action 2: 0.4996884735202492 < 0.5003115264797501\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1606\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1606\n",
            "Iteration 1607\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968886123210954, action1_reward_count: 1607\n",
            "action2_reward: 1, action2_reward_avg: 0.5003111387678898, action2_reward_count: 1607\n",
            "Iteration 1608\n",
            "Chose Action 2: 0.49968886123210954 < 0.5003111387678898\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1608\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1608\n",
            "Iteration 1609\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996892479801119, action1_reward_count: 1609\n",
            "action2_reward: 1, action2_reward_avg: 0.5003107520198875, action2_reward_count: 1609\n",
            "Iteration 1610\n",
            "Chose Action 2: 0.4996892479801119 < 0.5003107520198875\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1610\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1610\n",
            "Iteration 1611\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968963376784603, action1_reward_count: 1611\n",
            "action2_reward: 1, action2_reward_avg: 0.5003103662321533, action2_reward_count: 1611\n",
            "Iteration 1612\n",
            "Chose Action 2: 0.49968963376784603 < 0.5003103662321533\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1612\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1612\n",
            "Iteration 1613\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49969001859888407, action1_reward_count: 1613\n",
            "action2_reward: 1, action2_reward_avg: 0.5003099814011154, action2_reward_count: 1613\n",
            "Iteration 1614\n",
            "Chose Action 2: 0.49969001859888407 < 0.5003099814011154\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1614\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1614\n",
            "Iteration 1615\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996904024767802, action1_reward_count: 1615\n",
            "action2_reward: 1, action2_reward_avg: 0.5003095975232192, action2_reward_count: 1615\n",
            "Iteration 1616\n",
            "Chose Action 2: 0.4996904024767802 < 0.5003095975232192\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1616\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1616\n",
            "Iteration 1617\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996907854050711, action1_reward_count: 1617\n",
            "action2_reward: 1, action2_reward_avg: 0.5003092145949283, action2_reward_count: 1617\n",
            "Iteration 1618\n",
            "Chose Action 2: 0.4996907854050711 < 0.5003092145949283\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1618\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1618\n",
            "Iteration 1619\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996911673872761, action1_reward_count: 1619\n",
            "action2_reward: 1, action2_reward_avg: 0.5003088326127233, action2_reward_count: 1619\n",
            "Iteration 1620\n",
            "Chose Action 2: 0.4996911673872761 < 0.5003088326127233\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1620\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1620\n",
            "Iteration 1621\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499691548426897, action1_reward_count: 1621\n",
            "action2_reward: 1, action2_reward_avg: 0.5003084515731024, action2_reward_count: 1621\n",
            "Iteration 1622\n",
            "Chose Action 2: 0.499691548426897 < 0.5003084515731024\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1622\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1622\n",
            "Iteration 1623\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969192852741834, action1_reward_count: 1623\n",
            "action2_reward: 1, action2_reward_avg: 0.500308071472581, action2_reward_count: 1623\n",
            "Iteration 1624\n",
            "Chose Action 2: 0.49969192852741834 < 0.500308071472581\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1624\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1624\n",
            "Iteration 1625\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996923076923077, action1_reward_count: 1625\n",
            "action2_reward: 1, action2_reward_avg: 0.5003076923076917, action2_reward_count: 1625\n",
            "Iteration 1626\n",
            "Chose Action 2: 0.4996923076923077 < 0.5003076923076917\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1626\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1626\n",
            "Iteration 1627\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49969268592501537, action1_reward_count: 1627\n",
            "action2_reward: 1, action2_reward_avg: 0.5003073140749841, action2_reward_count: 1627\n",
            "Iteration 1628\n",
            "Chose Action 2: 0.49969268592501537 < 0.5003073140749841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1628\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1628\n",
            "Iteration 1629\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969306322897483, action1_reward_count: 1629\n",
            "action2_reward: 1, action2_reward_avg: 0.5003069367710247, action2_reward_count: 1629\n",
            "Iteration 1630\n",
            "Chose Action 2: 0.49969306322897483 < 0.5003069367710247\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1630\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1630\n",
            "Iteration 1631\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996934396076027, action1_reward_count: 1631\n",
            "action2_reward: 1, action2_reward_avg: 0.5003065603923968, action2_reward_count: 1631\n",
            "Iteration 1632\n",
            "Chose Action 2: 0.4996934396076027 < 0.5003065603923968\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1632\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1632\n",
            "Iteration 1633\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49969381506429883, action1_reward_count: 1633\n",
            "action2_reward: 1, action2_reward_avg: 0.5003061849357007, action2_reward_count: 1633\n",
            "Iteration 1634\n",
            "Chose Action 2: 0.49969381506429883 < 0.5003061849357007\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1634\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1634\n",
            "Iteration 1635\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996941896024465, action1_reward_count: 1635\n",
            "action2_reward: 1, action2_reward_avg: 0.5003058103975531, action2_reward_count: 1635\n",
            "Iteration 1636\n",
            "Chose Action 2: 0.4996941896024465 < 0.5003058103975531\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1636\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1636\n",
            "Iteration 1637\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49969456322541234, action1_reward_count: 1637\n",
            "action2_reward: 1, action2_reward_avg: 0.5003054367745872, action2_reward_count: 1637\n",
            "Iteration 1638\n",
            "Chose Action 2: 0.49969456322541234 < 0.5003054367745872\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1638\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1638\n",
            "Iteration 1639\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996949359365467, action1_reward_count: 1639\n",
            "action2_reward: 1, action2_reward_avg: 0.5003050640634529, action2_reward_count: 1639\n",
            "Iteration 1640\n",
            "Chose Action 2: 0.4996949359365467 < 0.5003050640634529\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1640\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1640\n",
            "Iteration 1641\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4996953077391834, action1_reward_count: 1641\n",
            "action2_reward: 1, action2_reward_avg: 0.5003046922608161, action2_reward_count: 1641\n",
            "Iteration 1642\n",
            "Chose Action 2: 0.4996953077391834 < 0.5003046922608161\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1642\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1642\n",
            "Iteration 1643\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996956786366403, action1_reward_count: 1643\n",
            "action2_reward: 1, action2_reward_avg: 0.5003043213633592, action2_reward_count: 1643\n",
            "Iteration 1644\n",
            "Chose Action 2: 0.4996956786366403 < 0.5003043213633592\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1644\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1644\n",
            "Iteration 1645\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49969604863221884, action1_reward_count: 1645\n",
            "action2_reward: 1, action2_reward_avg: 0.5003039513677806, action2_reward_count: 1645\n",
            "Iteration 1646\n",
            "Chose Action 2: 0.49969604863221884 < 0.5003039513677806\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1646\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1646\n",
            "Iteration 1647\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996964177292046, action1_reward_count: 1647\n",
            "action2_reward: 1, action2_reward_avg: 0.5003035822707949, action2_reward_count: 1647\n",
            "Iteration 1648\n",
            "Chose Action 2: 0.4996964177292046 < 0.5003035822707949\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1648\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1648\n",
            "Iteration 1649\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996967859308672, action1_reward_count: 1649\n",
            "action2_reward: 1, action2_reward_avg: 0.5003032140691323, action2_reward_count: 1649\n",
            "Iteration 1650\n",
            "Chose Action 2: 0.4996967859308672 < 0.5003032140691323\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1650\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1650\n",
            "Iteration 1651\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996971532404603, action1_reward_count: 1651\n",
            "action2_reward: 1, action2_reward_avg: 0.5003028467595391, action2_reward_count: 1651\n",
            "Iteration 1652\n",
            "Chose Action 2: 0.4996971532404603 < 0.5003028467595391\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1652\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1652\n",
            "Iteration 1653\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499697519661222, action1_reward_count: 1653\n",
            "action2_reward: 1, action2_reward_avg: 0.5003024803387773, action2_reward_count: 1653\n",
            "Iteration 1654\n",
            "Chose Action 2: 0.499697519661222 < 0.5003024803387773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1654\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1654\n",
            "Iteration 1655\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49969788519637465, action1_reward_count: 1655\n",
            "action2_reward: 1, action2_reward_avg: 0.5003021148036247, action2_reward_count: 1655\n",
            "Iteration 1656\n",
            "Chose Action 2: 0.49969788519637465 < 0.5003021148036247\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1656\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1656\n",
            "Iteration 1657\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996982498491249, action1_reward_count: 1657\n",
            "action2_reward: 1, action2_reward_avg: 0.5003017501508744, action2_reward_count: 1657\n",
            "Iteration 1658\n",
            "Chose Action 2: 0.4996982498491249 < 0.5003017501508744\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1658\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1658\n",
            "Iteration 1659\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49969861362266427, action1_reward_count: 1659\n",
            "action2_reward: 1, action2_reward_avg: 0.5003013863773351, action2_reward_count: 1659\n",
            "Iteration 1660\n",
            "Chose Action 2: 0.49969861362266427 < 0.5003013863773351\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1660\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1660\n",
            "Iteration 1661\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996989765201686, action1_reward_count: 1661\n",
            "action2_reward: 1, action2_reward_avg: 0.5003010234798309, action2_reward_count: 1661\n",
            "Iteration 1662\n",
            "Chose Action 2: 0.4996989765201686 < 0.5003010234798309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1662\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1662\n",
            "Iteration 1663\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969933854479853, action1_reward_count: 1663\n",
            "action2_reward: 1, action2_reward_avg: 0.5003006614552009, action2_reward_count: 1663\n",
            "Iteration 1664\n",
            "Chose Action 2: 0.49969933854479853 < 0.5003006614552009\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1664\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1664\n",
            "Iteration 1665\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996996996996997, action1_reward_count: 1665\n",
            "action2_reward: 1, action2_reward_avg: 0.5003003003002997, action2_reward_count: 1665\n",
            "Iteration 1666\n",
            "Chose Action 2: 0.4996996996996997 < 0.5003003003002997\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1666\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1666\n",
            "Iteration 1667\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997000599880024, action1_reward_count: 1667\n",
            "action2_reward: 1, action2_reward_avg: 0.500299940011997, action2_reward_count: 1667\n",
            "Iteration 1668\n",
            "Chose Action 2: 0.4997000599880024 < 0.500299940011997\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1668\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1668\n",
            "Iteration 1669\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970041941282206, action1_reward_count: 1669\n",
            "action2_reward: 1, action2_reward_avg: 0.5002995805871773, action2_reward_count: 1669\n",
            "Iteration 1670\n",
            "Chose Action 2: 0.49970041941282206 < 0.5002995805871773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1670\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1670\n",
            "Iteration 1671\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970077797725915, action1_reward_count: 1671\n",
            "action2_reward: 1, action2_reward_avg: 0.5002992220227402, action2_reward_count: 1671\n",
            "Iteration 1672\n",
            "Chose Action 2: 0.49970077797725915 < 0.5002992220227402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1672\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1672\n",
            "Iteration 1673\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997011356843993, action1_reward_count: 1673\n",
            "action2_reward: 1, action2_reward_avg: 0.5002988643156001, action2_reward_count: 1673\n",
            "Iteration 1674\n",
            "Chose Action 2: 0.4997011356843993 < 0.5002988643156001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1674\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1674\n",
            "Iteration 1675\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49970149253731344, action1_reward_count: 1675\n",
            "action2_reward: 1, action2_reward_avg: 0.500298507462686, action2_reward_count: 1675\n",
            "Iteration 1676\n",
            "Chose Action 2: 0.49970149253731344 < 0.500298507462686\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1676\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1676\n",
            "Iteration 1677\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970184853905786, action1_reward_count: 1677\n",
            "action2_reward: 1, action2_reward_avg: 0.5002981514609416, action2_reward_count: 1677\n",
            "Iteration 1678\n",
            "Chose Action 2: 0.49970184853905786 < 0.5002981514609416\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1678\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1678\n",
            "Iteration 1679\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997022036926742, action1_reward_count: 1679\n",
            "action2_reward: 1, action2_reward_avg: 0.5002977963073252, action2_reward_count: 1679\n",
            "Iteration 1680\n",
            "Chose Action 2: 0.4997022036926742 < 0.5002977963073252\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1680\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1680\n",
            "Iteration 1681\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997025580011898, action1_reward_count: 1681\n",
            "action2_reward: 1, action2_reward_avg: 0.5002974419988097, action2_reward_count: 1681\n",
            "Iteration 1682\n",
            "Chose Action 2: 0.4997025580011898 < 0.5002974419988097\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1682\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1682\n",
            "Iteration 1683\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970291146761736, action1_reward_count: 1683\n",
            "action2_reward: 1, action2_reward_avg: 0.5002970885323821, action2_reward_count: 1683\n",
            "Iteration 1684\n",
            "Chose Action 2: 0.49970291146761736 < 0.5002970885323821\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1684\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1684\n",
            "Iteration 1685\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970326409495547, action1_reward_count: 1685\n",
            "action2_reward: 1, action2_reward_avg: 0.500296735905044, action2_reward_count: 1685\n",
            "Iteration 1686\n",
            "Chose Action 2: 0.49970326409495547 < 0.500296735905044\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1686\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1686\n",
            "Iteration 1687\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997036158861885, action1_reward_count: 1687\n",
            "action2_reward: 1, action2_reward_avg: 0.5002963841138109, action2_reward_count: 1687\n",
            "Iteration 1688\n",
            "Chose Action 2: 0.4997036158861885 < 0.5002963841138109\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1688\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1688\n",
            "Iteration 1689\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997039668442866, action1_reward_count: 1689\n",
            "action2_reward: 1, action2_reward_avg: 0.5002960331557129, action2_reward_count: 1689\n",
            "Iteration 1690\n",
            "Chose Action 2: 0.4997039668442866 < 0.5002960331557129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1690\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1690\n",
            "Iteration 1691\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997043169722058, action1_reward_count: 1691\n",
            "action2_reward: 1, action2_reward_avg: 0.5002956830277937, action2_reward_count: 1691\n",
            "Iteration 1692\n",
            "Chose Action 2: 0.4997043169722058 < 0.5002956830277937\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1692\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1692\n",
            "Iteration 1693\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49970466627288834, action1_reward_count: 1693\n",
            "action2_reward: 1, action2_reward_avg: 0.5002953337271111, action2_reward_count: 1693\n",
            "Iteration 1694\n",
            "Chose Action 2: 0.49970466627288834 < 0.5002953337271111\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1694\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1694\n",
            "Iteration 1695\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970501474926254, action1_reward_count: 1695\n",
            "action2_reward: 1, action2_reward_avg: 0.5002949852507369, action2_reward_count: 1695\n",
            "Iteration 1696\n",
            "Chose Action 2: 0.49970501474926254 < 0.5002949852507369\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1696\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1696\n",
            "Iteration 1697\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997053624042428, action1_reward_count: 1697\n",
            "action2_reward: 1, action2_reward_avg: 0.5002946375957567, action2_reward_count: 1697\n",
            "Iteration 1698\n",
            "Chose Action 2: 0.4997053624042428 < 0.5002946375957567\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1698\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1698\n",
            "Iteration 1699\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997057092407298, action1_reward_count: 1699\n",
            "action2_reward: 1, action2_reward_avg: 0.5002942907592696, action2_reward_count: 1699\n",
            "Iteration 1700\n",
            "Chose Action 2: 0.4997057092407298 < 0.5002942907592696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1700\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1700\n",
            "Iteration 1701\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997060552616108, action1_reward_count: 1701\n",
            "action2_reward: 1, action2_reward_avg: 0.5002939447383886, action2_reward_count: 1701\n",
            "Iteration 1702\n",
            "Chose Action 2: 0.4997060552616108 < 0.5002939447383886\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1702\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1702\n",
            "Iteration 1703\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997064004697592, action1_reward_count: 1703\n",
            "action2_reward: 1, action2_reward_avg: 0.5002935995302402, action2_reward_count: 1703\n",
            "Iteration 1704\n",
            "Chose Action 2: 0.4997064004697592 < 0.5002935995302402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1704\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1704\n",
            "Iteration 1705\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997067448680352, action1_reward_count: 1705\n",
            "action2_reward: 1, action2_reward_avg: 0.5002932551319642, action2_reward_count: 1705\n",
            "Iteration 1706\n",
            "Chose Action 2: 0.4997067448680352 < 0.5002932551319642\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1706\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1706\n",
            "Iteration 1707\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997070884592853, action1_reward_count: 1707\n",
            "action2_reward: 1, action2_reward_avg: 0.5002929115407141, action2_reward_count: 1707\n",
            "Iteration 1708\n",
            "Chose Action 2: 0.4997070884592853 < 0.5002929115407141\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1708\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1708\n",
            "Iteration 1709\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49970743124634287, action1_reward_count: 1709\n",
            "action2_reward: 1, action2_reward_avg: 0.5002925687536565, action2_reward_count: 1709\n",
            "Iteration 1710\n",
            "Chose Action 2: 0.49970743124634287 < 0.5002925687536565\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1710\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1710\n",
            "Iteration 1711\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970777323202803, action1_reward_count: 1711\n",
            "action2_reward: 1, action2_reward_avg: 0.5002922267679712, action2_reward_count: 1711\n",
            "Iteration 1712\n",
            "Chose Action 2: 0.49970777323202803 < 0.5002922267679712\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1712\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1712\n",
            "Iteration 1713\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4997081144191477, action1_reward_count: 1713\n",
            "action2_reward: 1, action2_reward_avg: 0.5002918855808516, action2_reward_count: 1713\n",
            "Iteration 1714\n",
            "Chose Action 2: 0.4997081144191477 < 0.5002918855808516\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1714\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1714\n",
            "Iteration 1715\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49970845481049564, action1_reward_count: 1715\n",
            "action2_reward: 1, action2_reward_avg: 0.5002915451895037, action2_reward_count: 1715\n",
            "Iteration 1716\n",
            "Chose Action 2: 0.49970845481049564 < 0.5002915451895037\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1716\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1716\n",
            "Iteration 1717\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970879440885263, action1_reward_count: 1717\n",
            "action2_reward: 1, action2_reward_avg: 0.5002912055911467, action2_reward_count: 1717\n",
            "Iteration 1718\n",
            "Chose Action 2: 0.49970879440885263 < 0.5002912055911467\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1718\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1718\n",
            "Iteration 1719\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997091332169866, action1_reward_count: 1719\n",
            "action2_reward: 1, action2_reward_avg: 0.5002908667830127, action2_reward_count: 1719\n",
            "Iteration 1720\n",
            "Chose Action 2: 0.4997091332169866 < 0.5002908667830127\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1720\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1720\n",
            "Iteration 1721\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997094712376525, action1_reward_count: 1721\n",
            "action2_reward: 1, action2_reward_avg: 0.5002905287623468, action2_reward_count: 1721\n",
            "Iteration 1722\n",
            "Chose Action 2: 0.4997094712376525 < 0.5002905287623468\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1722\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1722\n",
            "Iteration 1723\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997098084735926, action1_reward_count: 1723\n",
            "action2_reward: 1, action2_reward_avg: 0.5002901915264067, action2_reward_count: 1723\n",
            "Iteration 1724\n",
            "Chose Action 2: 0.4997098084735926 < 0.5002901915264067\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1724\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1724\n",
            "Iteration 1725\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49971014492753624, action1_reward_count: 1725\n",
            "action2_reward: 1, action2_reward_avg: 0.5002898550724632, action2_reward_count: 1725\n",
            "Iteration 1726\n",
            "Chose Action 2: 0.49971014492753624 < 0.5002898550724632\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1726\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1726\n",
            "Iteration 1727\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971048060220036, action1_reward_count: 1727\n",
            "action2_reward: 1, action2_reward_avg: 0.5002895193977991, action2_reward_count: 1727\n",
            "Iteration 1728\n",
            "Chose Action 2: 0.49971048060220036 < 0.5002895193977991\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1728\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1728\n",
            "Iteration 1729\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997108155002892, action1_reward_count: 1729\n",
            "action2_reward: 1, action2_reward_avg: 0.5002891844997103, action2_reward_count: 1729\n",
            "Iteration 1730\n",
            "Chose Action 2: 0.4997108155002892 < 0.5002891844997103\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1730\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1730\n",
            "Iteration 1731\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49971114962449453, action1_reward_count: 1731\n",
            "action2_reward: 1, action2_reward_avg: 0.500288850375505, action2_reward_count: 1731\n",
            "Iteration 1732\n",
            "Chose Action 2: 0.49971114962449453 < 0.500288850375505\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1732\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1732\n",
            "Iteration 1733\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997114829774957, action1_reward_count: 1733\n",
            "action2_reward: 1, action2_reward_avg: 0.5002885170225039, action2_reward_count: 1733\n",
            "Iteration 1734\n",
            "Chose Action 2: 0.4997114829774957 < 0.5002885170225039\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1734\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1734\n",
            "Iteration 1735\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49971181556195965, action1_reward_count: 1735\n",
            "action2_reward: 1, action2_reward_avg: 0.5002881844380399, action2_reward_count: 1735\n",
            "Iteration 1736\n",
            "Chose Action 2: 0.49971181556195965 < 0.5002881844380399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1736\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1736\n",
            "Iteration 1737\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49971214738054115, action1_reward_count: 1737\n",
            "action2_reward: 1, action2_reward_avg: 0.5002878526194584, action2_reward_count: 1737\n",
            "Iteration 1738\n",
            "Chose Action 2: 0.49971214738054115 < 0.5002878526194584\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1738\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1738\n",
            "Iteration 1739\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997124784358827, action1_reward_count: 1739\n",
            "action2_reward: 1, action2_reward_avg: 0.5002875215641168, action2_reward_count: 1739\n",
            "Iteration 1740\n",
            "Chose Action 2: 0.4997124784358827 < 0.5002875215641168\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1740\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1740\n",
            "Iteration 1741\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997128087306146, action1_reward_count: 1741\n",
            "action2_reward: 1, action2_reward_avg: 0.5002871912693849, action2_reward_count: 1741\n",
            "Iteration 1742\n",
            "Chose Action 2: 0.4997128087306146 < 0.5002871912693849\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1742\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1742\n",
            "Iteration 1743\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49971313826735514, action1_reward_count: 1743\n",
            "action2_reward: 1, action2_reward_avg: 0.5002868617326444, action2_reward_count: 1743\n",
            "Iteration 1744\n",
            "Chose Action 2: 0.49971313826735514 < 0.5002868617326444\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1744\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1744\n",
            "Iteration 1745\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997134670487106, action1_reward_count: 1745\n",
            "action2_reward: 1, action2_reward_avg: 0.5002865329512889, action2_reward_count: 1745\n",
            "Iteration 1746\n",
            "Chose Action 2: 0.4997134670487106 < 0.5002865329512889\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1746\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1746\n",
            "Iteration 1747\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997137950772753, action1_reward_count: 1747\n",
            "action2_reward: 1, action2_reward_avg: 0.5002862049227241, action2_reward_count: 1747\n",
            "Iteration 1748\n",
            "Chose Action 2: 0.4997137950772753 < 0.5002862049227241\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1748\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1748\n",
            "Iteration 1749\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997141223556318, action1_reward_count: 1749\n",
            "action2_reward: 1, action2_reward_avg: 0.5002858776443676, action2_reward_count: 1749\n",
            "Iteration 1750\n",
            "Chose Action 2: 0.4997141223556318 < 0.5002858776443676\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1750\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1750\n",
            "Iteration 1751\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971444888635064, action1_reward_count: 1751\n",
            "action2_reward: 1, action2_reward_avg: 0.5002855511136487, action2_reward_count: 1751\n",
            "Iteration 1752\n",
            "Chose Action 2: 0.49971444888635064 < 0.5002855511136487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1752\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1752\n",
            "Iteration 1753\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997147746719909, action1_reward_count: 1753\n",
            "action2_reward: 1, action2_reward_avg: 0.5002852253280085, action2_reward_count: 1753\n",
            "Iteration 1754\n",
            "Chose Action 2: 0.4997147746719909 < 0.5002852253280085\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1754\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1754\n",
            "Iteration 1755\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997150997150997, action1_reward_count: 1755\n",
            "action2_reward: 1, action2_reward_avg: 0.5002849002848996, action2_reward_count: 1755\n",
            "Iteration 1756\n",
            "Chose Action 2: 0.4997150997150997 < 0.5002849002848996\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1756\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1756\n",
            "Iteration 1757\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971542401821284, action1_reward_count: 1757\n",
            "action2_reward: 1, action2_reward_avg: 0.5002845759817864, action2_reward_count: 1757\n",
            "Iteration 1758\n",
            "Chose Action 2: 0.49971542401821284 < 0.5002845759817864\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1758\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1758\n",
            "Iteration 1759\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971574758385445, action1_reward_count: 1759\n",
            "action2_reward: 1, action2_reward_avg: 0.5002842524161448, action2_reward_count: 1759\n",
            "Iteration 1760\n",
            "Chose Action 2: 0.49971574758385445 < 0.5002842524161448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1760\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1760\n",
            "Iteration 1761\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4997160704145372, action1_reward_count: 1761\n",
            "action2_reward: 1, action2_reward_avg: 0.5002839295854621, action2_reward_count: 1761\n",
            "Iteration 1762\n",
            "Chose Action 2: 0.4997160704145372 < 0.5002839295854621\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1762\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1762\n",
            "Iteration 1763\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971639251276234, action1_reward_count: 1763\n",
            "action2_reward: 1, action2_reward_avg: 0.500283607487237, action2_reward_count: 1763\n",
            "Iteration 1764\n",
            "Chose Action 2: 0.49971639251276234 < 0.500283607487237\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1764\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1764\n",
            "Iteration 1765\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49971671388101985, action1_reward_count: 1765\n",
            "action2_reward: 1, action2_reward_avg: 0.5002832861189795, action2_reward_count: 1765\n",
            "Iteration 1766\n",
            "Chose Action 2: 0.49971671388101985 < 0.5002832861189795\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1766\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1766\n",
            "Iteration 1767\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971703452178834, action1_reward_count: 1767\n",
            "action2_reward: 1, action2_reward_avg: 0.500282965478211, action2_reward_count: 1767\n",
            "Iteration 1768\n",
            "Chose Action 2: 0.49971703452178834 < 0.500282965478211\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1768\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1768\n",
            "Iteration 1769\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971735443753534, action1_reward_count: 1769\n",
            "action2_reward: 1, action2_reward_avg: 0.500282645562464, action2_reward_count: 1769\n",
            "Iteration 1770\n",
            "Chose Action 2: 0.49971735443753534 < 0.500282645562464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1770\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1770\n",
            "Iteration 1771\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997176736307171, action1_reward_count: 1771\n",
            "action2_reward: 1, action2_reward_avg: 0.5002823263692823, action2_reward_count: 1771\n",
            "Iteration 1772\n",
            "Chose Action 2: 0.4997176736307171 < 0.5002823263692823\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1772\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1772\n",
            "Iteration 1773\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971799210377893, action1_reward_count: 1773\n",
            "action2_reward: 1, action2_reward_avg: 0.5002820078962205, action2_reward_count: 1773\n",
            "Iteration 1774\n",
            "Chose Action 2: 0.49971799210377893 < 0.5002820078962205\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1774\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1774\n",
            "Iteration 1775\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971830985915494, action1_reward_count: 1775\n",
            "action2_reward: 1, action2_reward_avg: 0.5002816901408444, action2_reward_count: 1775\n",
            "Iteration 1776\n",
            "Chose Action 2: 0.49971830985915494 < 0.5002816901408444\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1776\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1776\n",
            "Iteration 1777\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971862689926844, action1_reward_count: 1777\n",
            "action2_reward: 1, action2_reward_avg: 0.500281373100731, action2_reward_count: 1777\n",
            "Iteration 1778\n",
            "Chose Action 2: 0.49971862689926844 < 0.500281373100731\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1778\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1778\n",
            "Iteration 1779\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971894322653176, action1_reward_count: 1779\n",
            "action2_reward: 1, action2_reward_avg: 0.5002810567734677, action2_reward_count: 1779\n",
            "Iteration 1780\n",
            "Chose Action 2: 0.49971894322653176 < 0.5002810567734677\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1780\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1780\n",
            "Iteration 1781\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49971925884334645, action1_reward_count: 1781\n",
            "action2_reward: 1, action2_reward_avg: 0.500280741156653, action2_reward_count: 1781\n",
            "Iteration 1782\n",
            "Chose Action 2: 0.49971925884334645 < 0.500280741156653\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1782\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1782\n",
            "Iteration 1783\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997195737521032, action1_reward_count: 1783\n",
            "action2_reward: 1, action2_reward_avg: 0.5002804262478963, action2_reward_count: 1783\n",
            "Iteration 1784\n",
            "Chose Action 2: 0.4997195737521032 < 0.5002804262478963\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1784\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1784\n",
            "Iteration 1785\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997198879551821, action1_reward_count: 1785\n",
            "action2_reward: 1, action2_reward_avg: 0.5002801120448174, action2_reward_count: 1785\n",
            "Iteration 1786\n",
            "Chose Action 2: 0.4997198879551821 < 0.5002801120448174\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1786\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1786\n",
            "Iteration 1787\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972020145495244, action1_reward_count: 1787\n",
            "action2_reward: 1, action2_reward_avg: 0.500279798545047, action2_reward_count: 1787\n",
            "Iteration 1788\n",
            "Chose Action 2: 0.49972020145495244 < 0.500279798545047\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1788\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1788\n",
            "Iteration 1789\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972051425377306, action1_reward_count: 1789\n",
            "action2_reward: 1, action2_reward_avg: 0.5002794857462264, action2_reward_count: 1789\n",
            "Iteration 1790\n",
            "Chose Action 2: 0.49972051425377306 < 0.5002794857462264\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1790\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1790\n",
            "Iteration 1791\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997208263539922, action1_reward_count: 1791\n",
            "action2_reward: 1, action2_reward_avg: 0.5002791736460073, action2_reward_count: 1791\n",
            "Iteration 1792\n",
            "Chose Action 2: 0.4997208263539922 < 0.5002791736460073\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1792\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1792\n",
            "Iteration 1793\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997211377579476, action1_reward_count: 1793\n",
            "action2_reward: 1, action2_reward_avg: 0.5002788622420519, action2_reward_count: 1793\n",
            "Iteration 1794\n",
            "Chose Action 2: 0.4997211377579476 < 0.5002788622420519\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1794\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1794\n",
            "Iteration 1795\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972144846796657, action1_reward_count: 1795\n",
            "action2_reward: 1, action2_reward_avg: 0.5002785515320328, action2_reward_count: 1795\n",
            "Iteration 1796\n",
            "Chose Action 2: 0.49972144846796657 < 0.5002785515320328\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1796\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1796\n",
            "Iteration 1797\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997217584863662, action1_reward_count: 1797\n",
            "action2_reward: 1, action2_reward_avg: 0.5002782415136332, action2_reward_count: 1797\n",
            "Iteration 1798\n",
            "Chose Action 2: 0.4997217584863662 < 0.5002782415136332\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1798\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1798\n",
            "Iteration 1799\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49972206781545303, action1_reward_count: 1799\n",
            "action2_reward: 1, action2_reward_avg: 0.5002779321845464, action2_reward_count: 1799\n",
            "Iteration 1800\n",
            "Chose Action 2: 0.49972206781545303 < 0.5002779321845464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1800\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1800\n",
            "Iteration 1801\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997223764575236, action1_reward_count: 1801\n",
            "action2_reward: 1, action2_reward_avg: 0.5002776235424758, action2_reward_count: 1801\n",
            "Iteration 1802\n",
            "Chose Action 2: 0.4997223764575236 < 0.5002776235424758\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1802\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1802\n",
            "Iteration 1803\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997226844148641, action1_reward_count: 1803\n",
            "action2_reward: 1, action2_reward_avg: 0.5002773155851353, action2_reward_count: 1803\n",
            "Iteration 1804\n",
            "Chose Action 2: 0.4997226844148641 < 0.5002773155851353\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1804\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1804\n",
            "Iteration 1805\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997229916897507, action1_reward_count: 1805\n",
            "action2_reward: 1, action2_reward_avg: 0.5002770083102488, action2_reward_count: 1805\n",
            "Iteration 1806\n",
            "Chose Action 2: 0.4997229916897507 < 0.5002770083102488\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1806\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1806\n",
            "Iteration 1807\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997232982844494, action1_reward_count: 1807\n",
            "action2_reward: 1, action2_reward_avg: 0.5002767017155502, action2_reward_count: 1807\n",
            "Iteration 1808\n",
            "Chose Action 2: 0.4997232982844494 < 0.5002767017155502\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1808\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1808\n",
            "Iteration 1809\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49972360420121614, action1_reward_count: 1809\n",
            "action2_reward: 1, action2_reward_avg: 0.5002763957987835, action2_reward_count: 1809\n",
            "Iteration 1810\n",
            "Chose Action 2: 0.49972360420121614 < 0.5002763957987835\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1810\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1810\n",
            "Iteration 1811\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49972390944229705, action1_reward_count: 1811\n",
            "action2_reward: 1, action2_reward_avg: 0.5002760905577025, action2_reward_count: 1811\n",
            "Iteration 1812\n",
            "Chose Action 2: 0.49972390944229705 < 0.5002760905577025\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1812\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1812\n",
            "Iteration 1813\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997242140099283, action1_reward_count: 1813\n",
            "action2_reward: 1, action2_reward_avg: 0.5002757859900713, action2_reward_count: 1813\n",
            "Iteration 1814\n",
            "Chose Action 2: 0.4997242140099283 < 0.5002757859900713\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1814\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1814\n",
            "Iteration 1815\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997245179063361, action1_reward_count: 1815\n",
            "action2_reward: 1, action2_reward_avg: 0.5002754820936635, action2_reward_count: 1815\n",
            "Iteration 1816\n",
            "Chose Action 2: 0.4997245179063361 < 0.5002754820936635\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1816\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1816\n",
            "Iteration 1817\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49972482113373695, action1_reward_count: 1817\n",
            "action2_reward: 1, action2_reward_avg: 0.5002751788662626, action2_reward_count: 1817\n",
            "Iteration 1818\n",
            "Chose Action 2: 0.49972482113373695 < 0.5002751788662626\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1818\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1818\n",
            "Iteration 1819\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997251236943375, action1_reward_count: 1819\n",
            "action2_reward: 1, action2_reward_avg: 0.500274876305662, action2_reward_count: 1819\n",
            "Iteration 1820\n",
            "Chose Action 2: 0.4997251236943375 < 0.500274876305662\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1820\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1820\n",
            "Iteration 1821\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.499725425590335, action1_reward_count: 1821\n",
            "action2_reward: 1, action2_reward_avg: 0.5002745744096646, action2_reward_count: 1821\n",
            "Iteration 1822\n",
            "Chose Action 2: 0.499725425590335 < 0.5002745744096646\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1822\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1822\n",
            "Iteration 1823\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49972572682391664, action1_reward_count: 1823\n",
            "action2_reward: 1, action2_reward_avg: 0.500274273176083, action2_reward_count: 1823\n",
            "Iteration 1824\n",
            "Chose Action 2: 0.49972572682391664 < 0.500274273176083\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1824\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1824\n",
            "Iteration 1825\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997260273972603, action1_reward_count: 1825\n",
            "action2_reward: 1, action2_reward_avg: 0.5002739726027393, action2_reward_count: 1825\n",
            "Iteration 1826\n",
            "Chose Action 2: 0.4997260273972603 < 0.5002739726027393\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1826\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1826\n",
            "Iteration 1827\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997263273125342, action1_reward_count: 1827\n",
            "action2_reward: 1, action2_reward_avg: 0.5002736726874654, action2_reward_count: 1827\n",
            "Iteration 1828\n",
            "Chose Action 2: 0.4997263273125342 < 0.5002736726874654\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1828\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1828\n",
            "Iteration 1829\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997266265718972, action1_reward_count: 1829\n",
            "action2_reward: 1, action2_reward_avg: 0.5002733734281023, action2_reward_count: 1829\n",
            "Iteration 1830\n",
            "Chose Action 2: 0.4997266265718972 < 0.5002733734281023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1830\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1830\n",
            "Iteration 1831\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997269251774986, action1_reward_count: 1831\n",
            "action2_reward: 1, action2_reward_avg: 0.5002730748225008, action2_reward_count: 1831\n",
            "Iteration 1832\n",
            "Chose Action 2: 0.4997269251774986 < 0.5002730748225008\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1832\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1832\n",
            "Iteration 1833\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972722313147844, action1_reward_count: 1833\n",
            "action2_reward: 1, action2_reward_avg: 0.500272776868521, action2_reward_count: 1833\n",
            "Iteration 1834\n",
            "Chose Action 2: 0.49972722313147844 < 0.500272776868521\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1834\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1834\n",
            "Iteration 1835\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997275204359673, action1_reward_count: 1835\n",
            "action2_reward: 1, action2_reward_avg: 0.5002724795640321, action2_reward_count: 1835\n",
            "Iteration 1836\n",
            "Chose Action 2: 0.4997275204359673 < 0.5002724795640321\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1836\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1836\n",
            "Iteration 1837\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49972781709308656, action1_reward_count: 1837\n",
            "action2_reward: 1, action2_reward_avg: 0.5002721829069129, action2_reward_count: 1837\n",
            "Iteration 1838\n",
            "Chose Action 2: 0.49972781709308656 < 0.5002721829069129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1838\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1838\n",
            "Iteration 1839\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972811310494836, action1_reward_count: 1839\n",
            "action2_reward: 1, action2_reward_avg: 0.5002718868950511, action2_reward_count: 1839\n",
            "Iteration 1840\n",
            "Chose Action 2: 0.49972811310494836 < 0.5002718868950511\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1840\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1840\n",
            "Iteration 1841\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997284084736556, action1_reward_count: 1841\n",
            "action2_reward: 1, action2_reward_avg: 0.5002715915263438, action2_reward_count: 1841\n",
            "Iteration 1842\n",
            "Chose Action 2: 0.4997284084736556 < 0.5002715915263438\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1842\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1842\n",
            "Iteration 1843\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972870320130225, action1_reward_count: 1843\n",
            "action2_reward: 1, action2_reward_avg: 0.5002712967986972, action2_reward_count: 1843\n",
            "Iteration 1844\n",
            "Chose Action 2: 0.49972870320130225 < 0.5002712967986972\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1844\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1844\n",
            "Iteration 1845\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997289972899729, action1_reward_count: 1845\n",
            "action2_reward: 1, action2_reward_avg: 0.5002710027100266, action2_reward_count: 1845\n",
            "Iteration 1846\n",
            "Chose Action 2: 0.4997289972899729 < 0.5002710027100266\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1846\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1846\n",
            "Iteration 1847\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997292907417434, action1_reward_count: 1847\n",
            "action2_reward: 1, action2_reward_avg: 0.5002707092582561, action2_reward_count: 1847\n",
            "Iteration 1848\n",
            "Chose Action 2: 0.4997292907417434 < 0.5002707092582561\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1848\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1848\n",
            "Iteration 1849\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49972958355868036, action1_reward_count: 1849\n",
            "action2_reward: 1, action2_reward_avg: 0.5002704164413191, action2_reward_count: 1849\n",
            "Iteration 1850\n",
            "Chose Action 2: 0.49972958355868036 < 0.5002704164413191\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1850\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1850\n",
            "Iteration 1851\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997298757428417, action1_reward_count: 1851\n",
            "action2_reward: 1, action2_reward_avg: 0.5002701242571578, action2_reward_count: 1851\n",
            "Iteration 1852\n",
            "Chose Action 2: 0.4997298757428417 < 0.5002701242571578\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1852\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1852\n",
            "Iteration 1853\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997301672962763, action1_reward_count: 1853\n",
            "action2_reward: 1, action2_reward_avg: 0.5002698327037232, action2_reward_count: 1853\n",
            "Iteration 1854\n",
            "Chose Action 2: 0.4997301672962763 < 0.5002698327037232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1854\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1854\n",
            "Iteration 1855\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973045822102424, action1_reward_count: 1855\n",
            "action2_reward: 1, action2_reward_avg: 0.5002695417789752, action2_reward_count: 1855\n",
            "Iteration 1856\n",
            "Chose Action 2: 0.49973045822102424 < 0.5002695417789752\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1856\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1856\n",
            "Iteration 1857\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973074851911686, action1_reward_count: 1857\n",
            "action2_reward: 1, action2_reward_avg: 0.5002692514808826, action2_reward_count: 1857\n",
            "Iteration 1858\n",
            "Chose Action 2: 0.49973074851911686 < 0.5002692514808826\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1858\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1858\n",
            "Iteration 1859\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973103819257664, action1_reward_count: 1859\n",
            "action2_reward: 1, action2_reward_avg: 0.5002689618074229, action2_reward_count: 1859\n",
            "Iteration 1860\n",
            "Chose Action 2: 0.49973103819257664 < 0.5002689618074229\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1860\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1860\n",
            "Iteration 1861\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997313272434175, action1_reward_count: 1861\n",
            "action2_reward: 1, action2_reward_avg: 0.5002686727565819, action2_reward_count: 1861\n",
            "Iteration 1862\n",
            "Chose Action 2: 0.4997313272434175 < 0.5002686727565819\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1862\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1862\n",
            "Iteration 1863\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973161567364466, action1_reward_count: 1863\n",
            "action2_reward: 1, action2_reward_avg: 0.5002683843263548, action2_reward_count: 1863\n",
            "Iteration 1864\n",
            "Chose Action 2: 0.49973161567364466 < 0.5002683843263548\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1864\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1864\n",
            "Iteration 1865\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997319034852547, action1_reward_count: 1865\n",
            "action2_reward: 1, action2_reward_avg: 0.5002680965147448, action2_reward_count: 1865\n",
            "Iteration 1866\n",
            "Chose Action 2: 0.4997319034852547 < 0.5002680965147448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1866\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1866\n",
            "Iteration 1867\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973219068023567, action1_reward_count: 1867\n",
            "action2_reward: 1, action2_reward_avg: 0.5002678093197638, action2_reward_count: 1867\n",
            "Iteration 1868\n",
            "Chose Action 2: 0.49973219068023567 < 0.5002678093197638\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1868\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1868\n",
            "Iteration 1869\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973247726056713, action1_reward_count: 1869\n",
            "action2_reward: 1, action2_reward_avg: 0.5002675227394323, action2_reward_count: 1869\n",
            "Iteration 1870\n",
            "Chose Action 2: 0.49973247726056713 < 0.5002675227394323\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1870\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1870\n",
            "Iteration 1871\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997327632282202, action1_reward_count: 1871\n",
            "action2_reward: 1, action2_reward_avg: 0.5002672367717792, action2_reward_count: 1871\n",
            "Iteration 1872\n",
            "Chose Action 2: 0.4997327632282202 < 0.5002672367717792\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1872\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1872\n",
            "Iteration 1873\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997330485851575, action1_reward_count: 1873\n",
            "action2_reward: 1, action2_reward_avg: 0.5002669514148419, action2_reward_count: 1873\n",
            "Iteration 1874\n",
            "Chose Action 2: 0.4997330485851575 < 0.5002669514148419\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1874\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1874\n",
            "Iteration 1875\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997333333333333, action1_reward_count: 1875\n",
            "action2_reward: 1, action2_reward_avg: 0.5002666666666661, action2_reward_count: 1875\n",
            "Iteration 1876\n",
            "Chose Action 2: 0.4997333333333333 < 0.5002666666666661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1876\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1876\n",
            "Iteration 1877\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973361747469364, action1_reward_count: 1877\n",
            "action2_reward: 1, action2_reward_avg: 0.5002663825253058, action2_reward_count: 1877\n",
            "Iteration 1878\n",
            "Chose Action 2: 0.49973361747469364 < 0.5002663825253058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1878\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1878\n",
            "Iteration 1879\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973390101117615, action1_reward_count: 1879\n",
            "action2_reward: 1, action2_reward_avg: 0.5002660989888232, action2_reward_count: 1879\n",
            "Iteration 1880\n",
            "Chose Action 2: 0.49973390101117615 < 0.5002660989888232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1880\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1880\n",
            "Iteration 1881\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973418394471025, action1_reward_count: 1881\n",
            "action2_reward: 1, action2_reward_avg: 0.5002658160552891, action2_reward_count: 1881\n",
            "Iteration 1882\n",
            "Chose Action 2: 0.49973418394471025 < 0.5002658160552891\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1882\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1882\n",
            "Iteration 1883\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997344662772172, action1_reward_count: 1883\n",
            "action2_reward: 1, action2_reward_avg: 0.5002655337227822, action2_reward_count: 1883\n",
            "Iteration 1884\n",
            "Chose Action 2: 0.4997344662772172 < 0.5002655337227822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1884\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1884\n",
            "Iteration 1885\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997347480106101, action1_reward_count: 1885\n",
            "action2_reward: 1, action2_reward_avg: 0.5002652519893892, action2_reward_count: 1885\n",
            "Iteration 1886\n",
            "Chose Action 2: 0.4997347480106101 < 0.5002652519893892\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1886\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1886\n",
            "Iteration 1887\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49973502914679385, action1_reward_count: 1887\n",
            "action2_reward: 1, action2_reward_avg: 0.5002649708532054, action2_reward_count: 1887\n",
            "Iteration 1888\n",
            "Chose Action 2: 0.49973502914679385 < 0.5002649708532054\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1888\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1888\n",
            "Iteration 1889\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49973530968766544, action1_reward_count: 1889\n",
            "action2_reward: 1, action2_reward_avg: 0.5002646903123339, action2_reward_count: 1889\n",
            "Iteration 1890\n",
            "Chose Action 2: 0.49973530968766544 < 0.5002646903123339\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1890\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1890\n",
            "Iteration 1891\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997355896351137, action1_reward_count: 1891\n",
            "action2_reward: 1, action2_reward_avg: 0.5002644103648857, action2_reward_count: 1891\n",
            "Iteration 1892\n",
            "Chose Action 2: 0.4997355896351137 < 0.5002644103648857\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1892\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1892\n",
            "Iteration 1893\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973586899101957, action1_reward_count: 1893\n",
            "action2_reward: 1, action2_reward_avg: 0.5002641310089798, action2_reward_count: 1893\n",
            "Iteration 1894\n",
            "Chose Action 2: 0.49973586899101957 < 0.5002641310089798\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1894\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1894\n",
            "Iteration 1895\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973614775725594, action1_reward_count: 1895\n",
            "action2_reward: 1, action2_reward_avg: 0.5002638522427435, action2_reward_count: 1895\n",
            "Iteration 1896\n",
            "Chose Action 2: 0.49973614775725594 < 0.5002638522427435\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1896\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1896\n",
            "Iteration 1897\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973642593568796, action1_reward_count: 1897\n",
            "action2_reward: 1, action2_reward_avg: 0.5002635740643115, action2_reward_count: 1897\n",
            "Iteration 1898\n",
            "Chose Action 2: 0.49973642593568796 < 0.5002635740643115\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1898\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1898\n",
            "Iteration 1899\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973670352817273, action1_reward_count: 1899\n",
            "action2_reward: 1, action2_reward_avg: 0.5002632964718268, action2_reward_count: 1899\n",
            "Iteration 1900\n",
            "Chose Action 2: 0.49973670352817273 < 0.5002632964718268\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1900\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1900\n",
            "Iteration 1901\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997369805365597, action1_reward_count: 1901\n",
            "action2_reward: 1, action2_reward_avg: 0.5002630194634398, action2_reward_count: 1901\n",
            "Iteration 1902\n",
            "Chose Action 2: 0.4997369805365597 < 0.5002630194634398\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1902\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1902\n",
            "Iteration 1903\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997372569626905, action1_reward_count: 1903\n",
            "action2_reward: 1, action2_reward_avg: 0.500262743037309, action2_reward_count: 1903\n",
            "Iteration 1904\n",
            "Chose Action 2: 0.4997372569626905 < 0.500262743037309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1904\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1904\n",
            "Iteration 1905\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973753280839894, action1_reward_count: 1905\n",
            "action2_reward: 1, action2_reward_avg: 0.5002624671916005, action2_reward_count: 1905\n",
            "Iteration 1906\n",
            "Chose Action 2: 0.49973753280839894 < 0.5002624671916005\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1906\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1906\n",
            "Iteration 1907\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973780807551127, action1_reward_count: 1907\n",
            "action2_reward: 1, action2_reward_avg: 0.5002621919244882, action2_reward_count: 1907\n",
            "Iteration 1908\n",
            "Chose Action 2: 0.49973780807551127 < 0.5002621919244882\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1908\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1908\n",
            "Iteration 1909\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973808276584597, action1_reward_count: 1909\n",
            "action2_reward: 1, action2_reward_avg: 0.5002619172341535, action2_reward_count: 1909\n",
            "Iteration 1910\n",
            "Chose Action 2: 0.49973808276584597 < 0.5002619172341535\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1910\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1910\n",
            "Iteration 1911\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973835688121404, action1_reward_count: 1911\n",
            "action2_reward: 1, action2_reward_avg: 0.5002616431187854, action2_reward_count: 1911\n",
            "Iteration 1912\n",
            "Chose Action 2: 0.49973835688121404 < 0.5002616431187854\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1912\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1912\n",
            "Iteration 1913\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997386304234187, action1_reward_count: 1913\n",
            "action2_reward: 1, action2_reward_avg: 0.5002613695765807, action2_reward_count: 1913\n",
            "Iteration 1914\n",
            "Chose Action 2: 0.4997386304234187 < 0.5002613695765807\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1914\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1914\n",
            "Iteration 1915\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973890339425586, action1_reward_count: 1915\n",
            "action2_reward: 1, action2_reward_avg: 0.5002610966057436, action2_reward_count: 1915\n",
            "Iteration 1916\n",
            "Chose Action 2: 0.49973890339425586 < 0.5002610966057436\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1916\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1916\n",
            "Iteration 1917\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997391757955138, action1_reward_count: 1917\n",
            "action2_reward: 1, action2_reward_avg: 0.5002608242044856, action2_reward_count: 1917\n",
            "Iteration 1918\n",
            "Chose Action 2: 0.4997391757955138 < 0.5002608242044856\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1918\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1918\n",
            "Iteration 1919\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973944762897343, action1_reward_count: 1919\n",
            "action2_reward: 1, action2_reward_avg: 0.500260552371026, action2_reward_count: 1919\n",
            "Iteration 1920\n",
            "Chose Action 2: 0.49973944762897343 < 0.500260552371026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1920\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1920\n",
            "Iteration 1921\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997397188964081, action1_reward_count: 1921\n",
            "action2_reward: 1, action2_reward_avg: 0.5002602811035912, action2_reward_count: 1921\n",
            "Iteration 1922\n",
            "Chose Action 2: 0.4997397188964081 < 0.5002602811035912\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1922\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1922\n",
            "Iteration 1923\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.499739989599584, action1_reward_count: 1923\n",
            "action2_reward: 1, action2_reward_avg: 0.5002600104004153, action2_reward_count: 1923\n",
            "Iteration 1924\n",
            "Chose Action 2: 0.499739989599584 < 0.5002600104004153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1924\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1924\n",
            "Iteration 1925\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49974025974025976, action1_reward_count: 1925\n",
            "action2_reward: 1, action2_reward_avg: 0.5002597402597396, action2_reward_count: 1925\n",
            "Iteration 1926\n",
            "Chose Action 2: 0.49974025974025976 < 0.5002597402597396\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1926\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1926\n",
            "Iteration 1927\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997405293201868, action1_reward_count: 1927\n",
            "action2_reward: 1, action2_reward_avg: 0.5002594706798126, action2_reward_count: 1927\n",
            "Iteration 1928\n",
            "Chose Action 2: 0.4997405293201868 < 0.5002594706798126\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1928\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1928\n",
            "Iteration 1929\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997407983411094, action1_reward_count: 1929\n",
            "action2_reward: 1, action2_reward_avg: 0.50025920165889, action2_reward_count: 1929\n",
            "Iteration 1930\n",
            "Chose Action 2: 0.4997407983411094 < 0.50025920165889\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1930\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1930\n",
            "Iteration 1931\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997410668047644, action1_reward_count: 1931\n",
            "action2_reward: 1, action2_reward_avg: 0.5002589331952351, action2_reward_count: 1931\n",
            "Iteration 1932\n",
            "Chose Action 2: 0.4997410668047644 < 0.5002589331952351\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1932\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1932\n",
            "Iteration 1933\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997413347128815, action1_reward_count: 1933\n",
            "action2_reward: 1, action2_reward_avg: 0.5002586652871179, action2_reward_count: 1933\n",
            "Iteration 1934\n",
            "Chose Action 2: 0.4997413347128815 < 0.5002586652871179\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1934\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1934\n",
            "Iteration 1935\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997416020671835, action1_reward_count: 1935\n",
            "action2_reward: 1, action2_reward_avg: 0.500258397932816, action2_reward_count: 1935\n",
            "Iteration 1936\n",
            "Chose Action 2: 0.4997416020671835 < 0.500258397932816\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1936\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1936\n",
            "Iteration 1937\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974186886938565, action1_reward_count: 1937\n",
            "action2_reward: 1, action2_reward_avg: 0.5002581311306139, action2_reward_count: 1937\n",
            "Iteration 1938\n",
            "Chose Action 2: 0.49974186886938565 < 0.5002581311306139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1938\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1938\n",
            "Iteration 1939\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997421351211965, action1_reward_count: 1939\n",
            "action2_reward: 1, action2_reward_avg: 0.5002578648788031, action2_reward_count: 1939\n",
            "Iteration 1940\n",
            "Chose Action 2: 0.4997421351211965 < 0.5002578648788031\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1940\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1940\n",
            "Iteration 1941\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974240082431737, action1_reward_count: 1941\n",
            "action2_reward: 1, action2_reward_avg: 0.5002575991756822, action2_reward_count: 1941\n",
            "Iteration 1942\n",
            "Chose Action 2: 0.49974240082431737 < 0.5002575991756822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1942\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1942\n",
            "Iteration 1943\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997426659804426, action1_reward_count: 1943\n",
            "action2_reward: 1, action2_reward_avg: 0.500257334019557, action2_reward_count: 1943\n",
            "Iteration 1944\n",
            "Chose Action 2: 0.4997426659804426 < 0.500257334019557\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1944\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1944\n",
            "Iteration 1945\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997429305912596, action1_reward_count: 1945\n",
            "action2_reward: 1, action2_reward_avg: 0.5002570694087399, action2_reward_count: 1945\n",
            "Iteration 1946\n",
            "Chose Action 2: 0.4997429305912596 < 0.5002570694087399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1946\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1946\n",
            "Iteration 1947\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997431946584489, action1_reward_count: 1947\n",
            "action2_reward: 1, action2_reward_avg: 0.5002568053415507, action2_reward_count: 1947\n",
            "Iteration 1948\n",
            "Chose Action 2: 0.4997431946584489 < 0.5002568053415507\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1948\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1948\n",
            "Iteration 1949\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974345818368393, action1_reward_count: 1949\n",
            "action2_reward: 1, action2_reward_avg: 0.5002565418163156, action2_reward_count: 1949\n",
            "Iteration 1950\n",
            "Chose Action 2: 0.49974345818368393 < 0.5002565418163156\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1950\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1950\n",
            "Iteration 1951\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974372116863147, action1_reward_count: 1951\n",
            "action2_reward: 1, action2_reward_avg: 0.5002562788313681, action2_reward_count: 1951\n",
            "Iteration 1952\n",
            "Chose Action 2: 0.49974372116863147 < 0.5002562788313681\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1952\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1952\n",
            "Iteration 1953\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974398361495137, action1_reward_count: 1953\n",
            "action2_reward: 1, action2_reward_avg: 0.5002560163850482, action2_reward_count: 1953\n",
            "Iteration 1954\n",
            "Chose Action 2: 0.49974398361495137 < 0.5002560163850482\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1954\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1954\n",
            "Iteration 1955\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997442455242967, action1_reward_count: 1955\n",
            "action2_reward: 1, action2_reward_avg: 0.5002557544757029, action2_reward_count: 1955\n",
            "Iteration 1956\n",
            "Chose Action 2: 0.4997442455242967 < 0.5002557544757029\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1956\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1956\n",
            "Iteration 1957\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974450689831373, action1_reward_count: 1957\n",
            "action2_reward: 1, action2_reward_avg: 0.5002554931016858, action2_reward_count: 1957\n",
            "Iteration 1958\n",
            "Chose Action 2: 0.49974450689831373 < 0.5002554931016858\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1958\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1958\n",
            "Iteration 1959\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997447677386422, action1_reward_count: 1959\n",
            "action2_reward: 1, action2_reward_avg: 0.5002552322613574, action2_reward_count: 1959\n",
            "Iteration 1960\n",
            "Chose Action 2: 0.4997447677386422 < 0.5002552322613574\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1960\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1960\n",
            "Iteration 1961\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974502804691484, action1_reward_count: 1961\n",
            "action2_reward: 1, action2_reward_avg: 0.5002549719530848, action2_reward_count: 1961\n",
            "Iteration 1962\n",
            "Chose Action 2: 0.49974502804691484 < 0.5002549719530848\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1962\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1962\n",
            "Iteration 1963\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.499745287824758, action1_reward_count: 1963\n",
            "action2_reward: 1, action2_reward_avg: 0.5002547121752415, action2_reward_count: 1963\n",
            "Iteration 1964\n",
            "Chose Action 2: 0.499745287824758 < 0.5002547121752415\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1964\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1964\n",
            "Iteration 1965\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997455470737914, action1_reward_count: 1965\n",
            "action2_reward: 1, action2_reward_avg: 0.5002544529262082, action2_reward_count: 1965\n",
            "Iteration 1966\n",
            "Chose Action 2: 0.4997455470737914 < 0.5002544529262082\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1966\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1966\n",
            "Iteration 1967\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997458057956279, action1_reward_count: 1967\n",
            "action2_reward: 1, action2_reward_avg: 0.5002541942043717, action2_reward_count: 1967\n",
            "Iteration 1968\n",
            "Chose Action 2: 0.4997458057956279 < 0.5002541942043717\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1968\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1968\n",
            "Iteration 1969\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974606399187405, action1_reward_count: 1969\n",
            "action2_reward: 1, action2_reward_avg: 0.5002539360081255, action2_reward_count: 1969\n",
            "Iteration 1970\n",
            "Chose Action 2: 0.49974606399187405 < 0.5002539360081255\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1970\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1970\n",
            "Iteration 1971\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997463216641299, action1_reward_count: 1971\n",
            "action2_reward: 1, action2_reward_avg: 0.5002536783358696, action2_reward_count: 1971\n",
            "Iteration 1972\n",
            "Chose Action 2: 0.4997463216641299 < 0.5002536783358696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1972\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1972\n",
            "Iteration 1973\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997465788139889, action1_reward_count: 1973\n",
            "action2_reward: 1, action2_reward_avg: 0.5002534211860107, action2_reward_count: 1973\n",
            "Iteration 1974\n",
            "Chose Action 2: 0.4997465788139889 < 0.5002534211860107\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1974\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1974\n",
            "Iteration 1975\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.499746835443038, action1_reward_count: 1975\n",
            "action2_reward: 1, action2_reward_avg: 0.5002531645569616, action2_reward_count: 1975\n",
            "Iteration 1976\n",
            "Chose Action 2: 0.499746835443038 < 0.5002531645569616\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1976\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1976\n",
            "Iteration 1977\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974709155285785, action1_reward_count: 1977\n",
            "action2_reward: 1, action2_reward_avg: 0.5002529084471417, action2_reward_count: 1977\n",
            "Iteration 1978\n",
            "Chose Action 2: 0.49974709155285785 < 0.5002529084471417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1978\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1978\n",
            "Iteration 1979\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997473471450227, action1_reward_count: 1979\n",
            "action2_reward: 1, action2_reward_avg: 0.5002526528549768, action2_reward_count: 1979\n",
            "Iteration 1980\n",
            "Chose Action 2: 0.4997473471450227 < 0.5002526528549768\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1980\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1980\n",
            "Iteration 1981\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974760222110043, action1_reward_count: 1981\n",
            "action2_reward: 1, action2_reward_avg: 0.5002523977788991, action2_reward_count: 1981\n",
            "Iteration 1982\n",
            "Chose Action 2: 0.49974760222110043 < 0.5002523977788991\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1982\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1982\n",
            "Iteration 1983\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974785678265254, action1_reward_count: 1983\n",
            "action2_reward: 1, action2_reward_avg: 0.5002521432173469, action2_reward_count: 1983\n",
            "Iteration 1984\n",
            "Chose Action 2: 0.49974785678265254 < 0.5002521432173469\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1984\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1984\n",
            "Iteration 1985\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974811083123427, action1_reward_count: 1985\n",
            "action2_reward: 1, action2_reward_avg: 0.5002518891687652, action2_reward_count: 1985\n",
            "Iteration 1986\n",
            "Chose Action 2: 0.49974811083123427 < 0.5002518891687652\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1986\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1986\n",
            "Iteration 1987\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974836436839454, action1_reward_count: 1987\n",
            "action2_reward: 1, action2_reward_avg: 0.5002516356316049, action2_reward_count: 1987\n",
            "Iteration 1988\n",
            "Chose Action 2: 0.49974836436839454 < 0.5002516356316049\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1988\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1988\n",
            "Iteration 1989\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997486173956762, action1_reward_count: 1989\n",
            "action2_reward: 1, action2_reward_avg: 0.5002513826043232, action2_reward_count: 1989\n",
            "Iteration 1990\n",
            "Chose Action 2: 0.4997486173956762 < 0.5002513826043232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1990\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1990\n",
            "Iteration 1991\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974886991461576, action1_reward_count: 1991\n",
            "action2_reward: 1, action2_reward_avg: 0.5002511300853837, action2_reward_count: 1991\n",
            "Iteration 1992\n",
            "Chose Action 2: 0.49974886991461576 < 0.5002511300853837\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1992\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1992\n",
            "Iteration 1993\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997491219267436, action1_reward_count: 1993\n",
            "action2_reward: 1, action2_reward_avg: 0.5002508780732559, action2_reward_count: 1993\n",
            "Iteration 1994\n",
            "Chose Action 2: 0.4997491219267436 < 0.5002508780732559\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1994\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1994\n",
            "Iteration 1995\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974937343358394, action1_reward_count: 1995\n",
            "action2_reward: 1, action2_reward_avg: 0.5002506265664155, action2_reward_count: 1995\n",
            "Iteration 1996\n",
            "Chose Action 2: 0.49974937343358394 < 0.5002506265664155\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1996\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1996\n",
            "Iteration 1997\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.499749624436655, action1_reward_count: 1997\n",
            "action2_reward: 1, action2_reward_avg: 0.5002503755633445, action2_reward_count: 1997\n",
            "Iteration 1998\n",
            "Chose Action 2: 0.499749624436655 < 0.5002503755633445\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1998\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1998\n",
            "Iteration 1999\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974987493746875, action1_reward_count: 1999\n",
            "action2_reward: 1, action2_reward_avg: 0.5002501250625307, action2_reward_count: 1999\n",
            "Iteration 2000\n",
            "Chose Action 2: 0.49974987493746875 < 0.5002501250625307\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 2000\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now consider a task with success probabilities 0.8 and 0.9, corresponding to point B in the upper-right difficult quadrant of Figure 2.2. In this case both actions produce success almost all the time. Any method that takes success as an indication of correctness can easily become stuck selecting the wrong action.\n",
        "\n",
        "Sutton, Richard S.; Barto, Andrew G.. Reinforcement Learning (Adaptive Computation and Machine Learning series) (Kindle Locations 797-808). MIT Press. Kindle Edition. "
      ],
      "metadata": {
        "id": "dk55zBZTY2a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation of Upper Right Quadrant (Quadrant I)\n",
        "population = [0, 1]\n",
        "action1_weights = [0.2, 0.8]\n",
        "action2_weights = [0.1, 0.9]\n",
        "binaryBanditSimulation(action1_weights,action2_weights,population,2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY5edHtuYmyo",
        "outputId": "b2b56882-98d0-4f62-e087-b9f60ca3d786"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 751\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993342210386152, action1_reward_count: 751\n",
            "action2_reward: 1, action2_reward_avg: 0.5006657789613849, action2_reward_count: 751\n",
            "Iteration 752\n",
            "Chose Action 2: 0.4993342210386152 < 0.5006657789613849\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 752\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 752\n",
            "Iteration 753\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933598937583, action1_reward_count: 753\n",
            "action2_reward: 1, action2_reward_avg: 0.50066401062417, action2_reward_count: 753\n",
            "Iteration 754\n",
            "Chose Action 2: 0.49933598937583 < 0.50066401062417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 754\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 754\n",
            "Iteration 755\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933774834437084, action1_reward_count: 755\n",
            "action2_reward: 1, action2_reward_avg: 0.5006622516556292, action2_reward_count: 755\n",
            "Iteration 756\n",
            "Chose Action 2: 0.49933774834437084 < 0.5006622516556292\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 756\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 756\n",
            "Iteration 757\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49933949801849403, action1_reward_count: 757\n",
            "action2_reward: 1, action2_reward_avg: 0.5006605019815059, action2_reward_count: 757\n",
            "Iteration 758\n",
            "Chose Action 2: 0.49933949801849403 < 0.5006605019815059\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 758\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 758\n",
            "Iteration 759\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993412384716733, action1_reward_count: 759\n",
            "action2_reward: 1, action2_reward_avg: 0.5006587615283267, action2_reward_count: 759\n",
            "Iteration 760\n",
            "Chose Action 2: 0.4993412384716733 < 0.5006587615283267\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 760\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 760\n",
            "Iteration 761\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49934296977660975, action1_reward_count: 761\n",
            "action2_reward: 1, action2_reward_avg: 0.5006570302233903, action2_reward_count: 761\n",
            "Iteration 762\n",
            "Chose Action 2: 0.49934296977660975 < 0.5006570302233903\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 762\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 762\n",
            "Iteration 763\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934469200524245, action1_reward_count: 763\n",
            "action2_reward: 1, action2_reward_avg: 0.5006553079947575, action2_reward_count: 763\n",
            "Iteration 764\n",
            "Chose Action 2: 0.49934469200524245 < 0.5006553079947575\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 764\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 764\n",
            "Iteration 765\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993464052287582, action1_reward_count: 765\n",
            "action2_reward: 1, action2_reward_avg: 0.5006535947712418, action2_reward_count: 765\n",
            "Iteration 766\n",
            "Chose Action 2: 0.4993464052287582 < 0.5006535947712418\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 766\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 766\n",
            "Iteration 767\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934810951760106, action1_reward_count: 767\n",
            "action2_reward: 1, action2_reward_avg: 0.500651890482399, action2_reward_count: 767\n",
            "Iteration 768\n",
            "Chose Action 2: 0.49934810951760106 < 0.500651890482399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 768\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 768\n",
            "Iteration 769\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49934980494148246, action1_reward_count: 769\n",
            "action2_reward: 1, action2_reward_avg: 0.5006501950585176, action2_reward_count: 769\n",
            "Iteration 770\n",
            "Chose Action 2: 0.49934980494148246 < 0.5006501950585176\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 770\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 770\n",
            "Iteration 771\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993514915693904, action1_reward_count: 771\n",
            "action2_reward: 1, action2_reward_avg: 0.5006485084306096, action2_reward_count: 771\n",
            "Iteration 772\n",
            "Chose Action 2: 0.4993514915693904 < 0.5006485084306096\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 772\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 772\n",
            "Iteration 773\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49935316946959896, action1_reward_count: 773\n",
            "action2_reward: 1, action2_reward_avg: 0.500646830530401, action2_reward_count: 773\n",
            "Iteration 774\n",
            "Chose Action 2: 0.49935316946959896 < 0.500646830530401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 774\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 774\n",
            "Iteration 775\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993548387096774, action1_reward_count: 775\n",
            "action2_reward: 1, action2_reward_avg: 0.5006451612903225, action2_reward_count: 775\n",
            "Iteration 776\n",
            "Chose Action 2: 0.4993548387096774 < 0.5006451612903225\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 776\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 776\n",
            "Iteration 777\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49935649935649934, action1_reward_count: 777\n",
            "action2_reward: 1, action2_reward_avg: 0.5006435006435006, action2_reward_count: 777\n",
            "Iteration 778\n",
            "Chose Action 2: 0.49935649935649934 < 0.5006435006435006\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 778\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 778\n",
            "Iteration 779\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993581514762516, action1_reward_count: 779\n",
            "action2_reward: 1, action2_reward_avg: 0.5006418485237484, action2_reward_count: 779\n",
            "Iteration 780\n",
            "Chose Action 2: 0.4993581514762516 < 0.5006418485237484\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 780\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 780\n",
            "Iteration 781\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499359795134443, action1_reward_count: 781\n",
            "action2_reward: 1, action2_reward_avg: 0.5006402048655569, action2_reward_count: 781\n",
            "Iteration 782\n",
            "Chose Action 2: 0.499359795134443 < 0.5006402048655569\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 782\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 782\n",
            "Iteration 783\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936143039591313, action1_reward_count: 783\n",
            "action2_reward: 1, action2_reward_avg: 0.5006385696040868, action2_reward_count: 783\n",
            "Iteration 784\n",
            "Chose Action 2: 0.49936143039591313 < 0.5006385696040868\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 784\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 784\n",
            "Iteration 785\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936305732484076, action1_reward_count: 785\n",
            "action2_reward: 1, action2_reward_avg: 0.5006369426751592, action2_reward_count: 785\n",
            "Iteration 786\n",
            "Chose Action 2: 0.49936305732484076 < 0.5006369426751592\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 786\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 786\n",
            "Iteration 787\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993646759847522, action1_reward_count: 787\n",
            "action2_reward: 1, action2_reward_avg: 0.5006353240152478, action2_reward_count: 787\n",
            "Iteration 788\n",
            "Chose Action 2: 0.4993646759847522 < 0.5006353240152478\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 788\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 788\n",
            "Iteration 789\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49936628643852976, action1_reward_count: 789\n",
            "action2_reward: 1, action2_reward_avg: 0.5006337135614702, action2_reward_count: 789\n",
            "Iteration 790\n",
            "Chose Action 2: 0.49936628643852976 < 0.5006337135614702\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 790\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 790\n",
            "Iteration 791\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993678887484197, action1_reward_count: 791\n",
            "action2_reward: 1, action2_reward_avg: 0.5006321112515802, action2_reward_count: 791\n",
            "Iteration 792\n",
            "Chose Action 2: 0.4993678887484197 < 0.5006321112515802\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 792\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 792\n",
            "Iteration 793\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49936948297604034, action1_reward_count: 793\n",
            "action2_reward: 1, action2_reward_avg: 0.5006305170239596, action2_reward_count: 793\n",
            "Iteration 794\n",
            "Chose Action 2: 0.49936948297604034 < 0.5006305170239596\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 794\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 794\n",
            "Iteration 795\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937106918238994, action1_reward_count: 795\n",
            "action2_reward: 1, action2_reward_avg: 0.50062893081761, action2_reward_count: 795\n",
            "Iteration 796\n",
            "Chose Action 2: 0.49937106918238994 < 0.50062893081761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 796\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 796\n",
            "Iteration 797\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993726474278545, action1_reward_count: 797\n",
            "action2_reward: 1, action2_reward_avg: 0.5006273525721454, action2_reward_count: 797\n",
            "Iteration 798\n",
            "Chose Action 2: 0.4993726474278545 < 0.5006273525721454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 798\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 798\n",
            "Iteration 799\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937421777221525, action1_reward_count: 799\n",
            "action2_reward: 1, action2_reward_avg: 0.5006257822277846, action2_reward_count: 799\n",
            "Iteration 800\n",
            "Chose Action 2: 0.49937421777221525 < 0.5006257822277846\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 800\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 800\n",
            "Iteration 801\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993757802746567, action1_reward_count: 801\n",
            "action2_reward: 1, action2_reward_avg: 0.5006242197253432, action2_reward_count: 801\n",
            "Iteration 802\n",
            "Chose Action 2: 0.4993757802746567 < 0.5006242197253432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 802\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 802\n",
            "Iteration 803\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49937733499377335, action1_reward_count: 803\n",
            "action2_reward: 1, action2_reward_avg: 0.5006226650062265, action2_reward_count: 803\n",
            "Iteration 804\n",
            "Chose Action 2: 0.49937733499377335 < 0.5006226650062265\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 804\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 804\n",
            "Iteration 805\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993788819875776, action1_reward_count: 805\n",
            "action2_reward: 1, action2_reward_avg: 0.5006211180124223, action2_reward_count: 805\n",
            "Iteration 806\n",
            "Chose Action 2: 0.4993788819875776 < 0.5006211180124223\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 806\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 806\n",
            "Iteration 807\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4993804213135068, action1_reward_count: 807\n",
            "action2_reward: 1, action2_reward_avg: 0.5006195786864931, action2_reward_count: 807\n",
            "Iteration 808\n",
            "Chose Action 2: 0.4993804213135068 < 0.5006195786864931\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 808\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 808\n",
            "Iteration 809\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49938195302843014, action1_reward_count: 809\n",
            "action2_reward: 1, action2_reward_avg: 0.5006180469715698, action2_reward_count: 809\n",
            "Iteration 810\n",
            "Chose Action 2: 0.49938195302843014 < 0.5006180469715698\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 810\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 810\n",
            "Iteration 811\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499383477188656, action1_reward_count: 811\n",
            "action2_reward: 1, action2_reward_avg: 0.500616522811344, action2_reward_count: 811\n",
            "Iteration 812\n",
            "Chose Action 2: 0.499383477188656 < 0.500616522811344\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 812\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 812\n",
            "Iteration 813\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4993849938499385, action1_reward_count: 813\n",
            "action2_reward: 1, action2_reward_avg: 0.5006150061500615, action2_reward_count: 813\n",
            "Iteration 814\n",
            "Chose Action 2: 0.4993849938499385 < 0.5006150061500615\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 814\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 814\n",
            "Iteration 815\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49938650306748467, action1_reward_count: 815\n",
            "action2_reward: 1, action2_reward_avg: 0.5006134969325153, action2_reward_count: 815\n",
            "Iteration 816\n",
            "Chose Action 2: 0.49938650306748467 < 0.5006134969325153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 816\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 816\n",
            "Iteration 817\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49938800489596086, action1_reward_count: 817\n",
            "action2_reward: 1, action2_reward_avg: 0.5006119951040392, action2_reward_count: 817\n",
            "Iteration 818\n",
            "Chose Action 2: 0.49938800489596086 < 0.5006119951040392\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 818\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 818\n",
            "Iteration 819\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993894993894994, action1_reward_count: 819\n",
            "action2_reward: 1, action2_reward_avg: 0.5006105006105006, action2_reward_count: 819\n",
            "Iteration 820\n",
            "Chose Action 2: 0.4993894993894994 < 0.5006105006105006\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 820\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 820\n",
            "Iteration 821\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993909866017052, action1_reward_count: 821\n",
            "action2_reward: 1, action2_reward_avg: 0.5006090133982948, action2_reward_count: 821\n",
            "Iteration 822\n",
            "Chose Action 2: 0.4993909866017052 < 0.5006090133982948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 822\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 822\n",
            "Iteration 823\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993924665856622, action1_reward_count: 823\n",
            "action2_reward: 1, action2_reward_avg: 0.5006075334143378, action2_reward_count: 823\n",
            "Iteration 824\n",
            "Chose Action 2: 0.4993924665856622 < 0.5006075334143378\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 824\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 824\n",
            "Iteration 825\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993939393939394, action1_reward_count: 825\n",
            "action2_reward: 1, action2_reward_avg: 0.5006060606060606, action2_reward_count: 825\n",
            "Iteration 826\n",
            "Chose Action 2: 0.4993939393939394 < 0.5006060606060606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 826\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 826\n",
            "Iteration 827\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939540507859737, action1_reward_count: 827\n",
            "action2_reward: 1, action2_reward_avg: 0.5006045949214026, action2_reward_count: 827\n",
            "Iteration 828\n",
            "Chose Action 2: 0.49939540507859737 < 0.5006045949214026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 828\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 828\n",
            "Iteration 829\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939686369119424, action1_reward_count: 829\n",
            "action2_reward: 1, action2_reward_avg: 0.5006031363088058, action2_reward_count: 829\n",
            "Iteration 830\n",
            "Chose Action 2: 0.49939686369119424 < 0.5006031363088058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 830\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 830\n",
            "Iteration 831\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4993983152827918, action1_reward_count: 831\n",
            "action2_reward: 1, action2_reward_avg: 0.5006016847172082, action2_reward_count: 831\n",
            "Iteration 832\n",
            "Chose Action 2: 0.4993983152827918 < 0.5006016847172082\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 832\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 832\n",
            "Iteration 833\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49939975990396157, action1_reward_count: 833\n",
            "action2_reward: 1, action2_reward_avg: 0.5006002400960384, action2_reward_count: 833\n",
            "Iteration 834\n",
            "Chose Action 2: 0.49939975990396157 < 0.5006002400960384\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 834\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 834\n",
            "Iteration 835\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994011976047904, action1_reward_count: 835\n",
            "action2_reward: 1, action2_reward_avg: 0.5005988023952096, action2_reward_count: 835\n",
            "Iteration 836\n",
            "Chose Action 2: 0.4994011976047904 < 0.5005988023952096\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 836\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 836\n",
            "Iteration 837\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994026284348865, action1_reward_count: 837\n",
            "action2_reward: 1, action2_reward_avg: 0.5005973715651135, action2_reward_count: 837\n",
            "Iteration 838\n",
            "Chose Action 2: 0.4994026284348865 < 0.5005973715651135\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 838\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 838\n",
            "Iteration 839\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499404052443385, action1_reward_count: 839\n",
            "action2_reward: 1, action2_reward_avg: 0.5005959475566151, action2_reward_count: 839\n",
            "Iteration 840\n",
            "Chose Action 2: 0.499404052443385 < 0.5005959475566151\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 840\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 840\n",
            "Iteration 841\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994054696789536, action1_reward_count: 841\n",
            "action2_reward: 1, action2_reward_avg: 0.5005945303210464, action2_reward_count: 841\n",
            "Iteration 842\n",
            "Chose Action 2: 0.4994054696789536 < 0.5005945303210464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 842\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 842\n",
            "Iteration 843\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940688018979834, action1_reward_count: 843\n",
            "action2_reward: 1, action2_reward_avg: 0.5005931198102017, action2_reward_count: 843\n",
            "Iteration 844\n",
            "Chose Action 2: 0.49940688018979834 < 0.5005931198102017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 844\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 844\n",
            "Iteration 845\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940828402366866, action1_reward_count: 845\n",
            "action2_reward: 1, action2_reward_avg: 0.5005917159763313, action2_reward_count: 845\n",
            "Iteration 846\n",
            "Chose Action 2: 0.49940828402366866 < 0.5005917159763313\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 846\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 846\n",
            "Iteration 847\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49940968122786306, action1_reward_count: 847\n",
            "action2_reward: 1, action2_reward_avg: 0.500590318772137, action2_reward_count: 847\n",
            "Iteration 848\n",
            "Chose Action 2: 0.49940968122786306 < 0.500590318772137\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 848\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 848\n",
            "Iteration 849\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994110718492344, action1_reward_count: 849\n",
            "action2_reward: 1, action2_reward_avg: 0.5005889281507656, action2_reward_count: 849\n",
            "Iteration 850\n",
            "Chose Action 2: 0.4994110718492344 < 0.5005889281507656\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 850\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 850\n",
            "Iteration 851\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994124559341951, action1_reward_count: 851\n",
            "action2_reward: 1, action2_reward_avg: 0.500587544065805, action2_reward_count: 851\n",
            "Iteration 852\n",
            "Chose Action 2: 0.4994124559341951 < 0.500587544065805\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 852\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 852\n",
            "Iteration 853\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49941383352872215, action1_reward_count: 853\n",
            "action2_reward: 1, action2_reward_avg: 0.5005861664712778, action2_reward_count: 853\n",
            "Iteration 854\n",
            "Chose Action 2: 0.49941383352872215 < 0.5005861664712778\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 854\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 854\n",
            "Iteration 855\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994152046783626, action1_reward_count: 855\n",
            "action2_reward: 1, action2_reward_avg: 0.5005847953216375, action2_reward_count: 855\n",
            "Iteration 856\n",
            "Chose Action 2: 0.4994152046783626 < 0.5005847953216375\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 856\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 856\n",
            "Iteration 857\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49941656942823803, action1_reward_count: 857\n",
            "action2_reward: 1, action2_reward_avg: 0.5005834305717619, action2_reward_count: 857\n",
            "Iteration 858\n",
            "Chose Action 2: 0.49941656942823803 < 0.5005834305717619\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 858\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 858\n",
            "Iteration 859\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49941792782305006, action1_reward_count: 859\n",
            "action2_reward: 1, action2_reward_avg: 0.5005820721769498, action2_reward_count: 859\n",
            "Iteration 860\n",
            "Chose Action 2: 0.49941792782305006 < 0.5005820721769498\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 860\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 860\n",
            "Iteration 861\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994192799070848, action1_reward_count: 861\n",
            "action2_reward: 1, action2_reward_avg: 0.5005807200929151, action2_reward_count: 861\n",
            "Iteration 862\n",
            "Chose Action 2: 0.4994192799070848 < 0.5005807200929151\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 862\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 862\n",
            "Iteration 863\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942062572421786, action1_reward_count: 863\n",
            "action2_reward: 1, action2_reward_avg: 0.500579374275782, action2_reward_count: 863\n",
            "Iteration 864\n",
            "Chose Action 2: 0.49942062572421786 < 0.500579374275782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 864\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 864\n",
            "Iteration 865\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942196531791905, action1_reward_count: 865\n",
            "action2_reward: 1, action2_reward_avg: 0.5005780346820808, action2_reward_count: 865\n",
            "Iteration 866\n",
            "Chose Action 2: 0.49942196531791905 < 0.5005780346820808\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 866\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 866\n",
            "Iteration 867\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994232987312572, action1_reward_count: 867\n",
            "action2_reward: 1, action2_reward_avg: 0.5005767012687427, action2_reward_count: 867\n",
            "Iteration 868\n",
            "Chose Action 2: 0.4994232987312572 < 0.5005767012687427\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 868\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 868\n",
            "Iteration 869\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994246260069045, action1_reward_count: 869\n",
            "action2_reward: 1, action2_reward_avg: 0.5005753739930954, action2_reward_count: 869\n",
            "Iteration 870\n",
            "Chose Action 2: 0.4994246260069045 < 0.5005753739930954\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 870\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 870\n",
            "Iteration 871\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49942594718714123, action1_reward_count: 871\n",
            "action2_reward: 1, action2_reward_avg: 0.5005740528128587, action2_reward_count: 871\n",
            "Iteration 872\n",
            "Chose Action 2: 0.49942594718714123 < 0.5005740528128587\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 872\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 872\n",
            "Iteration 873\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49942726231386025, action1_reward_count: 873\n",
            "action2_reward: 1, action2_reward_avg: 0.5005727376861397, action2_reward_count: 873\n",
            "Iteration 874\n",
            "Chose Action 2: 0.49942726231386025 < 0.5005727376861397\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 874\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 874\n",
            "Iteration 875\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49942857142857144, action1_reward_count: 875\n",
            "action2_reward: 1, action2_reward_avg: 0.5005714285714286, action2_reward_count: 875\n",
            "Iteration 876\n",
            "Chose Action 2: 0.49942857142857144 < 0.5005714285714286\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 876\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 876\n",
            "Iteration 877\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49942987457240595, action1_reward_count: 877\n",
            "action2_reward: 1, action2_reward_avg: 0.500570125427594, action2_reward_count: 877\n",
            "Iteration 878\n",
            "Chose Action 2: 0.49942987457240595 < 0.500570125427594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 878\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 878\n",
            "Iteration 879\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49943117178612056, action1_reward_count: 879\n",
            "action2_reward: 1, action2_reward_avg: 0.5005688282138794, action2_reward_count: 879\n",
            "Iteration 880\n",
            "Chose Action 2: 0.49943117178612056 < 0.5005688282138794\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 880\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 880\n",
            "Iteration 881\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49943246311010214, action1_reward_count: 881\n",
            "action2_reward: 1, action2_reward_avg: 0.5005675368898977, action2_reward_count: 881\n",
            "Iteration 882\n",
            "Chose Action 2: 0.49943246311010214 < 0.5005675368898977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 882\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 882\n",
            "Iteration 883\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49943374858437145, action1_reward_count: 883\n",
            "action2_reward: 1, action2_reward_avg: 0.5005662514156284, action2_reward_count: 883\n",
            "Iteration 884\n",
            "Chose Action 2: 0.49943374858437145 < 0.5005662514156284\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 884\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 884\n",
            "Iteration 885\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994350282485876, action1_reward_count: 885\n",
            "action2_reward: 1, action2_reward_avg: 0.5005649717514122, action2_reward_count: 885\n",
            "Iteration 886\n",
            "Chose Action 2: 0.4994350282485876 < 0.5005649717514122\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 886\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 886\n",
            "Iteration 887\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49943630214205187, action1_reward_count: 887\n",
            "action2_reward: 1, action2_reward_avg: 0.500563697857948, action2_reward_count: 887\n",
            "Iteration 888\n",
            "Chose Action 2: 0.49943630214205187 < 0.500563697857948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 888\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 888\n",
            "Iteration 889\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49943757030371205, action1_reward_count: 889\n",
            "action2_reward: 1, action2_reward_avg: 0.5005624296962878, action2_reward_count: 889\n",
            "Iteration 890\n",
            "Chose Action 2: 0.49943757030371205 < 0.5005624296962878\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 890\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 890\n",
            "Iteration 891\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994388327721661, action1_reward_count: 891\n",
            "action2_reward: 1, action2_reward_avg: 0.5005611672278338, action2_reward_count: 891\n",
            "Iteration 892\n",
            "Chose Action 2: 0.4994388327721661 < 0.5005611672278338\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 892\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 892\n",
            "Iteration 893\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49944008958566627, action1_reward_count: 893\n",
            "action2_reward: 1, action2_reward_avg: 0.5005599104143337, action2_reward_count: 893\n",
            "Iteration 894\n",
            "Chose Action 2: 0.49944008958566627 < 0.5005599104143337\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 894\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 894\n",
            "Iteration 895\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994413407821229, action1_reward_count: 895\n",
            "action2_reward: 1, action2_reward_avg: 0.500558659217877, action2_reward_count: 895\n",
            "Iteration 896\n",
            "Chose Action 2: 0.4994413407821229 < 0.500558659217877\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 896\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 896\n",
            "Iteration 897\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49944258639910816, action1_reward_count: 897\n",
            "action2_reward: 1, action2_reward_avg: 0.5005574136008918, action2_reward_count: 897\n",
            "Iteration 898\n",
            "Chose Action 2: 0.49944258639910816 < 0.5005574136008918\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 898\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 898\n",
            "Iteration 899\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994438264738598, action1_reward_count: 899\n",
            "action2_reward: 1, action2_reward_avg: 0.5005561735261401, action2_reward_count: 899\n",
            "Iteration 900\n",
            "Chose Action 2: 0.4994438264738598 < 0.5005561735261401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 900\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 900\n",
            "Iteration 901\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49944506104328523, action1_reward_count: 901\n",
            "action2_reward: 1, action2_reward_avg: 0.5005549389567147, action2_reward_count: 901\n",
            "Iteration 902\n",
            "Chose Action 2: 0.49944506104328523 < 0.5005549389567147\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 902\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 902\n",
            "Iteration 903\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994462901439646, action1_reward_count: 903\n",
            "action2_reward: 1, action2_reward_avg: 0.5005537098560353, action2_reward_count: 903\n",
            "Iteration 904\n",
            "Chose Action 2: 0.4994462901439646 < 0.5005537098560353\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 904\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 904\n",
            "Iteration 905\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994475138121547, action1_reward_count: 905\n",
            "action2_reward: 1, action2_reward_avg: 0.5005524861878452, action2_reward_count: 905\n",
            "Iteration 906\n",
            "Chose Action 2: 0.4994475138121547 < 0.5005524861878452\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 906\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 906\n",
            "Iteration 907\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994487320837927, action1_reward_count: 907\n",
            "action2_reward: 1, action2_reward_avg: 0.5005512679162072, action2_reward_count: 907\n",
            "Iteration 908\n",
            "Chose Action 2: 0.4994487320837927 < 0.5005512679162072\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 908\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 908\n",
            "Iteration 909\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49944994499449946, action1_reward_count: 909\n",
            "action2_reward: 1, action2_reward_avg: 0.5005500550055004, action2_reward_count: 909\n",
            "Iteration 910\n",
            "Chose Action 2: 0.49944994499449946 < 0.5005500550055004\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 910\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 910\n",
            "Iteration 911\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994511525795829, action1_reward_count: 911\n",
            "action2_reward: 1, action2_reward_avg: 0.500548847420417, action2_reward_count: 911\n",
            "Iteration 912\n",
            "Chose Action 2: 0.4994511525795829 < 0.500548847420417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 912\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 912\n",
            "Iteration 913\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994523548740416, action1_reward_count: 913\n",
            "action2_reward: 1, action2_reward_avg: 0.5005476451259583, action2_reward_count: 913\n",
            "Iteration 914\n",
            "Chose Action 2: 0.4994523548740416 < 0.5005476451259583\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 914\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 914\n",
            "Iteration 915\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994535519125683, action1_reward_count: 915\n",
            "action2_reward: 1, action2_reward_avg: 0.5005464480874315, action2_reward_count: 915\n",
            "Iteration 916\n",
            "Chose Action 2: 0.4994535519125683 < 0.5005464480874315\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 916\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 916\n",
            "Iteration 917\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4994547437295529, action1_reward_count: 917\n",
            "action2_reward: 1, action2_reward_avg: 0.500545256270447, action2_reward_count: 917\n",
            "Iteration 918\n",
            "Chose Action 2: 0.4994547437295529 < 0.500545256270447\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 918\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 918\n",
            "Iteration 919\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499455930359086, action1_reward_count: 919\n",
            "action2_reward: 1, action2_reward_avg: 0.5005440696409139, action2_reward_count: 919\n",
            "Iteration 920\n",
            "Chose Action 2: 0.499455930359086 < 0.5005440696409139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 920\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 920\n",
            "Iteration 921\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499457111834962, action1_reward_count: 921\n",
            "action2_reward: 1, action2_reward_avg: 0.5005428881650379, action2_reward_count: 921\n",
            "Iteration 922\n",
            "Chose Action 2: 0.499457111834962 < 0.5005428881650379\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 922\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 922\n",
            "Iteration 923\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49945828819068255, action1_reward_count: 923\n",
            "action2_reward: 1, action2_reward_avg: 0.5005417118093173, action2_reward_count: 923\n",
            "Iteration 924\n",
            "Chose Action 2: 0.49945828819068255 < 0.5005417118093173\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 924\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 924\n",
            "Iteration 925\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49945945945945946, action1_reward_count: 925\n",
            "action2_reward: 1, action2_reward_avg: 0.5005405405405404, action2_reward_count: 925\n",
            "Iteration 926\n",
            "Chose Action 2: 0.49945945945945946 < 0.5005405405405404\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 926\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 926\n",
            "Iteration 927\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4994606256742179, action1_reward_count: 927\n",
            "action2_reward: 1, action2_reward_avg: 0.500539374325782, action2_reward_count: 927\n",
            "Iteration 928\n",
            "Chose Action 2: 0.4994606256742179 < 0.500539374325782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 928\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 928\n",
            "Iteration 929\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49946178686759957, action1_reward_count: 929\n",
            "action2_reward: 1, action2_reward_avg: 0.5005382131324003, action2_reward_count: 929\n",
            "Iteration 930\n",
            "Chose Action 2: 0.49946178686759957 < 0.5005382131324003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 930\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 930\n",
            "Iteration 931\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49946294307196565, action1_reward_count: 931\n",
            "action2_reward: 1, action2_reward_avg: 0.5005370569280343, action2_reward_count: 931\n",
            "Iteration 932\n",
            "Chose Action 2: 0.49946294307196565 < 0.5005370569280343\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 932\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 932\n",
            "Iteration 933\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994640943193998, action1_reward_count: 933\n",
            "action2_reward: 1, action2_reward_avg: 0.5005359056806001, action2_reward_count: 933\n",
            "Iteration 934\n",
            "Chose Action 2: 0.4994640943193998 < 0.5005359056806001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 934\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 934\n",
            "Iteration 935\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994652406417112, action1_reward_count: 935\n",
            "action2_reward: 1, action2_reward_avg: 0.5005347593582887, action2_reward_count: 935\n",
            "Iteration 936\n",
            "Chose Action 2: 0.4994652406417112 < 0.5005347593582887\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 936\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 936\n",
            "Iteration 937\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994663820704376, action1_reward_count: 937\n",
            "action2_reward: 1, action2_reward_avg: 0.5005336179295624, action2_reward_count: 937\n",
            "Iteration 938\n",
            "Chose Action 2: 0.4994663820704376 < 0.5005336179295624\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 938\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 938\n",
            "Iteration 939\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994675186368477, action1_reward_count: 939\n",
            "action2_reward: 1, action2_reward_avg: 0.5005324813631523, action2_reward_count: 939\n",
            "Iteration 940\n",
            "Chose Action 2: 0.4994675186368477 < 0.5005324813631523\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 940\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 940\n",
            "Iteration 941\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49946865037194477, action1_reward_count: 941\n",
            "action2_reward: 1, action2_reward_avg: 0.5005313496280552, action2_reward_count: 941\n",
            "Iteration 942\n",
            "Chose Action 2: 0.49946865037194477 < 0.5005313496280552\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 942\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 942\n",
            "Iteration 943\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49946977730646874, action1_reward_count: 943\n",
            "action2_reward: 1, action2_reward_avg: 0.5005302226935313, action2_reward_count: 943\n",
            "Iteration 944\n",
            "Chose Action 2: 0.49946977730646874 < 0.5005302226935313\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 944\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 944\n",
            "Iteration 945\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947089947089945, action1_reward_count: 945\n",
            "action2_reward: 1, action2_reward_avg: 0.5005291005291005, action2_reward_count: 945\n",
            "Iteration 946\n",
            "Chose Action 2: 0.49947089947089945 < 0.5005291005291005\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 946\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 946\n",
            "Iteration 947\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49947201689545934, action1_reward_count: 947\n",
            "action2_reward: 1, action2_reward_avg: 0.5005279831045406, action2_reward_count: 947\n",
            "Iteration 948\n",
            "Chose Action 2: 0.49947201689545934 < 0.5005279831045406\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 948\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 948\n",
            "Iteration 949\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994731296101159, action1_reward_count: 949\n",
            "action2_reward: 1, action2_reward_avg: 0.5005268703898841, action2_reward_count: 949\n",
            "Iteration 950\n",
            "Chose Action 2: 0.4994731296101159 < 0.5005268703898841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 950\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 950\n",
            "Iteration 951\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947423764458465, action1_reward_count: 951\n",
            "action2_reward: 1, action2_reward_avg: 0.5005257623554153, action2_reward_count: 951\n",
            "Iteration 952\n",
            "Chose Action 2: 0.49947423764458465 < 0.5005257623554153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 952\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 952\n",
            "Iteration 953\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994753410283316, action1_reward_count: 953\n",
            "action2_reward: 1, action2_reward_avg: 0.5005246589716684, action2_reward_count: 953\n",
            "Iteration 954\n",
            "Chose Action 2: 0.4994753410283316 < 0.5005246589716684\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 954\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 954\n",
            "Iteration 955\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49947643979057593, action1_reward_count: 955\n",
            "action2_reward: 1, action2_reward_avg: 0.5005235602094241, action2_reward_count: 955\n",
            "Iteration 956\n",
            "Chose Action 2: 0.49947643979057593 < 0.5005235602094241\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 956\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 956\n",
            "Iteration 957\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994775339602926, action1_reward_count: 957\n",
            "action2_reward: 1, action2_reward_avg: 0.5005224660397074, action2_reward_count: 957\n",
            "Iteration 958\n",
            "Chose Action 2: 0.4994775339602926 < 0.5005224660397074\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 958\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 958\n",
            "Iteration 959\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994786235662148, action1_reward_count: 959\n",
            "action2_reward: 1, action2_reward_avg: 0.5005213764337852, action2_reward_count: 959\n",
            "Iteration 960\n",
            "Chose Action 2: 0.4994786235662148 < 0.5005213764337852\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 960\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 960\n",
            "Iteration 961\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4994797086368366, action1_reward_count: 961\n",
            "action2_reward: 1, action2_reward_avg: 0.5005202913631633, action2_reward_count: 961\n",
            "Iteration 962\n",
            "Chose Action 2: 0.4994797086368366 < 0.5005202913631633\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 962\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 962\n",
            "Iteration 963\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4994807892004154, action1_reward_count: 963\n",
            "action2_reward: 1, action2_reward_avg: 0.5005192107995846, action2_reward_count: 963\n",
            "Iteration 964\n",
            "Chose Action 2: 0.4994807892004154 < 0.5005192107995846\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 964\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 964\n",
            "Iteration 965\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948186528497407, action1_reward_count: 965\n",
            "action2_reward: 1, action2_reward_avg: 0.5005181347150259, action2_reward_count: 965\n",
            "Iteration 966\n",
            "Chose Action 2: 0.49948186528497407 < 0.5005181347150259\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 966\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 966\n",
            "Iteration 967\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948293691830403, action1_reward_count: 967\n",
            "action2_reward: 1, action2_reward_avg: 0.500517063081696, action2_reward_count: 967\n",
            "Iteration 968\n",
            "Chose Action 2: 0.49948293691830403 < 0.500517063081696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 968\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 968\n",
            "Iteration 969\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49948400412796695, action1_reward_count: 969\n",
            "action2_reward: 1, action2_reward_avg: 0.500515995872033, action2_reward_count: 969\n",
            "Iteration 970\n",
            "Chose Action 2: 0.49948400412796695 < 0.500515995872033\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 970\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 970\n",
            "Iteration 971\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49948506694129763, action1_reward_count: 971\n",
            "action2_reward: 1, action2_reward_avg: 0.5005149330587023, action2_reward_count: 971\n",
            "Iteration 972\n",
            "Chose Action 2: 0.49948506694129763 < 0.5005149330587023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 972\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 972\n",
            "Iteration 973\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499486125385406, action1_reward_count: 973\n",
            "action2_reward: 1, action2_reward_avg: 0.500513874614594, action2_reward_count: 973\n",
            "Iteration 974\n",
            "Chose Action 2: 0.499486125385406 < 0.500513874614594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 974\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 974\n",
            "Iteration 975\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49948717948717947, action1_reward_count: 975\n",
            "action2_reward: 1, action2_reward_avg: 0.5005128205128204, action2_reward_count: 975\n",
            "Iteration 976\n",
            "Chose Action 2: 0.49948717948717947 < 0.5005128205128204\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 976\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 976\n",
            "Iteration 977\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49948822927328557, action1_reward_count: 977\n",
            "action2_reward: 1, action2_reward_avg: 0.5005117707267143, action2_reward_count: 977\n",
            "Iteration 978\n",
            "Chose Action 2: 0.49948822927328557 < 0.5005117707267143\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 978\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 978\n",
            "Iteration 979\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49948927477017363, action1_reward_count: 979\n",
            "action2_reward: 1, action2_reward_avg: 0.5005107252298262, action2_reward_count: 979\n",
            "Iteration 980\n",
            "Chose Action 2: 0.49948927477017363 < 0.5005107252298262\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 980\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 980\n",
            "Iteration 981\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49949031600407745, action1_reward_count: 981\n",
            "action2_reward: 1, action2_reward_avg: 0.5005096839959223, action2_reward_count: 981\n",
            "Iteration 982\n",
            "Chose Action 2: 0.49949031600407745 < 0.5005096839959223\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 982\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 982\n",
            "Iteration 983\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949135300101727, action1_reward_count: 983\n",
            "action2_reward: 1, action2_reward_avg: 0.5005086469989825, action2_reward_count: 983\n",
            "Iteration 984\n",
            "Chose Action 2: 0.49949135300101727 < 0.5005086469989825\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 984\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 984\n",
            "Iteration 985\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49949238578680205, action1_reward_count: 985\n",
            "action2_reward: 1, action2_reward_avg: 0.5005076142131977, action2_reward_count: 985\n",
            "Iteration 986\n",
            "Chose Action 2: 0.49949238578680205 < 0.5005076142131977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 986\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 986\n",
            "Iteration 987\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49949341438703143, action1_reward_count: 987\n",
            "action2_reward: 1, action2_reward_avg: 0.5005065856129683, action2_reward_count: 987\n",
            "Iteration 988\n",
            "Chose Action 2: 0.49949341438703143 < 0.5005065856129683\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 988\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 988\n",
            "Iteration 989\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4994944388270981, action1_reward_count: 989\n",
            "action2_reward: 1, action2_reward_avg: 0.5005055611729017, action2_reward_count: 989\n",
            "Iteration 990\n",
            "Chose Action 2: 0.4994944388270981 < 0.5005055611729017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 990\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 990\n",
            "Iteration 991\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949545913218973, action1_reward_count: 991\n",
            "action2_reward: 1, action2_reward_avg: 0.50050454086781, action2_reward_count: 991\n",
            "Iteration 992\n",
            "Chose Action 2: 0.49949545913218973 < 0.50050454086781\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 992\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 992\n",
            "Iteration 993\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499496475327291, action1_reward_count: 993\n",
            "action2_reward: 1, action2_reward_avg: 0.5005035246727088, action2_reward_count: 993\n",
            "Iteration 994\n",
            "Chose Action 2: 0.499496475327291 < 0.5005035246727088\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 994\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 994\n",
            "Iteration 995\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4994974874371859, action1_reward_count: 995\n",
            "action2_reward: 1, action2_reward_avg: 0.5005025125628139, action2_reward_count: 995\n",
            "Iteration 996\n",
            "Chose Action 2: 0.4994974874371859 < 0.5005025125628139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 996\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 996\n",
            "Iteration 997\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49949849548645936, action1_reward_count: 997\n",
            "action2_reward: 1, action2_reward_avg: 0.5005015045135404, action2_reward_count: 997\n",
            "Iteration 998\n",
            "Chose Action 2: 0.49949849548645936 < 0.5005015045135404\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 998\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 998\n",
            "Iteration 999\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4994994994994995, action1_reward_count: 999\n",
            "action2_reward: 1, action2_reward_avg: 0.5005005005005002, action2_reward_count: 999\n",
            "Iteration 1000\n",
            "Chose Action 2: 0.4994994994994995 < 0.5005005005005002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1000\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1000\n",
            "Iteration 1001\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995004995004995, action1_reward_count: 1001\n",
            "action2_reward: 1, action2_reward_avg: 0.5004995004995002, action2_reward_count: 1001\n",
            "Iteration 1002\n",
            "Chose Action 2: 0.4995004995004995 < 0.5004995004995002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1002\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1002\n",
            "Iteration 1003\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995014955134596, action1_reward_count: 1003\n",
            "action2_reward: 1, action2_reward_avg: 0.5004985044865401, action2_reward_count: 1003\n",
            "Iteration 1004\n",
            "Chose Action 2: 0.4995014955134596 < 0.5004985044865401\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1004\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1004\n",
            "Iteration 1005\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49950248756218907, action1_reward_count: 1005\n",
            "action2_reward: 1, action2_reward_avg: 0.5004975124378107, action2_reward_count: 1005\n",
            "Iteration 1006\n",
            "Chose Action 2: 0.49950248756218907 < 0.5004975124378107\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1006\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1006\n",
            "Iteration 1007\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950347567030784, action1_reward_count: 1007\n",
            "action2_reward: 1, action2_reward_avg: 0.5004965243296919, action2_reward_count: 1007\n",
            "Iteration 1008\n",
            "Chose Action 2: 0.49950347567030784 < 0.5004965243296919\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1008\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1008\n",
            "Iteration 1009\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950445986124875, action1_reward_count: 1009\n",
            "action2_reward: 1, action2_reward_avg: 0.500495540138751, action2_reward_count: 1009\n",
            "Iteration 1010\n",
            "Chose Action 2: 0.49950445986124875 < 0.500495540138751\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1010\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1010\n",
            "Iteration 1011\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49950544015825915, action1_reward_count: 1011\n",
            "action2_reward: 1, action2_reward_avg: 0.5004945598417406, action2_reward_count: 1011\n",
            "Iteration 1012\n",
            "Chose Action 2: 0.49950544015825915 < 0.5004945598417406\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1012\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1012\n",
            "Iteration 1013\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49950641658440276, action1_reward_count: 1013\n",
            "action2_reward: 1, action2_reward_avg: 0.500493583415597, action2_reward_count: 1013\n",
            "Iteration 1014\n",
            "Chose Action 2: 0.49950641658440276 < 0.500493583415597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1014\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1014\n",
            "Iteration 1015\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995073891625616, action1_reward_count: 1015\n",
            "action2_reward: 1, action2_reward_avg: 0.5004926108374382, action2_reward_count: 1015\n",
            "Iteration 1016\n",
            "Chose Action 2: 0.4995073891625616 < 0.5004926108374382\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1016\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1016\n",
            "Iteration 1017\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995083579154376, action1_reward_count: 1017\n",
            "action2_reward: 1, action2_reward_avg: 0.5004916420845623, action2_reward_count: 1017\n",
            "Iteration 1018\n",
            "Chose Action 2: 0.4995083579154376 < 0.5004916420845623\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1018\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1018\n",
            "Iteration 1019\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49950932286555444, action1_reward_count: 1019\n",
            "action2_reward: 1, action2_reward_avg: 0.5004906771344454, action2_reward_count: 1019\n",
            "Iteration 1020\n",
            "Chose Action 2: 0.49950932286555444 < 0.5004906771344454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1020\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1020\n",
            "Iteration 1021\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49951028403525954, action1_reward_count: 1021\n",
            "action2_reward: 1, action2_reward_avg: 0.5004897159647402, action2_reward_count: 1021\n",
            "Iteration 1022\n",
            "Chose Action 2: 0.49951028403525954 < 0.5004897159647402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1022\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1022\n",
            "Iteration 1023\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995112414467253, action1_reward_count: 1023\n",
            "action2_reward: 1, action2_reward_avg: 0.5004887585532745, action2_reward_count: 1023\n",
            "Iteration 1024\n",
            "Chose Action 2: 0.4995112414467253 < 0.5004887585532745\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1024\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1024\n",
            "Iteration 1025\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995121951219512, action1_reward_count: 1025\n",
            "action2_reward: 1, action2_reward_avg: 0.5004878048780486, action2_reward_count: 1025\n",
            "Iteration 1026\n",
            "Chose Action 2: 0.4995121951219512 < 0.5004878048780486\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1026\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1026\n",
            "Iteration 1027\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951314508276534, action1_reward_count: 1027\n",
            "action2_reward: 1, action2_reward_avg: 0.5004868549172344, action2_reward_count: 1027\n",
            "Iteration 1028\n",
            "Chose Action 2: 0.49951314508276534 < 0.5004868549172344\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1028\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1028\n",
            "Iteration 1029\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951409135082603, action1_reward_count: 1029\n",
            "action2_reward: 1, action2_reward_avg: 0.5004859086491737, action2_reward_count: 1029\n",
            "Iteration 1030\n",
            "Chose Action 2: 0.49951409135082603 < 0.5004859086491737\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1030\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1030\n",
            "Iteration 1031\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49951503394762364, action1_reward_count: 1031\n",
            "action2_reward: 1, action2_reward_avg: 0.5004849660523761, action2_reward_count: 1031\n",
            "Iteration 1032\n",
            "Chose Action 2: 0.49951503394762364 < 0.5004849660523761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1032\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1032\n",
            "Iteration 1033\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995159728944821, action1_reward_count: 1033\n",
            "action2_reward: 1, action2_reward_avg: 0.5004840271055176, action2_reward_count: 1033\n",
            "Iteration 1034\n",
            "Chose Action 2: 0.4995159728944821 < 0.5004840271055176\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1034\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1034\n",
            "Iteration 1035\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995169082125604, action1_reward_count: 1035\n",
            "action2_reward: 1, action2_reward_avg: 0.5004830917874393, action2_reward_count: 1035\n",
            "Iteration 1036\n",
            "Chose Action 2: 0.4995169082125604 < 0.5004830917874393\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1036\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1036\n",
            "Iteration 1037\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49951783992285437, action1_reward_count: 1037\n",
            "action2_reward: 1, action2_reward_avg: 0.5004821600771453, action2_reward_count: 1037\n",
            "Iteration 1038\n",
            "Chose Action 2: 0.49951783992285437 < 0.5004821600771453\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1038\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1038\n",
            "Iteration 1039\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49951876804619827, action1_reward_count: 1039\n",
            "action2_reward: 1, action2_reward_avg: 0.5004812319538015, action2_reward_count: 1039\n",
            "Iteration 1040\n",
            "Chose Action 2: 0.49951876804619827 < 0.5004812319538015\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1040\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1040\n",
            "Iteration 1041\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49951969260326606, action1_reward_count: 1041\n",
            "action2_reward: 1, action2_reward_avg: 0.5004803073967337, action2_reward_count: 1041\n",
            "Iteration 1042\n",
            "Chose Action 2: 0.49951969260326606 < 0.5004803073967337\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1042\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1042\n",
            "Iteration 1043\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49952061361457334, action1_reward_count: 1043\n",
            "action2_reward: 1, action2_reward_avg: 0.5004793863854263, action2_reward_count: 1043\n",
            "Iteration 1044\n",
            "Chose Action 2: 0.49952061361457334 < 0.5004793863854263\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1044\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1044\n",
            "Iteration 1045\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995215311004785, action1_reward_count: 1045\n",
            "action2_reward: 1, action2_reward_avg: 0.5004784688995212, action2_reward_count: 1045\n",
            "Iteration 1046\n",
            "Chose Action 2: 0.4995215311004785 < 0.5004784688995212\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1046\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1046\n",
            "Iteration 1047\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995224450811843, action1_reward_count: 1047\n",
            "action2_reward: 1, action2_reward_avg: 0.5004775549188153, action2_reward_count: 1047\n",
            "Iteration 1048\n",
            "Chose Action 2: 0.4995224450811843 < 0.5004775549188153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1048\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1048\n",
            "Iteration 1049\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49952335557673977, action1_reward_count: 1049\n",
            "action2_reward: 1, action2_reward_avg: 0.5004766444232599, action2_reward_count: 1049\n",
            "Iteration 1050\n",
            "Chose Action 2: 0.49952335557673977 < 0.5004766444232599\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1050\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1050\n",
            "Iteration 1051\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995242626070409, action1_reward_count: 1051\n",
            "action2_reward: 1, action2_reward_avg: 0.5004757373929588, action2_reward_count: 1051\n",
            "Iteration 1052\n",
            "Chose Action 2: 0.4995242626070409 < 0.5004757373929588\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1052\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1052\n",
            "Iteration 1053\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49952516619183285, action1_reward_count: 1053\n",
            "action2_reward: 1, action2_reward_avg: 0.5004748338081668, action2_reward_count: 1053\n",
            "Iteration 1054\n",
            "Chose Action 2: 0.49952516619183285 < 0.5004748338081668\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1054\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1054\n",
            "Iteration 1055\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995260663507109, action1_reward_count: 1055\n",
            "action2_reward: 1, action2_reward_avg: 0.5004739336492887, action2_reward_count: 1055\n",
            "Iteration 1056\n",
            "Chose Action 2: 0.4995260663507109 < 0.5004739336492887\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1056\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1056\n",
            "Iteration 1057\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49952696310312206, action1_reward_count: 1057\n",
            "action2_reward: 1, action2_reward_avg: 0.5004730368968776, action2_reward_count: 1057\n",
            "Iteration 1058\n",
            "Chose Action 2: 0.49952696310312206 < 0.5004730368968776\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1058\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1058\n",
            "Iteration 1059\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995278564683664, action1_reward_count: 1059\n",
            "action2_reward: 1, action2_reward_avg: 0.5004721435316333, action2_reward_count: 1059\n",
            "Iteration 1060\n",
            "Chose Action 2: 0.4995278564683664 < 0.5004721435316333\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1060\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1060\n",
            "Iteration 1061\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49952874646559847, action1_reward_count: 1061\n",
            "action2_reward: 1, action2_reward_avg: 0.5004712535344011, action2_reward_count: 1061\n",
            "Iteration 1062\n",
            "Chose Action 2: 0.49952874646559847 < 0.5004712535344011\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1062\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1062\n",
            "Iteration 1063\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995296331138288, action1_reward_count: 1063\n",
            "action2_reward: 1, action2_reward_avg: 0.5004703668861709, action2_reward_count: 1063\n",
            "Iteration 1064\n",
            "Chose Action 2: 0.4995296331138288 < 0.5004703668861709\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1064\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1064\n",
            "Iteration 1065\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49953051643192486, action1_reward_count: 1065\n",
            "action2_reward: 1, action2_reward_avg: 0.5004694835680747, action2_reward_count: 1065\n",
            "Iteration 1066\n",
            "Chose Action 2: 0.49953051643192486 < 0.5004694835680747\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1066\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1066\n",
            "Iteration 1067\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49953139643861294, action1_reward_count: 1067\n",
            "action2_reward: 1, action2_reward_avg: 0.5004686035613867, action2_reward_count: 1067\n",
            "Iteration 1068\n",
            "Chose Action 2: 0.49953139643861294 < 0.5004686035613867\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1068\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1068\n",
            "Iteration 1069\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49953227315247895, action1_reward_count: 1069\n",
            "action2_reward: 1, action2_reward_avg: 0.5004677268475206, action2_reward_count: 1069\n",
            "Iteration 1070\n",
            "Chose Action 2: 0.49953227315247895 < 0.5004677268475206\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1070\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1070\n",
            "Iteration 1071\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995331465919701, action1_reward_count: 1071\n",
            "action2_reward: 1, action2_reward_avg: 0.5004668534080294, action2_reward_count: 1071\n",
            "Iteration 1072\n",
            "Chose Action 2: 0.4995331465919701 < 0.5004668534080294\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1072\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1072\n",
            "Iteration 1073\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995340167753961, action1_reward_count: 1073\n",
            "action2_reward: 1, action2_reward_avg: 0.5004659832246035, action2_reward_count: 1073\n",
            "Iteration 1074\n",
            "Chose Action 2: 0.4995340167753961 < 0.5004659832246035\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1074\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1074\n",
            "Iteration 1075\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953488372093025, action1_reward_count: 1075\n",
            "action2_reward: 1, action2_reward_avg: 0.5004651162790693, action2_reward_count: 1075\n",
            "Iteration 1076\n",
            "Chose Action 2: 0.49953488372093025 < 0.5004651162790693\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1076\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1076\n",
            "Iteration 1077\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953574744661094, action1_reward_count: 1077\n",
            "action2_reward: 1, action2_reward_avg: 0.5004642525533886, action2_reward_count: 1077\n",
            "Iteration 1078\n",
            "Chose Action 2: 0.49953574744661094 < 0.5004642525533886\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1078\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1078\n",
            "Iteration 1079\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4995366079703429, action1_reward_count: 1079\n",
            "action2_reward: 1, action2_reward_avg: 0.5004633920296566, action2_reward_count: 1079\n",
            "Iteration 1080\n",
            "Chose Action 2: 0.4995366079703429 < 0.5004633920296566\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1080\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1080\n",
            "Iteration 1081\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49953746530989823, action1_reward_count: 1081\n",
            "action2_reward: 1, action2_reward_avg: 0.5004625346901013, action2_reward_count: 1081\n",
            "Iteration 1082\n",
            "Chose Action 2: 0.49953746530989823 < 0.5004625346901013\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1082\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1082\n",
            "Iteration 1083\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4995383194829178, action1_reward_count: 1083\n",
            "action2_reward: 1, action2_reward_avg: 0.5004616805170817, action2_reward_count: 1083\n",
            "Iteration 1084\n",
            "Chose Action 2: 0.4995383194829178 < 0.5004616805170817\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1084\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1084\n",
            "Iteration 1085\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49953917050691243, action1_reward_count: 1085\n",
            "action2_reward: 1, action2_reward_avg: 0.5004608294930871, action2_reward_count: 1085\n",
            "Iteration 1086\n",
            "Chose Action 2: 0.49953917050691243 < 0.5004608294930871\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1086\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1086\n",
            "Iteration 1087\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954001839926404, action1_reward_count: 1087\n",
            "action2_reward: 1, action2_reward_avg: 0.5004599816007356, action2_reward_count: 1087\n",
            "Iteration 1088\n",
            "Chose Action 2: 0.49954001839926404 < 0.5004599816007356\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1088\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1088\n",
            "Iteration 1089\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995408631772268, action1_reward_count: 1089\n",
            "action2_reward: 1, action2_reward_avg: 0.5004591368227728, action2_reward_count: 1089\n",
            "Iteration 1090\n",
            "Chose Action 2: 0.4995408631772268 < 0.5004591368227728\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1090\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1090\n",
            "Iteration 1091\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995417048579285, action1_reward_count: 1091\n",
            "action2_reward: 1, action2_reward_avg: 0.5004582951420711, action2_reward_count: 1091\n",
            "Iteration 1092\n",
            "Chose Action 2: 0.4995417048579285 < 0.5004582951420711\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1092\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1092\n",
            "Iteration 1093\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954254345837146, action1_reward_count: 1093\n",
            "action2_reward: 1, action2_reward_avg: 0.5004574565416281, action2_reward_count: 1093\n",
            "Iteration 1094\n",
            "Chose Action 2: 0.49954254345837146 < 0.5004574565416281\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1094\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1094\n",
            "Iteration 1095\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995433789954338, action1_reward_count: 1095\n",
            "action2_reward: 1, action2_reward_avg: 0.5004566210045658, action2_reward_count: 1095\n",
            "Iteration 1096\n",
            "Chose Action 2: 0.4995433789954338 < 0.5004566210045658\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1096\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1096\n",
            "Iteration 1097\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4995442114858706, action1_reward_count: 1097\n",
            "action2_reward: 1, action2_reward_avg: 0.500455788514129, action2_reward_count: 1097\n",
            "Iteration 1098\n",
            "Chose Action 2: 0.4995442114858706 < 0.500455788514129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1098\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1098\n",
            "Iteration 1099\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49954504094631486, action1_reward_count: 1099\n",
            "action2_reward: 1, action2_reward_avg: 0.5004549590536848, action2_reward_count: 1099\n",
            "Iteration 1100\n",
            "Chose Action 2: 0.49954504094631486 < 0.5004549590536848\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1100\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1100\n",
            "Iteration 1101\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49954586739327883, action1_reward_count: 1101\n",
            "action2_reward: 1, action2_reward_avg: 0.5004541326067208, action2_reward_count: 1101\n",
            "Iteration 1102\n",
            "Chose Action 2: 0.49954586739327883 < 0.5004541326067208\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1102\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1102\n",
            "Iteration 1103\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.499546690843155, action1_reward_count: 1103\n",
            "action2_reward: 1, action2_reward_avg: 0.5004533091568446, action2_reward_count: 1103\n",
            "Iteration 1104\n",
            "Chose Action 2: 0.499546690843155 < 0.5004533091568446\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1104\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1104\n",
            "Iteration 1105\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4995475113122172, action1_reward_count: 1105\n",
            "action2_reward: 1, action2_reward_avg: 0.5004524886877825, action2_reward_count: 1105\n",
            "Iteration 1106\n",
            "Chose Action 2: 0.4995475113122172 < 0.5004524886877825\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1106\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1106\n",
            "Iteration 1107\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995483288166215, action1_reward_count: 1107\n",
            "action2_reward: 1, action2_reward_avg: 0.5004516711833782, action2_reward_count: 1107\n",
            "Iteration 1108\n",
            "Chose Action 2: 0.4995483288166215 < 0.5004516711833782\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1108\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1108\n",
            "Iteration 1109\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995491433724076, action1_reward_count: 1109\n",
            "action2_reward: 1, action2_reward_avg: 0.5004508566275921, action2_reward_count: 1109\n",
            "Iteration 1110\n",
            "Chose Action 2: 0.4995491433724076 < 0.5004508566275921\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1110\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1110\n",
            "Iteration 1111\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49954995499549953, action1_reward_count: 1111\n",
            "action2_reward: 1, action2_reward_avg: 0.5004500450045002, action2_reward_count: 1111\n",
            "Iteration 1112\n",
            "Chose Action 2: 0.49954995499549953 < 0.5004500450045002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1112\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1112\n",
            "Iteration 1113\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995507637017071, action1_reward_count: 1113\n",
            "action2_reward: 1, action2_reward_avg: 0.5004492362982926, action2_reward_count: 1113\n",
            "Iteration 1114\n",
            "Chose Action 2: 0.4995507637017071 < 0.5004492362982926\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1114\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1114\n",
            "Iteration 1115\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955156950672647, action1_reward_count: 1115\n",
            "action2_reward: 1, action2_reward_avg: 0.5004484304932733, action2_reward_count: 1115\n",
            "Iteration 1116\n",
            "Chose Action 2: 0.49955156950672647 < 0.5004484304932733\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1116\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1116\n",
            "Iteration 1117\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995523724261415, action1_reward_count: 1117\n",
            "action2_reward: 1, action2_reward_avg: 0.5004476275738583, action2_reward_count: 1117\n",
            "Iteration 1118\n",
            "Chose Action 2: 0.4995523724261415 < 0.5004476275738583\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1118\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1118\n",
            "Iteration 1119\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49955317247542447, action1_reward_count: 1119\n",
            "action2_reward: 1, action2_reward_avg: 0.5004468275245753, action2_reward_count: 1119\n",
            "Iteration 1120\n",
            "Chose Action 2: 0.49955317247542447 < 0.5004468275245753\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1120\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1120\n",
            "Iteration 1121\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955396966993754, action1_reward_count: 1121\n",
            "action2_reward: 1, action2_reward_avg: 0.5004460303300622, action2_reward_count: 1121\n",
            "Iteration 1122\n",
            "Chose Action 2: 0.49955396966993754 < 0.5004460303300622\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1122\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1122\n",
            "Iteration 1123\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995547640249332, action1_reward_count: 1123\n",
            "action2_reward: 1, action2_reward_avg: 0.5004452359750665, action2_reward_count: 1123\n",
            "Iteration 1124\n",
            "Chose Action 2: 0.4995547640249332 < 0.5004452359750665\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1124\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1124\n",
            "Iteration 1125\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49955555555555553, action1_reward_count: 1125\n",
            "action2_reward: 1, action2_reward_avg: 0.5004444444444441, action2_reward_count: 1125\n",
            "Iteration 1126\n",
            "Chose Action 2: 0.49955555555555553 < 0.5004444444444441\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1126\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1126\n",
            "Iteration 1127\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49955634427684115, action1_reward_count: 1127\n",
            "action2_reward: 1, action2_reward_avg: 0.5004436557231585, action2_reward_count: 1127\n",
            "Iteration 1128\n",
            "Chose Action 2: 0.49955634427684115 < 0.5004436557231585\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1128\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1128\n",
            "Iteration 1129\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995571302037201, action1_reward_count: 1129\n",
            "action2_reward: 1, action2_reward_avg: 0.5004428697962796, action2_reward_count: 1129\n",
            "Iteration 1130\n",
            "Chose Action 2: 0.4995571302037201 < 0.5004428697962796\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1130\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1130\n",
            "Iteration 1131\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995579133510168, action1_reward_count: 1131\n",
            "action2_reward: 1, action2_reward_avg: 0.5004420866489829, action2_reward_count: 1131\n",
            "Iteration 1132\n",
            "Chose Action 2: 0.4995579133510168 < 0.5004420866489829\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1132\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1132\n",
            "Iteration 1133\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.499558693733451, action1_reward_count: 1133\n",
            "action2_reward: 1, action2_reward_avg: 0.5004413062665487, action2_reward_count: 1133\n",
            "Iteration 1134\n",
            "Chose Action 2: 0.499558693733451 < 0.5004413062665487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1134\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1134\n",
            "Iteration 1135\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995594713656388, action1_reward_count: 1135\n",
            "action2_reward: 1, action2_reward_avg: 0.500440528634361, action2_reward_count: 1135\n",
            "Iteration 1136\n",
            "Chose Action 2: 0.4995594713656388 < 0.500440528634361\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1136\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1136\n",
            "Iteration 1137\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995602462620932, action1_reward_count: 1137\n",
            "action2_reward: 1, action2_reward_avg: 0.5004397537379065, action2_reward_count: 1137\n",
            "Iteration 1138\n",
            "Chose Action 2: 0.4995602462620932 < 0.5004397537379065\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1138\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1138\n",
            "Iteration 1139\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995610184372256, action1_reward_count: 1139\n",
            "action2_reward: 1, action2_reward_avg: 0.5004389815627741, action2_reward_count: 1139\n",
            "Iteration 1140\n",
            "Chose Action 2: 0.4995610184372256 < 0.5004389815627741\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1140\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1140\n",
            "Iteration 1141\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956178790534617, action1_reward_count: 1141\n",
            "action2_reward: 1, action2_reward_avg: 0.5004382120946536, action2_reward_count: 1141\n",
            "Iteration 1142\n",
            "Chose Action 2: 0.49956178790534617 < 0.5004382120946536\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1142\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1142\n",
            "Iteration 1143\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995625546806649, action1_reward_count: 1143\n",
            "action2_reward: 1, action2_reward_avg: 0.5004374453193348, action2_reward_count: 1143\n",
            "Iteration 1144\n",
            "Chose Action 2: 0.4995625546806649 < 0.5004374453193348\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1144\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1144\n",
            "Iteration 1145\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995633187772926, action1_reward_count: 1145\n",
            "action2_reward: 1, action2_reward_avg: 0.5004366812227071, action2_reward_count: 1145\n",
            "Iteration 1146\n",
            "Chose Action 2: 0.4995633187772926 < 0.5004366812227071\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1146\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1146\n",
            "Iteration 1147\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995640802092415, action1_reward_count: 1147\n",
            "action2_reward: 1, action2_reward_avg: 0.5004359197907582, action2_reward_count: 1147\n",
            "Iteration 1148\n",
            "Chose Action 2: 0.4995640802092415 < 0.5004359197907582\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1148\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1148\n",
            "Iteration 1149\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4995648389904265, action1_reward_count: 1149\n",
            "action2_reward: 1, action2_reward_avg: 0.5004351610095732, action2_reward_count: 1149\n",
            "Iteration 1150\n",
            "Chose Action 2: 0.4995648389904265 < 0.5004351610095732\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1150\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1150\n",
            "Iteration 1151\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49956559513466553, action1_reward_count: 1151\n",
            "action2_reward: 1, action2_reward_avg: 0.5004344048653342, action2_reward_count: 1151\n",
            "Iteration 1152\n",
            "Chose Action 2: 0.49956559513466553 < 0.5004344048653342\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1152\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1152\n",
            "Iteration 1153\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956634865568084, action1_reward_count: 1153\n",
            "action2_reward: 1, action2_reward_avg: 0.5004336513443189, action2_reward_count: 1153\n",
            "Iteration 1154\n",
            "Chose Action 2: 0.49956634865568084 < 0.5004336513443189\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1154\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1154\n",
            "Iteration 1155\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49956709956709955, action1_reward_count: 1155\n",
            "action2_reward: 1, action2_reward_avg: 0.5004329004329002, action2_reward_count: 1155\n",
            "Iteration 1156\n",
            "Chose Action 2: 0.49956709956709955 < 0.5004329004329002\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1156\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1156\n",
            "Iteration 1157\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995678478824546, action1_reward_count: 1157\n",
            "action2_reward: 1, action2_reward_avg: 0.5004321521175451, action2_reward_count: 1157\n",
            "Iteration 1158\n",
            "Chose Action 2: 0.4995678478824546 < 0.5004321521175451\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1158\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1158\n",
            "Iteration 1159\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4995685936151855, action1_reward_count: 1159\n",
            "action2_reward: 1, action2_reward_avg: 0.5004314063848142, action2_reward_count: 1159\n",
            "Iteration 1160\n",
            "Chose Action 2: 0.4995685936151855 < 0.5004314063848142\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1160\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1160\n",
            "Iteration 1161\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49956933677863913, action1_reward_count: 1161\n",
            "action2_reward: 1, action2_reward_avg: 0.5004306632213606, action2_reward_count: 1161\n",
            "Iteration 1162\n",
            "Chose Action 2: 0.49956933677863913 < 0.5004306632213606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1162\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1162\n",
            "Iteration 1163\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995700773860705, action1_reward_count: 1163\n",
            "action2_reward: 1, action2_reward_avg: 0.5004299226139293, action2_reward_count: 1163\n",
            "Iteration 1164\n",
            "Chose Action 2: 0.4995700773860705 < 0.5004299226139293\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1164\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1164\n",
            "Iteration 1165\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995708154506438, action1_reward_count: 1165\n",
            "action2_reward: 1, action2_reward_avg: 0.500429184549356, action2_reward_count: 1165\n",
            "Iteration 1166\n",
            "Chose Action 2: 0.4995708154506438 < 0.500429184549356\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1166\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1166\n",
            "Iteration 1167\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995715509854327, action1_reward_count: 1167\n",
            "action2_reward: 1, action2_reward_avg: 0.5004284490145671, action2_reward_count: 1167\n",
            "Iteration 1168\n",
            "Chose Action 2: 0.4995715509854327 < 0.5004284490145671\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1168\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1168\n",
            "Iteration 1169\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49957228400342174, action1_reward_count: 1169\n",
            "action2_reward: 1, action2_reward_avg: 0.5004277159965781, action2_reward_count: 1169\n",
            "Iteration 1170\n",
            "Chose Action 2: 0.49957228400342174 < 0.5004277159965781\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1170\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1170\n",
            "Iteration 1171\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995730145175064, action1_reward_count: 1171\n",
            "action2_reward: 1, action2_reward_avg: 0.5004269854824934, action2_reward_count: 1171\n",
            "Iteration 1172\n",
            "Chose Action 2: 0.4995730145175064 < 0.5004269854824934\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1172\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1172\n",
            "Iteration 1173\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957374254049447, action1_reward_count: 1173\n",
            "action2_reward: 1, action2_reward_avg: 0.5004262574595054, action2_reward_count: 1173\n",
            "Iteration 1174\n",
            "Chose Action 2: 0.49957374254049447 < 0.5004262574595054\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1174\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1174\n",
            "Iteration 1175\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49957446808510636, action1_reward_count: 1175\n",
            "action2_reward: 1, action2_reward_avg: 0.5004255319148935, action2_reward_count: 1175\n",
            "Iteration 1176\n",
            "Chose Action 2: 0.49957446808510636 < 0.5004255319148935\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1176\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1176\n",
            "Iteration 1177\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995751911639762, action1_reward_count: 1177\n",
            "action2_reward: 1, action2_reward_avg: 0.5004248088360236, action2_reward_count: 1177\n",
            "Iteration 1178\n",
            "Chose Action 2: 0.4995751911639762 < 0.5004248088360236\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1178\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1178\n",
            "Iteration 1179\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49957591178965227, action1_reward_count: 1179\n",
            "action2_reward: 1, action2_reward_avg: 0.5004240882103476, action2_reward_count: 1179\n",
            "Iteration 1180\n",
            "Chose Action 2: 0.49957591178965227 < 0.5004240882103476\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1180\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1180\n",
            "Iteration 1181\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995766299745978, action1_reward_count: 1181\n",
            "action2_reward: 1, action2_reward_avg: 0.500423370025402, action2_reward_count: 1181\n",
            "Iteration 1182\n",
            "Chose Action 2: 0.4995766299745978 < 0.500423370025402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1182\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1182\n",
            "Iteration 1183\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995773457311919, action1_reward_count: 1183\n",
            "action2_reward: 1, action2_reward_avg: 0.5004226542688079, action2_reward_count: 1183\n",
            "Iteration 1184\n",
            "Chose Action 2: 0.4995773457311919 < 0.5004226542688079\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1184\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1184\n",
            "Iteration 1185\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957805907173, action1_reward_count: 1185\n",
            "action2_reward: 1, action2_reward_avg: 0.5004219409282699, action2_reward_count: 1185\n",
            "Iteration 1186\n",
            "Chose Action 2: 0.49957805907173 < 0.5004219409282699\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1186\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1186\n",
            "Iteration 1187\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995787700084246, action1_reward_count: 1187\n",
            "action2_reward: 1, action2_reward_avg: 0.5004212299915752, action2_reward_count: 1187\n",
            "Iteration 1188\n",
            "Chose Action 2: 0.4995787700084246 < 0.5004212299915752\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1188\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1188\n",
            "Iteration 1189\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49957947855340623, action1_reward_count: 1189\n",
            "action2_reward: 1, action2_reward_avg: 0.5004205214465937, action2_reward_count: 1189\n",
            "Iteration 1190\n",
            "Chose Action 2: 0.49957947855340623 < 0.5004205214465937\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1190\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1190\n",
            "Iteration 1191\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995801847187238, action1_reward_count: 1191\n",
            "action2_reward: 1, action2_reward_avg: 0.5004198152812761, action2_reward_count: 1191\n",
            "Iteration 1192\n",
            "Chose Action 2: 0.4995801847187238 < 0.5004198152812761\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1192\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1192\n",
            "Iteration 1193\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49958088851634536, action1_reward_count: 1193\n",
            "action2_reward: 1, action2_reward_avg: 0.5004191114836546, action2_reward_count: 1193\n",
            "Iteration 1194\n",
            "Chose Action 2: 0.49958088851634536 < 0.5004191114836546\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1194\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1194\n",
            "Iteration 1195\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499581589958159, action1_reward_count: 1195\n",
            "action2_reward: 1, action2_reward_avg: 0.500418410041841, action2_reward_count: 1195\n",
            "Iteration 1196\n",
            "Chose Action 2: 0.499581589958159 < 0.500418410041841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1196\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1196\n",
            "Iteration 1197\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958228905597324, action1_reward_count: 1197\n",
            "action2_reward: 1, action2_reward_avg: 0.5004177109440267, action2_reward_count: 1197\n",
            "Iteration 1198\n",
            "Chose Action 2: 0.49958228905597324 < 0.5004177109440267\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1198\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1198\n",
            "Iteration 1199\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958298582151794, action1_reward_count: 1199\n",
            "action2_reward: 1, action2_reward_avg: 0.5004170141784821, action2_reward_count: 1199\n",
            "Iteration 1200\n",
            "Chose Action 2: 0.49958298582151794 < 0.5004170141784821\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1200\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1200\n",
            "Iteration 1201\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995836802664446, action1_reward_count: 1201\n",
            "action2_reward: 1, action2_reward_avg: 0.5004163197335554, action2_reward_count: 1201\n",
            "Iteration 1202\n",
            "Chose Action 2: 0.4995836802664446 < 0.5004163197335554\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1202\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1202\n",
            "Iteration 1203\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995843724023275, action1_reward_count: 1203\n",
            "action2_reward: 1, action2_reward_avg: 0.5004156275976724, action2_reward_count: 1203\n",
            "Iteration 1204\n",
            "Chose Action 2: 0.4995843724023275 < 0.5004156275976724\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1204\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1204\n",
            "Iteration 1205\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4995850622406639, action1_reward_count: 1205\n",
            "action2_reward: 1, action2_reward_avg: 0.5004149377593361, action2_reward_count: 1205\n",
            "Iteration 1206\n",
            "Chose Action 2: 0.4995850622406639 < 0.5004149377593361\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1206\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1206\n",
            "Iteration 1207\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.4995857497928749, action1_reward_count: 1207\n",
            "action2_reward: 1, action2_reward_avg: 0.5004142502071252, action2_reward_count: 1207\n",
            "Iteration 1208\n",
            "Chose Action 2: 0.4995857497928749 < 0.5004142502071252\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1208\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1208\n",
            "Iteration 1209\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49958643507030603, action1_reward_count: 1209\n",
            "action2_reward: 1, action2_reward_avg: 0.5004135649296939, action2_reward_count: 1209\n",
            "Iteration 1210\n",
            "Chose Action 2: 0.49958643507030603 < 0.5004135649296939\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1210\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1210\n",
            "Iteration 1211\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4995871180842279, action1_reward_count: 1211\n",
            "action2_reward: 1, action2_reward_avg: 0.500412881915772, action2_reward_count: 1211\n",
            "Iteration 1212\n",
            "Chose Action 2: 0.4995871180842279 < 0.500412881915772\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1212\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1212\n",
            "Iteration 1213\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958779884583676, action1_reward_count: 1213\n",
            "action2_reward: 1, action2_reward_avg: 0.5004122011541632, action2_reward_count: 1213\n",
            "Iteration 1214\n",
            "Chose Action 2: 0.49958779884583676 < 0.5004122011541632\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1214\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1214\n",
            "Iteration 1215\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958847736625517, action1_reward_count: 1215\n",
            "action2_reward: 1, action2_reward_avg: 0.5004115226337448, action2_reward_count: 1215\n",
            "Iteration 1216\n",
            "Chose Action 2: 0.49958847736625517 < 0.5004115226337448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1216\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1216\n",
            "Iteration 1217\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49958915365653245, action1_reward_count: 1217\n",
            "action2_reward: 1, action2_reward_avg: 0.5004108463434674, action2_reward_count: 1217\n",
            "Iteration 1218\n",
            "Chose Action 2: 0.49958915365653245 < 0.5004108463434674\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1218\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1218\n",
            "Iteration 1219\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995898277276456, action1_reward_count: 1219\n",
            "action2_reward: 1, action2_reward_avg: 0.5004101722723543, action2_reward_count: 1219\n",
            "Iteration 1220\n",
            "Chose Action 2: 0.4995898277276456 < 0.5004101722723543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1220\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1220\n",
            "Iteration 1221\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995904995904996, action1_reward_count: 1221\n",
            "action2_reward: 1, action2_reward_avg: 0.5004095004095003, action2_reward_count: 1221\n",
            "Iteration 1222\n",
            "Chose Action 2: 0.4995904995904996 < 0.5004095004095003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1222\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1222\n",
            "Iteration 1223\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959116925592806, action1_reward_count: 1223\n",
            "action2_reward: 1, action2_reward_avg: 0.5004088307440718, action2_reward_count: 1223\n",
            "Iteration 1224\n",
            "Chose Action 2: 0.49959116925592806 < 0.5004088307440718\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1224\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1224\n",
            "Iteration 1225\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4995918367346939, action1_reward_count: 1225\n",
            "action2_reward: 1, action2_reward_avg: 0.500408163265306, action2_reward_count: 1225\n",
            "Iteration 1226\n",
            "Chose Action 2: 0.4995918367346939 < 0.500408163265306\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1226\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1226\n",
            "Iteration 1227\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959250203748984, action1_reward_count: 1227\n",
            "action2_reward: 1, action2_reward_avg: 0.50040749796251, action2_reward_count: 1227\n",
            "Iteration 1228\n",
            "Chose Action 2: 0.49959250203748984 < 0.50040749796251\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1228\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1228\n",
            "Iteration 1229\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959316517493896, action1_reward_count: 1229\n",
            "action2_reward: 1, action2_reward_avg: 0.5004068348250609, action2_reward_count: 1229\n",
            "Iteration 1230\n",
            "Chose Action 2: 0.49959316517493896 < 0.5004068348250609\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1230\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1230\n",
            "Iteration 1231\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49959382615759546, action1_reward_count: 1231\n",
            "action2_reward: 1, action2_reward_avg: 0.5004061738424044, action2_reward_count: 1231\n",
            "Iteration 1232\n",
            "Chose Action 2: 0.49959382615759546 < 0.5004061738424044\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1232\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1232\n",
            "Iteration 1233\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49959448499594483, action1_reward_count: 1233\n",
            "action2_reward: 1, action2_reward_avg: 0.500405515004055, action2_reward_count: 1233\n",
            "Iteration 1234\n",
            "Chose Action 2: 0.49959448499594483 < 0.500405515004055\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1234\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1234\n",
            "Iteration 1235\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49959514170040487, action1_reward_count: 1235\n",
            "action2_reward: 1, action2_reward_avg: 0.5004048582995949, action2_reward_count: 1235\n",
            "Iteration 1236\n",
            "Chose Action 2: 0.49959514170040487 < 0.5004048582995949\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1236\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1236\n",
            "Iteration 1237\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995957962813258, action1_reward_count: 1237\n",
            "action2_reward: 1, action2_reward_avg: 0.500404203718674, action2_reward_count: 1237\n",
            "Iteration 1238\n",
            "Chose Action 2: 0.4995957962813258 < 0.500404203718674\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1238\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1238\n",
            "Iteration 1239\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995964487489911, action1_reward_count: 1239\n",
            "action2_reward: 1, action2_reward_avg: 0.5004035512510087, action2_reward_count: 1239\n",
            "Iteration 1240\n",
            "Chose Action 2: 0.4995964487489911 < 0.5004035512510087\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1240\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1240\n",
            "Iteration 1241\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49959709911361805, action1_reward_count: 1241\n",
            "action2_reward: 1, action2_reward_avg: 0.5004029008863817, action2_reward_count: 1241\n",
            "Iteration 1242\n",
            "Chose Action 2: 0.49959709911361805 < 0.5004029008863817\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1242\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1242\n",
            "Iteration 1243\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499597747385358, action1_reward_count: 1243\n",
            "action2_reward: 1, action2_reward_avg: 0.5004022526146418, action2_reward_count: 1243\n",
            "Iteration 1244\n",
            "Chose Action 2: 0.499597747385358 < 0.5004022526146418\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1244\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1244\n",
            "Iteration 1245\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4995983935742972, action1_reward_count: 1245\n",
            "action2_reward: 1, action2_reward_avg: 0.5004016064257026, action2_reward_count: 1245\n",
            "Iteration 1246\n",
            "Chose Action 2: 0.4995983935742972 < 0.5004016064257026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1246\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1246\n",
            "Iteration 1247\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4995990376904571, action1_reward_count: 1247\n",
            "action2_reward: 1, action2_reward_avg: 0.5004009623095428, action2_reward_count: 1247\n",
            "Iteration 1248\n",
            "Chose Action 2: 0.4995990376904571 < 0.5004009623095428\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1248\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1248\n",
            "Iteration 1249\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49959967974379504, action1_reward_count: 1249\n",
            "action2_reward: 1, action2_reward_avg: 0.5004003202562048, action2_reward_count: 1249\n",
            "Iteration 1250\n",
            "Chose Action 2: 0.49959967974379504 < 0.5004003202562048\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1250\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1250\n",
            "Iteration 1251\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49960031974420466, action1_reward_count: 1251\n",
            "action2_reward: 1, action2_reward_avg: 0.5003996802557953, action2_reward_count: 1251\n",
            "Iteration 1252\n",
            "Chose Action 2: 0.49960031974420466 < 0.5003996802557953\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1252\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1252\n",
            "Iteration 1253\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49960095770151636, action1_reward_count: 1253\n",
            "action2_reward: 1, action2_reward_avg: 0.5003990422984835, action2_reward_count: 1253\n",
            "Iteration 1254\n",
            "Chose Action 2: 0.49960095770151636 < 0.5003990422984835\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1254\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1254\n",
            "Iteration 1255\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.499601593625498, action1_reward_count: 1255\n",
            "action2_reward: 1, action2_reward_avg: 0.5003984063745018, action2_reward_count: 1255\n",
            "Iteration 1256\n",
            "Chose Action 2: 0.499601593625498 < 0.5003984063745018\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1256\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1256\n",
            "Iteration 1257\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996022275258552, action1_reward_count: 1257\n",
            "action2_reward: 1, action2_reward_avg: 0.5003977724741446, action2_reward_count: 1257\n",
            "Iteration 1258\n",
            "Chose Action 2: 0.4996022275258552 < 0.5003977724741446\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1258\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1258\n",
            "Iteration 1259\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996028594122319, action1_reward_count: 1259\n",
            "action2_reward: 1, action2_reward_avg: 0.5003971405877679, action2_reward_count: 1259\n",
            "Iteration 1260\n",
            "Chose Action 2: 0.4996028594122319 < 0.5003971405877679\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1260\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1260\n",
            "Iteration 1261\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49960348929421095, action1_reward_count: 1261\n",
            "action2_reward: 1, action2_reward_avg: 0.5003965107057888, action2_reward_count: 1261\n",
            "Iteration 1262\n",
            "Chose Action 2: 0.49960348929421095 < 0.5003965107057888\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1262\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1262\n",
            "Iteration 1263\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996041171813143, action1_reward_count: 1263\n",
            "action2_reward: 1, action2_reward_avg: 0.5003958828186854, action2_reward_count: 1263\n",
            "Iteration 1264\n",
            "Chose Action 2: 0.4996041171813143 < 0.5003958828186854\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1264\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1264\n",
            "Iteration 1265\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49960474308300395, action1_reward_count: 1265\n",
            "action2_reward: 1, action2_reward_avg: 0.5003952569169958, action2_reward_count: 1265\n",
            "Iteration 1266\n",
            "Chose Action 2: 0.49960474308300395 < 0.5003952569169958\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1266\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1266\n",
            "Iteration 1267\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996053670086819, action1_reward_count: 1267\n",
            "action2_reward: 1, action2_reward_avg: 0.5003946329913178, action2_reward_count: 1267\n",
            "Iteration 1268\n",
            "Chose Action 2: 0.4996053670086819 < 0.5003946329913178\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1268\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1268\n",
            "Iteration 1269\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996059889676911, action1_reward_count: 1269\n",
            "action2_reward: 1, action2_reward_avg: 0.5003940110323086, action2_reward_count: 1269\n",
            "Iteration 1270\n",
            "Chose Action 2: 0.4996059889676911 < 0.5003940110323086\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1270\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1270\n",
            "Iteration 1271\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996066089693155, action1_reward_count: 1271\n",
            "action2_reward: 1, action2_reward_avg: 0.5003933910306843, action2_reward_count: 1271\n",
            "Iteration 1272\n",
            "Chose Action 2: 0.4996066089693155 < 0.5003933910306843\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1272\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1272\n",
            "Iteration 1273\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996072270227808, action1_reward_count: 1273\n",
            "action2_reward: 1, action2_reward_avg: 0.500392772977219, action2_reward_count: 1273\n",
            "Iteration 1274\n",
            "Chose Action 2: 0.4996072270227808 < 0.500392772977219\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1274\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1274\n",
            "Iteration 1275\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996078431372549, action1_reward_count: 1275\n",
            "action2_reward: 1, action2_reward_avg: 0.5003921568627449, action2_reward_count: 1275\n",
            "Iteration 1276\n",
            "Chose Action 2: 0.4996078431372549 < 0.5003921568627449\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1276\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1276\n",
            "Iteration 1277\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49960845732184805, action1_reward_count: 1277\n",
            "action2_reward: 1, action2_reward_avg: 0.5003915426781517, action2_reward_count: 1277\n",
            "Iteration 1278\n",
            "Chose Action 2: 0.49960845732184805 < 0.5003915426781517\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1278\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1278\n",
            "Iteration 1279\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49960906958561374, action1_reward_count: 1279\n",
            "action2_reward: 1, action2_reward_avg: 0.500390930414386, action2_reward_count: 1279\n",
            "Iteration 1280\n",
            "Chose Action 2: 0.49960906958561374 < 0.500390930414386\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1280\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1280\n",
            "Iteration 1281\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996096799375488, action1_reward_count: 1281\n",
            "action2_reward: 1, action2_reward_avg: 0.5003903200624509, action2_reward_count: 1281\n",
            "Iteration 1282\n",
            "Chose Action 2: 0.4996096799375488 < 0.5003903200624509\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1282\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1282\n",
            "Iteration 1283\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961028838659394, action1_reward_count: 1283\n",
            "action2_reward: 1, action2_reward_avg: 0.5003897116134057, action2_reward_count: 1283\n",
            "Iteration 1284\n",
            "Chose Action 2: 0.49961028838659394 < 0.5003897116134057\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1284\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1284\n",
            "Iteration 1285\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961089494163424, action1_reward_count: 1285\n",
            "action2_reward: 1, action2_reward_avg: 0.5003891050583654, action2_reward_count: 1285\n",
            "Iteration 1286\n",
            "Chose Action 2: 0.49961089494163424 < 0.5003891050583654\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1286\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1286\n",
            "Iteration 1287\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4996114996114996, action1_reward_count: 1287\n",
            "action2_reward: 1, action2_reward_avg: 0.5003885003885, action2_reward_count: 1287\n",
            "Iteration 1288\n",
            "Chose Action 2: 0.4996114996114996 < 0.5003885003885\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1288\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1288\n",
            "Iteration 1289\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49961210240496506, action1_reward_count: 1289\n",
            "action2_reward: 1, action2_reward_avg: 0.5003878975950345, action2_reward_count: 1289\n",
            "Iteration 1290\n",
            "Chose Action 2: 0.49961210240496506 < 0.5003878975950345\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1290\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1290\n",
            "Iteration 1291\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49961270333075136, action1_reward_count: 1291\n",
            "action2_reward: 1, action2_reward_avg: 0.5003872966692483, action2_reward_count: 1291\n",
            "Iteration 1292\n",
            "Chose Action 2: 0.49961270333075136 < 0.5003872966692483\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1292\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1292\n",
            "Iteration 1293\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49961330239752516, action1_reward_count: 1293\n",
            "action2_reward: 1, action2_reward_avg: 0.5003866976024746, action2_reward_count: 1293\n",
            "Iteration 1294\n",
            "Chose Action 2: 0.49961330239752516 < 0.5003866976024746\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1294\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1294\n",
            "Iteration 1295\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996138996138996, action1_reward_count: 1295\n",
            "action2_reward: 1, action2_reward_avg: 0.5003861003861001, action2_reward_count: 1295\n",
            "Iteration 1296\n",
            "Chose Action 2: 0.4996138996138996 < 0.5003861003861001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1296\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1296\n",
            "Iteration 1297\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49961449498843485, action1_reward_count: 1297\n",
            "action2_reward: 1, action2_reward_avg: 0.5003855050115649, action2_reward_count: 1297\n",
            "Iteration 1298\n",
            "Chose Action 2: 0.49961449498843485 < 0.5003855050115649\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1298\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1298\n",
            "Iteration 1299\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996150885296382, action1_reward_count: 1299\n",
            "action2_reward: 1, action2_reward_avg: 0.5003849114703616, action2_reward_count: 1299\n",
            "Iteration 1300\n",
            "Chose Action 2: 0.4996150885296382 < 0.5003849114703616\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1300\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1300\n",
            "Iteration 1301\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961568024596464, action1_reward_count: 1301\n",
            "action2_reward: 1, action2_reward_avg: 0.5003843197540352, action2_reward_count: 1301\n",
            "Iteration 1302\n",
            "Chose Action 2: 0.49961568024596464 < 0.5003843197540352\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1302\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1302\n",
            "Iteration 1303\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49961627014581733, action1_reward_count: 1303\n",
            "action2_reward: 1, action2_reward_avg: 0.5003837298541824, action2_reward_count: 1303\n",
            "Iteration 1304\n",
            "Chose Action 2: 0.49961627014581733 < 0.5003837298541824\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1304\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1304\n",
            "Iteration 1305\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961685823754787, action1_reward_count: 1305\n",
            "action2_reward: 1, action2_reward_avg: 0.5003831417624519, action2_reward_count: 1305\n",
            "Iteration 1306\n",
            "Chose Action 2: 0.49961685823754787 < 0.5003831417624519\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1306\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1306\n",
            "Iteration 1307\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996174445294568, action1_reward_count: 1307\n",
            "action2_reward: 1, action2_reward_avg: 0.500382555470543, action2_reward_count: 1307\n",
            "Iteration 1308\n",
            "Chose Action 2: 0.4996174445294568 < 0.500382555470543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1308\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1308\n",
            "Iteration 1309\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49961802902979374, action1_reward_count: 1309\n",
            "action2_reward: 1, action2_reward_avg: 0.5003819709702061, action2_reward_count: 1309\n",
            "Iteration 1310\n",
            "Chose Action 2: 0.49961802902979374 < 0.5003819709702061\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1310\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1310\n",
            "Iteration 1311\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996186117467582, action1_reward_count: 1311\n",
            "action2_reward: 1, action2_reward_avg: 0.5003813882532416, action2_reward_count: 1311\n",
            "Iteration 1312\n",
            "Chose Action 2: 0.4996186117467582 < 0.5003813882532416\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1312\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1312\n",
            "Iteration 1313\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49961919268849964, action1_reward_count: 1313\n",
            "action2_reward: 1, action2_reward_avg: 0.5003808073115003, action2_reward_count: 1313\n",
            "Iteration 1314\n",
            "Chose Action 2: 0.49961919268849964 < 0.5003808073115003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1314\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1314\n",
            "Iteration 1315\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49961977186311785, action1_reward_count: 1315\n",
            "action2_reward: 1, action2_reward_avg: 0.500380228136882, action2_reward_count: 1315\n",
            "Iteration 1316\n",
            "Chose Action 2: 0.49961977186311785 < 0.500380228136882\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1316\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1316\n",
            "Iteration 1317\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996203492786636, action1_reward_count: 1317\n",
            "action2_reward: 1, action2_reward_avg: 0.5003796507213362, action2_reward_count: 1317\n",
            "Iteration 1318\n",
            "Chose Action 2: 0.4996203492786636 < 0.5003796507213362\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1318\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1318\n",
            "Iteration 1319\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49962092494313876, action1_reward_count: 1319\n",
            "action2_reward: 1, action2_reward_avg: 0.5003790750568611, action2_reward_count: 1319\n",
            "Iteration 1320\n",
            "Chose Action 2: 0.49962092494313876 < 0.5003790750568611\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1320\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1320\n",
            "Iteration 1321\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996214988644966, action1_reward_count: 1321\n",
            "action2_reward: 1, action2_reward_avg: 0.5003785011355032, action2_reward_count: 1321\n",
            "Iteration 1322\n",
            "Chose Action 2: 0.4996214988644966 < 0.5003785011355032\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1322\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1322\n",
            "Iteration 1323\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996220710506425, action1_reward_count: 1323\n",
            "action2_reward: 1, action2_reward_avg: 0.5003779289493573, action2_reward_count: 1323\n",
            "Iteration 1324\n",
            "Chose Action 2: 0.4996220710506425 < 0.5003779289493573\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1324\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1324\n",
            "Iteration 1325\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.499622641509434, action1_reward_count: 1325\n",
            "action2_reward: 1, action2_reward_avg: 0.5003773584905659, action2_reward_count: 1325\n",
            "Iteration 1326\n",
            "Chose Action 2: 0.499622641509434 < 0.5003773584905659\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1326\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1326\n",
            "Iteration 1327\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996232102486812, action1_reward_count: 1327\n",
            "action2_reward: 1, action2_reward_avg: 0.5003767897513186, action2_reward_count: 1327\n",
            "Iteration 1328\n",
            "Chose Action 2: 0.4996232102486812 < 0.5003767897513186\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1328\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1328\n",
            "Iteration 1329\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996237772761475, action1_reward_count: 1329\n",
            "action2_reward: 1, action2_reward_avg: 0.5003762227238524, action2_reward_count: 1329\n",
            "Iteration 1330\n",
            "Chose Action 2: 0.4996237772761475 < 0.5003762227238524\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1330\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1330\n",
            "Iteration 1331\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996243425995492, action1_reward_count: 1331\n",
            "action2_reward: 1, action2_reward_avg: 0.5003756574004506, action2_reward_count: 1331\n",
            "Iteration 1332\n",
            "Chose Action 2: 0.4996243425995492 < 0.5003756574004506\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1332\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1332\n",
            "Iteration 1333\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49962490622655664, action1_reward_count: 1333\n",
            "action2_reward: 1, action2_reward_avg: 0.5003750937734432, action2_reward_count: 1333\n",
            "Iteration 1334\n",
            "Chose Action 2: 0.49962490622655664 < 0.5003750937734432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1334\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1334\n",
            "Iteration 1335\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962546816479403, action1_reward_count: 1335\n",
            "action2_reward: 1, action2_reward_avg: 0.5003745318352059, action2_reward_count: 1335\n",
            "Iteration 1336\n",
            "Chose Action 2: 0.49962546816479403 < 0.5003745318352059\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1336\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1336\n",
            "Iteration 1337\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962602842183995, action1_reward_count: 1337\n",
            "action2_reward: 1, action2_reward_avg: 0.50037397157816, action2_reward_count: 1337\n",
            "Iteration 1338\n",
            "Chose Action 2: 0.49962602842183995 < 0.50037397157816\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1338\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1338\n",
            "Iteration 1339\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996265870052278, action1_reward_count: 1339\n",
            "action2_reward: 1, action2_reward_avg: 0.5003734129947721, action2_reward_count: 1339\n",
            "Iteration 1340\n",
            "Chose Action 2: 0.4996265870052278 < 0.5003734129947721\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1340\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1340\n",
            "Iteration 1341\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962714392244595, action1_reward_count: 1341\n",
            "action2_reward: 1, action2_reward_avg: 0.500372856077554, action2_reward_count: 1341\n",
            "Iteration 1342\n",
            "Chose Action 2: 0.49962714392244595 < 0.500372856077554\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1342\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1342\n",
            "Iteration 1343\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996276991809382, action1_reward_count: 1343\n",
            "action2_reward: 1, action2_reward_avg: 0.5003723008190617, action2_reward_count: 1343\n",
            "Iteration 1344\n",
            "Chose Action 2: 0.4996276991809382 < 0.5003723008190617\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1344\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1344\n",
            "Iteration 1345\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996282527881041, action1_reward_count: 1345\n",
            "action2_reward: 1, action2_reward_avg: 0.5003717472118958, action2_reward_count: 1345\n",
            "Iteration 1346\n",
            "Chose Action 2: 0.4996282527881041 < 0.5003717472118958\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1346\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1346\n",
            "Iteration 1347\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49962880475129917, action1_reward_count: 1347\n",
            "action2_reward: 1, action2_reward_avg: 0.5003711952487007, action2_reward_count: 1347\n",
            "Iteration 1348\n",
            "Chose Action 2: 0.49962880475129917 < 0.5003711952487007\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1348\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1348\n",
            "Iteration 1349\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49962935507783546, action1_reward_count: 1349\n",
            "action2_reward: 1, action2_reward_avg: 0.5003706449221644, action2_reward_count: 1349\n",
            "Iteration 1350\n",
            "Chose Action 2: 0.49962935507783546 < 0.5003706449221644\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1350\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1350\n",
            "Iteration 1351\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996299037749815, action1_reward_count: 1351\n",
            "action2_reward: 1, action2_reward_avg: 0.5003700962250184, action2_reward_count: 1351\n",
            "Iteration 1352\n",
            "Chose Action 2: 0.4996299037749815 < 0.5003700962250184\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1352\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1352\n",
            "Iteration 1353\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963045084996305, action1_reward_count: 1353\n",
            "action2_reward: 1, action2_reward_avg: 0.5003695491500368, action2_reward_count: 1353\n",
            "Iteration 1354\n",
            "Chose Action 2: 0.49963045084996305 < 0.5003695491500368\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1354\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1354\n",
            "Iteration 1355\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996309963099631, action1_reward_count: 1355\n",
            "action2_reward: 1, action2_reward_avg: 0.5003690036900368, action2_reward_count: 1355\n",
            "Iteration 1356\n",
            "Chose Action 2: 0.4996309963099631 < 0.5003690036900368\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1356\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1356\n",
            "Iteration 1357\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963154016212236, action1_reward_count: 1357\n",
            "action2_reward: 1, action2_reward_avg: 0.5003684598378776, action2_reward_count: 1357\n",
            "Iteration 1358\n",
            "Chose Action 2: 0.49963154016212236 < 0.5003684598378776\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1358\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1358\n",
            "Iteration 1359\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49963208241353935, action1_reward_count: 1359\n",
            "action2_reward: 1, action2_reward_avg: 0.5003679175864606, action2_reward_count: 1359\n",
            "Iteration 1360\n",
            "Chose Action 2: 0.49963208241353935 < 0.5003679175864606\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1360\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1360\n",
            "Iteration 1361\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996326230712711, action1_reward_count: 1361\n",
            "action2_reward: 1, action2_reward_avg: 0.5003673769287288, action2_reward_count: 1361\n",
            "Iteration 1362\n",
            "Chose Action 2: 0.4996326230712711 < 0.5003673769287288\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1362\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1362\n",
            "Iteration 1363\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996331621423331, action1_reward_count: 1363\n",
            "action2_reward: 1, action2_reward_avg: 0.5003668378576668, action2_reward_count: 1363\n",
            "Iteration 1364\n",
            "Chose Action 2: 0.4996331621423331 < 0.5003668378576668\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1364\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1364\n",
            "Iteration 1365\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963369963369964, action1_reward_count: 1365\n",
            "action2_reward: 1, action2_reward_avg: 0.5003663003663003, action2_reward_count: 1365\n",
            "Iteration 1366\n",
            "Chose Action 2: 0.49963369963369964 < 0.5003663003663003\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1366\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1366\n",
            "Iteration 1367\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996342355523043, action1_reward_count: 1367\n",
            "action2_reward: 1, action2_reward_avg: 0.5003657644476955, action2_reward_count: 1367\n",
            "Iteration 1368\n",
            "Chose Action 2: 0.4996342355523043 < 0.5003657644476955\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1368\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1368\n",
            "Iteration 1369\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996347699050402, action1_reward_count: 1369\n",
            "action2_reward: 1, action2_reward_avg: 0.5003652300949597, action2_reward_count: 1369\n",
            "Iteration 1370\n",
            "Chose Action 2: 0.4996347699050402 < 0.5003652300949597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1370\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1370\n",
            "Iteration 1371\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963530269876005, action1_reward_count: 1371\n",
            "action2_reward: 1, action2_reward_avg: 0.5003646973012399, action2_reward_count: 1371\n",
            "Iteration 1372\n",
            "Chose Action 2: 0.49963530269876005 < 0.5003646973012399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1372\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1372\n",
            "Iteration 1373\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996358339402768, action1_reward_count: 1373\n",
            "action2_reward: 1, action2_reward_avg: 0.5003641660597232, action2_reward_count: 1373\n",
            "Iteration 1374\n",
            "Chose Action 2: 0.4996358339402768 < 0.5003641660597232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1374\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1374\n",
            "Iteration 1375\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963636363636366, action1_reward_count: 1375\n",
            "action2_reward: 1, action2_reward_avg: 0.5003636363636363, action2_reward_count: 1375\n",
            "Iteration 1376\n",
            "Chose Action 2: 0.49963636363636366 < 0.5003636363636363\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1376\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1376\n",
            "Iteration 1377\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963689179375453, action1_reward_count: 1377\n",
            "action2_reward: 1, action2_reward_avg: 0.5003631082062454, action2_reward_count: 1377\n",
            "Iteration 1378\n",
            "Chose Action 2: 0.49963689179375453 < 0.5003631082062454\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1378\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1378\n",
            "Iteration 1379\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49963741841914433, action1_reward_count: 1379\n",
            "action2_reward: 1, action2_reward_avg: 0.5003625815808557, action2_reward_count: 1379\n",
            "Iteration 1380\n",
            "Chose Action 2: 0.49963741841914433 < 0.5003625815808557\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1380\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1380\n",
            "Iteration 1381\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.499637943519189, action1_reward_count: 1381\n",
            "action2_reward: 1, action2_reward_avg: 0.500362056480811, action2_reward_count: 1381\n",
            "Iteration 1382\n",
            "Chose Action 2: 0.499637943519189 < 0.500362056480811\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1382\n",
            "action2_reward: 0, action2_reward_avg: 0.5, action2_reward_count: 1382\n",
            "Iteration 1383\n",
            "Chose Action 1: 0.5 >= 0.5\n",
            "action1_reward: 0, action1_reward_avg: 0.49963846710050613, action1_reward_count: 1383\n",
            "action2_reward: 1, action2_reward_avg: 0.5003615328994938, action2_reward_count: 1383\n",
            "Iteration 1384\n",
            "Chose Action 2: 0.49963846710050613 < 0.5003615328994938\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1384\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999994, action2_reward_count: 1384\n",
            "Iteration 1385\n",
            "Chose Action 1: 0.5 >= 0.49999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996389891696751, action1_reward_count: 1385\n",
            "action2_reward: 1, action2_reward_avg: 0.5003610108303248, action2_reward_count: 1385\n",
            "Iteration 1386\n",
            "Chose Action 2: 0.4996389891696751 < 0.5003610108303248\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1386\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1386\n",
            "Iteration 1387\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.49963950973323723, action1_reward_count: 1387\n",
            "action2_reward: 1, action2_reward_avg: 0.5003604902667627, action2_reward_count: 1387\n",
            "Iteration 1388\n",
            "Chose Action 2: 0.49963950973323723 < 0.5003604902667627\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1388\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1388\n",
            "Iteration 1389\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996400287976962, action1_reward_count: 1389\n",
            "action2_reward: 1, action2_reward_avg: 0.5003599712023037, action2_reward_count: 1389\n",
            "Iteration 1390\n",
            "Chose Action 2: 0.4996400287976962 < 0.5003599712023037\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1390\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999999, action2_reward_count: 1390\n",
            "Iteration 1391\n",
            "Chose Action 1: 0.5 >= 0.4999999999999999\n",
            "action1_reward: 0, action1_reward_avg: 0.4996405463695183, action1_reward_count: 1391\n",
            "action2_reward: 1, action2_reward_avg: 0.5003594536304815, action2_reward_count: 1391\n",
            "Iteration 1392\n",
            "Chose Action 2: 0.4996405463695183 < 0.5003594536304815\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1392\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1392\n",
            "Iteration 1393\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996410624551328, action1_reward_count: 1393\n",
            "action2_reward: 1, action2_reward_avg: 0.500358937544867, action2_reward_count: 1393\n",
            "Iteration 1394\n",
            "Chose Action 2: 0.4996410624551328 < 0.500358937544867\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1394\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1394\n",
            "Iteration 1395\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996415770609319, action1_reward_count: 1395\n",
            "action2_reward: 1, action2_reward_avg: 0.500358422939068, action2_reward_count: 1395\n",
            "Iteration 1396\n",
            "Chose Action 2: 0.4996415770609319 < 0.500358422939068\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1396\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1396\n",
            "Iteration 1397\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.49964209019327127, action1_reward_count: 1397\n",
            "action2_reward: 1, action2_reward_avg: 0.5003579098067286, action2_reward_count: 1397\n",
            "Iteration 1398\n",
            "Chose Action 2: 0.49964209019327127 < 0.5003579098067286\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1398\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1398\n",
            "Iteration 1399\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996426018584703, action1_reward_count: 1399\n",
            "action2_reward: 1, action2_reward_avg: 0.5003573981415295, action2_reward_count: 1399\n",
            "Iteration 1400\n",
            "Chose Action 2: 0.4996426018584703 < 0.5003573981415295\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1400\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1400\n",
            "Iteration 1401\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964311206281226, action1_reward_count: 1401\n",
            "action2_reward: 1, action2_reward_avg: 0.5003568879371875, action2_reward_count: 1401\n",
            "Iteration 1402\n",
            "Chose Action 2: 0.49964311206281226 < 0.5003568879371875\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1402\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1402\n",
            "Iteration 1403\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49964362081254454, action1_reward_count: 1403\n",
            "action2_reward: 1, action2_reward_avg: 0.5003563791874551, action2_reward_count: 1403\n",
            "Iteration 1404\n",
            "Chose Action 2: 0.49964362081254454 < 0.5003563791874551\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1404\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1404\n",
            "Iteration 1405\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.499644128113879, action1_reward_count: 1405\n",
            "action2_reward: 1, action2_reward_avg: 0.5003558718861206, action2_reward_count: 1405\n",
            "Iteration 1406\n",
            "Chose Action 2: 0.499644128113879 < 0.5003558718861206\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1406\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1406\n",
            "Iteration 1407\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996446339729922, action1_reward_count: 1407\n",
            "action2_reward: 1, action2_reward_avg: 0.5003553660270075, action2_reward_count: 1407\n",
            "Iteration 1408\n",
            "Chose Action 2: 0.4996446339729922 < 0.5003553660270075\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1408\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1408\n",
            "Iteration 1409\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49964513839602553, action1_reward_count: 1409\n",
            "action2_reward: 1, action2_reward_avg: 0.5003548616039741, action2_reward_count: 1409\n",
            "Iteration 1410\n",
            "Chose Action 2: 0.49964513839602553 < 0.5003548616039741\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1410\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1410\n",
            "Iteration 1411\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49964564138908574, action1_reward_count: 1411\n",
            "action2_reward: 1, action2_reward_avg: 0.5003543586109139, action2_reward_count: 1411\n",
            "Iteration 1412\n",
            "Chose Action 2: 0.49964564138908574 < 0.5003543586109139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1412\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1412\n",
            "Iteration 1413\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.4996461429582449, action1_reward_count: 1413\n",
            "action2_reward: 1, action2_reward_avg: 0.5003538570417548, action2_reward_count: 1413\n",
            "Iteration 1414\n",
            "Chose Action 2: 0.4996461429582449 < 0.5003538570417548\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1414\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1414\n",
            "Iteration 1415\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.49964664310954066, action1_reward_count: 1415\n",
            "action2_reward: 1, action2_reward_avg: 0.5003533568904591, action2_reward_count: 1415\n",
            "Iteration 1416\n",
            "Chose Action 2: 0.49964664310954066 < 0.5003533568904591\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1416\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1416\n",
            "Iteration 1417\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964714184897674, action1_reward_count: 1417\n",
            "action2_reward: 1, action2_reward_avg: 0.500352858151023, action2_reward_count: 1417\n",
            "Iteration 1418\n",
            "Chose Action 2: 0.49964714184897674 < 0.500352858151023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1418\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1418\n",
            "Iteration 1419\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996476391825229, action1_reward_count: 1419\n",
            "action2_reward: 1, action2_reward_avg: 0.5003523608174769, action2_reward_count: 1419\n",
            "Iteration 1420\n",
            "Chose Action 2: 0.4996476391825229 < 0.5003523608174769\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1420\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999983, action2_reward_count: 1420\n",
            "Iteration 1421\n",
            "Chose Action 1: 0.5 >= 0.49999999999999983\n",
            "action1_reward: 0, action1_reward_avg: 0.4996481351161154, action1_reward_count: 1421\n",
            "action2_reward: 1, action2_reward_avg: 0.5003518648838844, action2_reward_count: 1421\n",
            "Iteration 1422\n",
            "Chose Action 2: 0.4996481351161154 < 0.5003518648838844\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1422\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1422\n",
            "Iteration 1423\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964862965565704, action1_reward_count: 1423\n",
            "action2_reward: 1, action2_reward_avg: 0.5003513703443427, action2_reward_count: 1423\n",
            "Iteration 1424\n",
            "Chose Action 2: 0.49964862965565704 < 0.5003513703443427\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1424\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1424\n",
            "Iteration 1425\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964912280701756, action1_reward_count: 1425\n",
            "action2_reward: 1, action2_reward_avg: 0.5003508771929822, action2_reward_count: 1425\n",
            "Iteration 1426\n",
            "Chose Action 2: 0.49964912280701756 < 0.5003508771929822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1426\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1426\n",
            "Iteration 1427\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.49964961457603363, action1_reward_count: 1427\n",
            "action2_reward: 1, action2_reward_avg: 0.5003503854239661, action2_reward_count: 1427\n",
            "Iteration 1428\n",
            "Chose Action 2: 0.49964961457603363 < 0.5003503854239661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1428\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999998, action2_reward_count: 1428\n",
            "Iteration 1429\n",
            "Chose Action 1: 0.5 >= 0.4999999999999998\n",
            "action1_reward: 0, action1_reward_avg: 0.4996501049685094, action1_reward_count: 1429\n",
            "action2_reward: 1, action2_reward_avg: 0.5003498950314903, action2_reward_count: 1429\n",
            "Iteration 1430\n",
            "Chose Action 2: 0.4996501049685094 < 0.5003498950314903\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1430\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999997, action2_reward_count: 1430\n",
            "Iteration 1431\n",
            "Chose Action 1: 0.5 >= 0.4999999999999997\n",
            "action1_reward: 0, action1_reward_avg: 0.4996505939902166, action1_reward_count: 1431\n",
            "action2_reward: 1, action2_reward_avg: 0.5003494060097831, action2_reward_count: 1431\n",
            "Iteration 1432\n",
            "Chose Action 2: 0.4996505939902166 < 0.5003494060097831\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1432\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1432\n",
            "Iteration 1433\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49965108164689465, action1_reward_count: 1433\n",
            "action2_reward: 1, action2_reward_avg: 0.500348918353105, action2_reward_count: 1433\n",
            "Iteration 1434\n",
            "Chose Action 2: 0.49965108164689465 < 0.500348918353105\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1434\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999967, action2_reward_count: 1434\n",
            "Iteration 1435\n",
            "Chose Action 1: 0.5 >= 0.49999999999999967\n",
            "action1_reward: 0, action1_reward_avg: 0.49965156794425086, action1_reward_count: 1435\n",
            "action2_reward: 1, action2_reward_avg: 0.5003484320557487, action2_reward_count: 1435\n",
            "Iteration 1436\n",
            "Chose Action 2: 0.49965156794425086 < 0.5003484320557487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1436\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1436\n",
            "Iteration 1437\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49965205288796105, action1_reward_count: 1437\n",
            "action2_reward: 1, action2_reward_avg: 0.5003479471120386, action2_reward_count: 1437\n",
            "Iteration 1438\n",
            "Chose Action 2: 0.49965205288796105 < 0.5003479471120386\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1438\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1438\n",
            "Iteration 1439\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996525364836692, action1_reward_count: 1439\n",
            "action2_reward: 1, action2_reward_avg: 0.5003474635163304, action2_reward_count: 1439\n",
            "Iteration 1440\n",
            "Chose Action 2: 0.4996525364836692 < 0.5003474635163304\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1440\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1440\n",
            "Iteration 1441\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4996530187369882, action1_reward_count: 1441\n",
            "action2_reward: 1, action2_reward_avg: 0.5003469812630114, action2_reward_count: 1441\n",
            "Iteration 1442\n",
            "Chose Action 2: 0.4996530187369882 < 0.5003469812630114\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1442\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1442\n",
            "Iteration 1443\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49965349965349964, action1_reward_count: 1443\n",
            "action2_reward: 1, action2_reward_avg: 0.5003465003464999, action2_reward_count: 1443\n",
            "Iteration 1444\n",
            "Chose Action 2: 0.49965349965349964 < 0.5003465003464999\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1444\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1444\n",
            "Iteration 1445\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996539792387543, action1_reward_count: 1445\n",
            "action2_reward: 1, action2_reward_avg: 0.5003460207612451, action2_reward_count: 1445\n",
            "Iteration 1446\n",
            "Chose Action 2: 0.4996539792387543 < 0.5003460207612451\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1446\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1446\n",
            "Iteration 1447\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996544574982723, action1_reward_count: 1447\n",
            "action2_reward: 1, action2_reward_avg: 0.5003455425017271, action2_reward_count: 1447\n",
            "Iteration 1448\n",
            "Chose Action 2: 0.4996544574982723 < 0.5003455425017271\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1448\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1448\n",
            "Iteration 1449\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996549344375431, action1_reward_count: 1449\n",
            "action2_reward: 1, action2_reward_avg: 0.5003450655624563, action2_reward_count: 1449\n",
            "Iteration 1450\n",
            "Chose Action 2: 0.4996549344375431 < 0.5003450655624563\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1450\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1450\n",
            "Iteration 1451\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996554100620262, action1_reward_count: 1451\n",
            "action2_reward: 1, action2_reward_avg: 0.5003445899379731, action2_reward_count: 1451\n",
            "Iteration 1452\n",
            "Chose Action 2: 0.4996554100620262 < 0.5003445899379731\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1452\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1452\n",
            "Iteration 1453\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49965588437715075, action1_reward_count: 1453\n",
            "action2_reward: 1, action2_reward_avg: 0.5003441156228486, action2_reward_count: 1453\n",
            "Iteration 1454\n",
            "Chose Action 2: 0.49965588437715075 < 0.5003441156228486\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1454\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1454\n",
            "Iteration 1455\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49965635738831615, action1_reward_count: 1455\n",
            "action2_reward: 1, action2_reward_avg: 0.5003436426116833, action2_reward_count: 1455\n",
            "Iteration 1456\n",
            "Chose Action 2: 0.49965635738831615 < 0.5003436426116833\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1456\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1456\n",
            "Iteration 1457\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49965682910089226, action1_reward_count: 1457\n",
            "action2_reward: 1, action2_reward_avg: 0.5003431708991072, action2_reward_count: 1457\n",
            "Iteration 1458\n",
            "Chose Action 2: 0.49965682910089226 < 0.5003431708991072\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1458\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1458\n",
            "Iteration 1459\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996572995202193, action1_reward_count: 1459\n",
            "action2_reward: 1, action2_reward_avg: 0.5003427004797801, action2_reward_count: 1459\n",
            "Iteration 1460\n",
            "Chose Action 2: 0.4996572995202193 < 0.5003427004797801\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1460\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1460\n",
            "Iteration 1461\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996577686516085, action1_reward_count: 1461\n",
            "action2_reward: 1, action2_reward_avg: 0.500342231348391, action2_reward_count: 1461\n",
            "Iteration 1462\n",
            "Chose Action 2: 0.4996577686516085 < 0.500342231348391\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1462\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1462\n",
            "Iteration 1463\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49965823650034175, action1_reward_count: 1463\n",
            "action2_reward: 1, action2_reward_avg: 0.5003417634996576, action2_reward_count: 1463\n",
            "Iteration 1464\n",
            "Chose Action 2: 0.49965823650034175 < 0.5003417634996576\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1464\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1464\n",
            "Iteration 1465\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49965870307167237, action1_reward_count: 1465\n",
            "action2_reward: 1, action2_reward_avg: 0.5003412969283271, action2_reward_count: 1465\n",
            "Iteration 1466\n",
            "Chose Action 2: 0.49965870307167237 < 0.5003412969283271\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1466\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1466\n",
            "Iteration 1467\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996591683708248, action1_reward_count: 1467\n",
            "action2_reward: 1, action2_reward_avg: 0.5003408316291746, action2_reward_count: 1467\n",
            "Iteration 1468\n",
            "Chose Action 2: 0.4996591683708248 < 0.5003408316291746\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1468\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1468\n",
            "Iteration 1469\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996596324029952, action1_reward_count: 1469\n",
            "action2_reward: 1, action2_reward_avg: 0.5003403675970042, action2_reward_count: 1469\n",
            "Iteration 1470\n",
            "Chose Action 2: 0.4996596324029952 < 0.5003403675970042\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1470\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1470\n",
            "Iteration 1471\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966009517335147, action1_reward_count: 1471\n",
            "action2_reward: 1, action2_reward_avg: 0.5003399048266479, action2_reward_count: 1471\n",
            "Iteration 1472\n",
            "Chose Action 2: 0.49966009517335147 < 0.5003399048266479\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1472\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1472\n",
            "Iteration 1473\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966055668703324, action1_reward_count: 1473\n",
            "action2_reward: 1, action2_reward_avg: 0.5003394433129661, action2_reward_count: 1473\n",
            "Iteration 1474\n",
            "Chose Action 2: 0.49966055668703324 < 0.5003394433129661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1474\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1474\n",
            "Iteration 1475\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966101694915255, action1_reward_count: 1475\n",
            "action2_reward: 1, action2_reward_avg: 0.5003389830508468, action2_reward_count: 1475\n",
            "Iteration 1476\n",
            "Chose Action 2: 0.49966101694915255 < 0.5003389830508468\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1476\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1476\n",
            "Iteration 1477\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996614759647935, action1_reward_count: 1477\n",
            "action2_reward: 1, action2_reward_avg: 0.5003385240352058, action2_reward_count: 1477\n",
            "Iteration 1478\n",
            "Chose Action 2: 0.4996614759647935 < 0.5003385240352058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1478\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1478\n",
            "Iteration 1479\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966193373901285, action1_reward_count: 1479\n",
            "action2_reward: 1, action2_reward_avg: 0.5003380662609865, action2_reward_count: 1479\n",
            "Iteration 1480\n",
            "Chose Action 2: 0.49966193373901285 < 0.5003380662609865\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1480\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1480\n",
            "Iteration 1481\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49966239027683995, action1_reward_count: 1481\n",
            "action2_reward: 1, action2_reward_avg: 0.5003376097231594, action2_reward_count: 1481\n",
            "Iteration 1482\n",
            "Chose Action 2: 0.49966239027683995 < 0.5003376097231594\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1482\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1482\n",
            "Iteration 1483\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996628455832771, action1_reward_count: 1483\n",
            "action2_reward: 1, action2_reward_avg: 0.5003371544167222, action2_reward_count: 1483\n",
            "Iteration 1484\n",
            "Chose Action 2: 0.4996628455832771 < 0.5003371544167222\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1484\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1484\n",
            "Iteration 1485\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49966329966329964, action1_reward_count: 1485\n",
            "action2_reward: 1, action2_reward_avg: 0.5003367003366996, action2_reward_count: 1485\n",
            "Iteration 1486\n",
            "Chose Action 2: 0.49966329966329964 < 0.5003367003366996\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1486\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1486\n",
            "Iteration 1487\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996637525218561, action1_reward_count: 1487\n",
            "action2_reward: 1, action2_reward_avg: 0.5003362474781432, action2_reward_count: 1487\n",
            "Iteration 1488\n",
            "Chose Action 2: 0.4996637525218561 < 0.5003362474781432\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1488\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1488\n",
            "Iteration 1489\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49966420416386836, action1_reward_count: 1489\n",
            "action2_reward: 1, action2_reward_avg: 0.5003357958361309, action2_reward_count: 1489\n",
            "Iteration 1490\n",
            "Chose Action 2: 0.49966420416386836 < 0.5003357958361309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1490\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1490\n",
            "Iteration 1491\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49966465459423204, action1_reward_count: 1491\n",
            "action2_reward: 1, action2_reward_avg: 0.5003353454057672, action2_reward_count: 1491\n",
            "Iteration 1492\n",
            "Chose Action 2: 0.49966465459423204 < 0.5003353454057672\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1492\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1492\n",
            "Iteration 1493\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.4996651038178165, action1_reward_count: 1493\n",
            "action2_reward: 1, action2_reward_avg: 0.5003348961821827, action2_reward_count: 1493\n",
            "Iteration 1494\n",
            "Chose Action 2: 0.4996651038178165 < 0.5003348961821827\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1494\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1494\n",
            "Iteration 1495\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49966555183946487, action1_reward_count: 1495\n",
            "action2_reward: 1, action2_reward_avg: 0.5003344481605343, action2_reward_count: 1495\n",
            "Iteration 1496\n",
            "Chose Action 2: 0.49966555183946487 < 0.5003344481605343\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1496\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1496\n",
            "Iteration 1497\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.49966599866399464, action1_reward_count: 1497\n",
            "action2_reward: 1, action2_reward_avg: 0.5003340013360045, action2_reward_count: 1497\n",
            "Iteration 1498\n",
            "Chose Action 2: 0.49966599866399464 < 0.5003340013360045\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1498\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1498\n",
            "Iteration 1499\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966644429619744, action1_reward_count: 1499\n",
            "action2_reward: 1, action2_reward_avg: 0.5003335557038017, action2_reward_count: 1499\n",
            "Iteration 1500\n",
            "Chose Action 2: 0.49966644429619744 < 0.5003335557038017\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1500\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1500\n",
            "Iteration 1501\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996668887408394, action1_reward_count: 1501\n",
            "action2_reward: 1, action2_reward_avg: 0.5003331112591597, action2_reward_count: 1501\n",
            "Iteration 1502\n",
            "Chose Action 2: 0.4996668887408394 < 0.5003331112591597\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1502\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1502\n",
            "Iteration 1503\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966733200266134, action1_reward_count: 1503\n",
            "action2_reward: 1, action2_reward_avg: 0.5003326679973378, action2_reward_count: 1503\n",
            "Iteration 1504\n",
            "Chose Action 2: 0.49966733200266134 < 0.5003326679973378\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1504\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1504\n",
            "Iteration 1505\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966777408637875, action1_reward_count: 1505\n",
            "action2_reward: 1, action2_reward_avg: 0.5003322259136204, action2_reward_count: 1505\n",
            "Iteration 1506\n",
            "Chose Action 2: 0.49966777408637875 < 0.5003322259136204\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1506\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1506\n",
            "Iteration 1507\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996682149966821, action1_reward_count: 1507\n",
            "action2_reward: 1, action2_reward_avg: 0.500331785003317, action2_reward_count: 1507\n",
            "Iteration 1508\n",
            "Chose Action 2: 0.4996682149966821 < 0.500331785003317\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1508\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1508\n",
            "Iteration 1509\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49966865473823724, action1_reward_count: 1509\n",
            "action2_reward: 1, action2_reward_avg: 0.5003313452617618, action2_reward_count: 1509\n",
            "Iteration 1510\n",
            "Chose Action 2: 0.49966865473823724 < 0.5003313452617618\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1510\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999906, action2_reward_count: 1510\n",
            "Iteration 1511\n",
            "Chose Action 1: 0.5 >= 0.49999999999999906\n",
            "action1_reward: 0, action1_reward_avg: 0.499669093315685, action1_reward_count: 1511\n",
            "action2_reward: 1, action2_reward_avg: 0.5003309066843141, action2_reward_count: 1511\n",
            "Iteration 1512\n",
            "Chose Action 2: 0.499669093315685 < 0.5003309066843141\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1512\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1512\n",
            "Iteration 1513\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.4996695307336418, action1_reward_count: 1513\n",
            "action2_reward: 1, action2_reward_avg: 0.5003304692663574, action2_reward_count: 1513\n",
            "Iteration 1514\n",
            "Chose Action 2: 0.4996695307336418 < 0.5003304692663574\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1514\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1514\n",
            "Iteration 1515\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996699669966997, action1_reward_count: 1515\n",
            "action2_reward: 1, action2_reward_avg: 0.5003300330032995, action2_reward_count: 1515\n",
            "Iteration 1516\n",
            "Chose Action 2: 0.4996699669966997 < 0.5003300330032995\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1516\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1516\n",
            "Iteration 1517\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996704021094265, action1_reward_count: 1517\n",
            "action2_reward: 1, action2_reward_avg: 0.5003295978905726, action2_reward_count: 1517\n",
            "Iteration 1518\n",
            "Chose Action 2: 0.4996704021094265 < 0.5003295978905726\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1518\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999991, action2_reward_count: 1518\n",
            "Iteration 1519\n",
            "Chose Action 1: 0.5 >= 0.4999999999999991\n",
            "action1_reward: 0, action1_reward_avg: 0.49967083607636603, action1_reward_count: 1519\n",
            "action2_reward: 1, action2_reward_avg: 0.5003291639236331, action2_reward_count: 1519\n",
            "Iteration 1520\n",
            "Chose Action 2: 0.49967083607636603 < 0.5003291639236331\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1520\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1520\n",
            "Iteration 1521\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996712689020381, action1_reward_count: 1521\n",
            "action2_reward: 1, action2_reward_avg: 0.500328731097961, action2_reward_count: 1521\n",
            "Iteration 1522\n",
            "Chose Action 2: 0.4996712689020381 < 0.500328731097961\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1522\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1522\n",
            "Iteration 1523\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.49967170059093896, action1_reward_count: 1523\n",
            "action2_reward: 1, action2_reward_avg: 0.5003282994090602, action2_reward_count: 1523\n",
            "Iteration 1524\n",
            "Chose Action 2: 0.49967170059093896 < 0.5003282994090602\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1524\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1524\n",
            "Iteration 1525\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.499672131147541, action1_reward_count: 1525\n",
            "action2_reward: 1, action2_reward_avg: 0.5003278688524582, action2_reward_count: 1525\n",
            "Iteration 1526\n",
            "Chose Action 2: 0.499672131147541 < 0.5003278688524582\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1526\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999917, action2_reward_count: 1526\n",
            "Iteration 1527\n",
            "Chose Action 1: 0.5 >= 0.49999999999999917\n",
            "action1_reward: 0, action1_reward_avg: 0.4996725605762934, action1_reward_count: 1527\n",
            "action2_reward: 1, action2_reward_avg: 0.5003274394237058, action2_reward_count: 1527\n",
            "Iteration 1528\n",
            "Chose Action 2: 0.4996725605762934 < 0.5003274394237058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1528\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1528\n",
            "Iteration 1529\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.499672988881622, action1_reward_count: 1529\n",
            "action2_reward: 1, action2_reward_avg: 0.5003270111183773, action2_reward_count: 1529\n",
            "Iteration 1530\n",
            "Chose Action 2: 0.499672988881622 < 0.5003270111183773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1530\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1530\n",
            "Iteration 1531\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996734160679295, action1_reward_count: 1531\n",
            "action2_reward: 1, action2_reward_avg: 0.5003265839320699, action2_reward_count: 1531\n",
            "Iteration 1532\n",
            "Chose Action 2: 0.4996734160679295 < 0.5003265839320699\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1532\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1532\n",
            "Iteration 1533\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967384213959554, action1_reward_count: 1533\n",
            "action2_reward: 1, action2_reward_avg: 0.5003261578604038, action2_reward_count: 1533\n",
            "Iteration 1534\n",
            "Chose Action 2: 0.49967384213959554 < 0.5003261578604038\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1534\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1534\n",
            "Iteration 1535\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996742671009772, action1_reward_count: 1535\n",
            "action2_reward: 1, action2_reward_avg: 0.5003257328990222, action2_reward_count: 1535\n",
            "Iteration 1536\n",
            "Chose Action 2: 0.4996742671009772 < 0.5003257328990222\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1536\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1536\n",
            "Iteration 1537\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996746909564086, action1_reward_count: 1537\n",
            "action2_reward: 1, action2_reward_avg: 0.5003253090435907, action2_reward_count: 1537\n",
            "Iteration 1538\n",
            "Chose Action 2: 0.4996746909564086 < 0.5003253090435907\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1538\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1538\n",
            "Iteration 1539\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967511371020146, action1_reward_count: 1539\n",
            "action2_reward: 1, action2_reward_avg: 0.5003248862897979, action2_reward_count: 1539\n",
            "Iteration 1540\n",
            "Chose Action 2: 0.49967511371020146 < 0.5003248862897979\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1540\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1540\n",
            "Iteration 1541\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967553536664505, action1_reward_count: 1541\n",
            "action2_reward: 1, action2_reward_avg: 0.5003244646333543, action2_reward_count: 1541\n",
            "Iteration 1542\n",
            "Chose Action 2: 0.49967553536664505 < 0.5003244646333543\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1542\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1542\n",
            "Iteration 1543\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49967595593000647, action1_reward_count: 1543\n",
            "action2_reward: 1, action2_reward_avg: 0.5003240440699929, action2_reward_count: 1543\n",
            "Iteration 1544\n",
            "Chose Action 2: 0.49967595593000647 < 0.5003240440699929\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1544\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1544\n",
            "Iteration 1545\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49967637540453075, action1_reward_count: 1545\n",
            "action2_reward: 1, action2_reward_avg: 0.5003236245954686, action2_reward_count: 1545\n",
            "Iteration 1546\n",
            "Chose Action 2: 0.49967637540453075 < 0.5003236245954686\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1546\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1546\n",
            "Iteration 1547\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49967679379444085, action1_reward_count: 1547\n",
            "action2_reward: 1, action2_reward_avg: 0.5003232062055586, action2_reward_count: 1547\n",
            "Iteration 1548\n",
            "Chose Action 2: 0.49967679379444085 < 0.5003232062055586\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1548\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1548\n",
            "Iteration 1549\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49967721110393803, action1_reward_count: 1549\n",
            "action2_reward: 1, action2_reward_avg: 0.5003227888960614, action2_reward_count: 1549\n",
            "Iteration 1550\n",
            "Chose Action 2: 0.49967721110393803 < 0.5003227888960614\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1550\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1550\n",
            "Iteration 1551\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996776273372018, action1_reward_count: 1551\n",
            "action2_reward: 1, action2_reward_avg: 0.5003223726627977, action2_reward_count: 1551\n",
            "Iteration 1552\n",
            "Chose Action 2: 0.4996776273372018 < 0.5003223726627977\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1552\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1552\n",
            "Iteration 1553\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996780424983902, action1_reward_count: 1553\n",
            "action2_reward: 1, action2_reward_avg: 0.5003219575016092, action2_reward_count: 1553\n",
            "Iteration 1554\n",
            "Chose Action 2: 0.4996780424983902 < 0.5003219575016092\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1554\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1554\n",
            "Iteration 1555\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996784565916399, action1_reward_count: 1555\n",
            "action2_reward: 1, action2_reward_avg: 0.5003215434083595, action2_reward_count: 1555\n",
            "Iteration 1556\n",
            "Chose Action 2: 0.4996784565916399 < 0.5003215434083595\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1556\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1556\n",
            "Iteration 1557\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49967886962106617, action1_reward_count: 1557\n",
            "action2_reward: 1, action2_reward_avg: 0.5003211303789333, action2_reward_count: 1557\n",
            "Iteration 1558\n",
            "Chose Action 2: 0.49967886962106617 < 0.5003211303789333\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1558\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1558\n",
            "Iteration 1559\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996792815907633, action1_reward_count: 1559\n",
            "action2_reward: 1, action2_reward_avg: 0.5003207184092362, action2_reward_count: 1559\n",
            "Iteration 1560\n",
            "Chose Action 2: 0.4996792815907633 < 0.5003207184092362\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1560\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1560\n",
            "Iteration 1561\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996796925048046, action1_reward_count: 1561\n",
            "action2_reward: 1, action2_reward_avg: 0.5003203074951948, action2_reward_count: 1561\n",
            "Iteration 1562\n",
            "Chose Action 2: 0.4996796925048046 < 0.5003203074951948\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1562\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1562\n",
            "Iteration 1563\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996801023672425, action1_reward_count: 1563\n",
            "action2_reward: 1, action2_reward_avg: 0.500319897632757, action2_reward_count: 1563\n",
            "Iteration 1564\n",
            "Chose Action 2: 0.4996801023672425 < 0.500319897632757\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1564\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1564\n",
            "Iteration 1565\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996805111821086, action1_reward_count: 1565\n",
            "action2_reward: 1, action2_reward_avg: 0.5003194888178908, action2_reward_count: 1565\n",
            "Iteration 1566\n",
            "Chose Action 2: 0.4996805111821086 < 0.5003194888178908\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1566\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1566\n",
            "Iteration 1567\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968091895341415, action1_reward_count: 1567\n",
            "action2_reward: 1, action2_reward_avg: 0.5003190810465852, action2_reward_count: 1567\n",
            "Iteration 1568\n",
            "Chose Action 2: 0.49968091895341415 < 0.5003190810465852\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1568\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1568\n",
            "Iteration 1569\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996813256851498, action1_reward_count: 1569\n",
            "action2_reward: 1, action2_reward_avg: 0.5003186743148496, action2_reward_count: 1569\n",
            "Iteration 1570\n",
            "Chose Action 2: 0.4996813256851498 < 0.5003186743148496\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1570\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1570\n",
            "Iteration 1571\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996817313812858, action1_reward_count: 1571\n",
            "action2_reward: 1, action2_reward_avg: 0.5003182686187135, action2_reward_count: 1571\n",
            "Iteration 1572\n",
            "Chose Action 2: 0.4996817313812858 < 0.5003182686187135\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1572\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1572\n",
            "Iteration 1573\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996821360457724, action1_reward_count: 1573\n",
            "action2_reward: 1, action2_reward_avg: 0.500317863954227, action2_reward_count: 1573\n",
            "Iteration 1574\n",
            "Chose Action 2: 0.4996821360457724 < 0.500317863954227\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1574\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1574\n",
            "Iteration 1575\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996825396825397, action1_reward_count: 1575\n",
            "action2_reward: 1, action2_reward_avg: 0.5003174603174596, action2_reward_count: 1575\n",
            "Iteration 1576\n",
            "Chose Action 2: 0.4996825396825397 < 0.5003174603174596\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1576\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1576\n",
            "Iteration 1577\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968294229549776, action1_reward_count: 1577\n",
            "action2_reward: 1, action2_reward_avg: 0.5003170577045015, action2_reward_count: 1577\n",
            "Iteration 1578\n",
            "Chose Action 2: 0.49968294229549776 < 0.5003170577045015\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1578\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1578\n",
            "Iteration 1579\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.499683343888537, action1_reward_count: 1579\n",
            "action2_reward: 1, action2_reward_avg: 0.5003166561114623, action2_reward_count: 1579\n",
            "Iteration 1580\n",
            "Chose Action 2: 0.499683343888537 < 0.5003166561114623\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1580\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1580\n",
            "Iteration 1581\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968374446552816, action1_reward_count: 1581\n",
            "action2_reward: 1, action2_reward_avg: 0.5003162555344711, action2_reward_count: 1581\n",
            "Iteration 1582\n",
            "Chose Action 2: 0.49968374446552816 < 0.5003162555344711\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1582\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1582\n",
            "Iteration 1583\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996841440303222, action1_reward_count: 1583\n",
            "action2_reward: 1, action2_reward_avg: 0.5003158559696771, action2_reward_count: 1583\n",
            "Iteration 1584\n",
            "Chose Action 2: 0.4996841440303222 < 0.5003158559696771\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1584\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1584\n",
            "Iteration 1585\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968454258675077, action1_reward_count: 1585\n",
            "action2_reward: 1, action2_reward_avg: 0.5003154574132485, action2_reward_count: 1585\n",
            "Iteration 1586\n",
            "Chose Action 2: 0.49968454258675077 < 0.5003154574132485\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1586\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999992, action2_reward_count: 1586\n",
            "Iteration 1587\n",
            "Chose Action 1: 0.5 >= 0.4999999999999992\n",
            "action1_reward: 0, action1_reward_avg: 0.49968494013862635, action1_reward_count: 1587\n",
            "action2_reward: 1, action2_reward_avg: 0.5003150598613729, action2_reward_count: 1587\n",
            "Iteration 1588\n",
            "Chose Action 2: 0.49968494013862635 < 0.5003150598613729\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1588\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1588\n",
            "Iteration 1589\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968533668974197, action1_reward_count: 1589\n",
            "action2_reward: 1, action2_reward_avg: 0.5003146633102573, action2_reward_count: 1589\n",
            "Iteration 1590\n",
            "Chose Action 2: 0.49968533668974197 < 0.5003146633102573\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1590\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1590\n",
            "Iteration 1591\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996857322438718, action1_reward_count: 1591\n",
            "action2_reward: 1, action2_reward_avg: 0.5003142677561275, action2_reward_count: 1591\n",
            "Iteration 1592\n",
            "Chose Action 2: 0.4996857322438718 < 0.5003142677561275\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1592\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1592\n",
            "Iteration 1593\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968612680477087, action1_reward_count: 1593\n",
            "action2_reward: 1, action2_reward_avg: 0.5003138731952285, action2_reward_count: 1593\n",
            "Iteration 1594\n",
            "Chose Action 2: 0.49968612680477087 < 0.5003138731952285\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1594\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1594\n",
            "Iteration 1595\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968652037617556, action1_reward_count: 1595\n",
            "action2_reward: 1, action2_reward_avg: 0.5003134796238238, action2_reward_count: 1595\n",
            "Iteration 1596\n",
            "Chose Action 2: 0.49968652037617556 < 0.5003134796238238\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1596\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1596\n",
            "Iteration 1597\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996869129618034, action1_reward_count: 1597\n",
            "action2_reward: 1, action2_reward_avg: 0.500313087038196, action2_reward_count: 1597\n",
            "Iteration 1598\n",
            "Chose Action 2: 0.4996869129618034 < 0.500313087038196\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1598\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1598\n",
            "Iteration 1599\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996873045653533, action1_reward_count: 1599\n",
            "action2_reward: 1, action2_reward_avg: 0.5003126954346461, action2_reward_count: 1599\n",
            "Iteration 1600\n",
            "Chose Action 2: 0.4996873045653533 < 0.5003126954346461\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1600\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1600\n",
            "Iteration 1601\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968769519050593, action1_reward_count: 1601\n",
            "action2_reward: 1, action2_reward_avg: 0.5003123048094934, action2_reward_count: 1601\n",
            "Iteration 1602\n",
            "Chose Action 2: 0.49968769519050593 < 0.5003123048094934\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1602\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1602\n",
            "Iteration 1603\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49968808484092325, action1_reward_count: 1603\n",
            "action2_reward: 1, action2_reward_avg: 0.500311915159076, action2_reward_count: 1603\n",
            "Iteration 1604\n",
            "Chose Action 2: 0.49968808484092325 < 0.500311915159076\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1604\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1604\n",
            "Iteration 1605\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4996884735202492, action1_reward_count: 1605\n",
            "action2_reward: 1, action2_reward_avg: 0.5003115264797501, action2_reward_count: 1605\n",
            "Iteration 1606\n",
            "Chose Action 2: 0.4996884735202492 < 0.5003115264797501\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1606\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1606\n",
            "Iteration 1607\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49968886123210954, action1_reward_count: 1607\n",
            "action2_reward: 1, action2_reward_avg: 0.5003111387678898, action2_reward_count: 1607\n",
            "Iteration 1608\n",
            "Chose Action 2: 0.49968886123210954 < 0.5003111387678898\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1608\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1608\n",
            "Iteration 1609\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4996892479801119, action1_reward_count: 1609\n",
            "action2_reward: 1, action2_reward_avg: 0.5003107520198875, action2_reward_count: 1609\n",
            "Iteration 1610\n",
            "Chose Action 2: 0.4996892479801119 < 0.5003107520198875\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1610\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1610\n",
            "Iteration 1611\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49968963376784603, action1_reward_count: 1611\n",
            "action2_reward: 1, action2_reward_avg: 0.5003103662321533, action2_reward_count: 1611\n",
            "Iteration 1612\n",
            "Chose Action 2: 0.49968963376784603 < 0.5003103662321533\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1612\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1612\n",
            "Iteration 1613\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49969001859888407, action1_reward_count: 1613\n",
            "action2_reward: 1, action2_reward_avg: 0.5003099814011154, action2_reward_count: 1613\n",
            "Iteration 1614\n",
            "Chose Action 2: 0.49969001859888407 < 0.5003099814011154\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1614\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1614\n",
            "Iteration 1615\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996904024767802, action1_reward_count: 1615\n",
            "action2_reward: 1, action2_reward_avg: 0.5003095975232192, action2_reward_count: 1615\n",
            "Iteration 1616\n",
            "Chose Action 2: 0.4996904024767802 < 0.5003095975232192\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1616\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1616\n",
            "Iteration 1617\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996907854050711, action1_reward_count: 1617\n",
            "action2_reward: 1, action2_reward_avg: 0.5003092145949283, action2_reward_count: 1617\n",
            "Iteration 1618\n",
            "Chose Action 2: 0.4996907854050711 < 0.5003092145949283\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1618\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1618\n",
            "Iteration 1619\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996911673872761, action1_reward_count: 1619\n",
            "action2_reward: 1, action2_reward_avg: 0.5003088326127233, action2_reward_count: 1619\n",
            "Iteration 1620\n",
            "Chose Action 2: 0.4996911673872761 < 0.5003088326127233\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1620\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1620\n",
            "Iteration 1621\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499691548426897, action1_reward_count: 1621\n",
            "action2_reward: 1, action2_reward_avg: 0.5003084515731024, action2_reward_count: 1621\n",
            "Iteration 1622\n",
            "Chose Action 2: 0.499691548426897 < 0.5003084515731024\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1622\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1622\n",
            "Iteration 1623\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969192852741834, action1_reward_count: 1623\n",
            "action2_reward: 1, action2_reward_avg: 0.500308071472581, action2_reward_count: 1623\n",
            "Iteration 1624\n",
            "Chose Action 2: 0.49969192852741834 < 0.500308071472581\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1624\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1624\n",
            "Iteration 1625\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996923076923077, action1_reward_count: 1625\n",
            "action2_reward: 1, action2_reward_avg: 0.5003076923076917, action2_reward_count: 1625\n",
            "Iteration 1626\n",
            "Chose Action 2: 0.4996923076923077 < 0.5003076923076917\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1626\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1626\n",
            "Iteration 1627\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49969268592501537, action1_reward_count: 1627\n",
            "action2_reward: 1, action2_reward_avg: 0.5003073140749841, action2_reward_count: 1627\n",
            "Iteration 1628\n",
            "Chose Action 2: 0.49969268592501537 < 0.5003073140749841\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1628\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1628\n",
            "Iteration 1629\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969306322897483, action1_reward_count: 1629\n",
            "action2_reward: 1, action2_reward_avg: 0.5003069367710247, action2_reward_count: 1629\n",
            "Iteration 1630\n",
            "Chose Action 2: 0.49969306322897483 < 0.5003069367710247\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1630\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1630\n",
            "Iteration 1631\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996934396076027, action1_reward_count: 1631\n",
            "action2_reward: 1, action2_reward_avg: 0.5003065603923968, action2_reward_count: 1631\n",
            "Iteration 1632\n",
            "Chose Action 2: 0.4996934396076027 < 0.5003065603923968\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1632\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1632\n",
            "Iteration 1633\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49969381506429883, action1_reward_count: 1633\n",
            "action2_reward: 1, action2_reward_avg: 0.5003061849357007, action2_reward_count: 1633\n",
            "Iteration 1634\n",
            "Chose Action 2: 0.49969381506429883 < 0.5003061849357007\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1634\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1634\n",
            "Iteration 1635\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996941896024465, action1_reward_count: 1635\n",
            "action2_reward: 1, action2_reward_avg: 0.5003058103975531, action2_reward_count: 1635\n",
            "Iteration 1636\n",
            "Chose Action 2: 0.4996941896024465 < 0.5003058103975531\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1636\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1636\n",
            "Iteration 1637\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49969456322541234, action1_reward_count: 1637\n",
            "action2_reward: 1, action2_reward_avg: 0.5003054367745872, action2_reward_count: 1637\n",
            "Iteration 1638\n",
            "Chose Action 2: 0.49969456322541234 < 0.5003054367745872\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1638\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1638\n",
            "Iteration 1639\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996949359365467, action1_reward_count: 1639\n",
            "action2_reward: 1, action2_reward_avg: 0.5003050640634529, action2_reward_count: 1639\n",
            "Iteration 1640\n",
            "Chose Action 2: 0.4996949359365467 < 0.5003050640634529\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1640\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1640\n",
            "Iteration 1641\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4996953077391834, action1_reward_count: 1641\n",
            "action2_reward: 1, action2_reward_avg: 0.5003046922608161, action2_reward_count: 1641\n",
            "Iteration 1642\n",
            "Chose Action 2: 0.4996953077391834 < 0.5003046922608161\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1642\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1642\n",
            "Iteration 1643\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4996956786366403, action1_reward_count: 1643\n",
            "action2_reward: 1, action2_reward_avg: 0.5003043213633592, action2_reward_count: 1643\n",
            "Iteration 1644\n",
            "Chose Action 2: 0.4996956786366403 < 0.5003043213633592\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1644\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1644\n",
            "Iteration 1645\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49969604863221884, action1_reward_count: 1645\n",
            "action2_reward: 1, action2_reward_avg: 0.5003039513677806, action2_reward_count: 1645\n",
            "Iteration 1646\n",
            "Chose Action 2: 0.49969604863221884 < 0.5003039513677806\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1646\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1646\n",
            "Iteration 1647\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996964177292046, action1_reward_count: 1647\n",
            "action2_reward: 1, action2_reward_avg: 0.5003035822707949, action2_reward_count: 1647\n",
            "Iteration 1648\n",
            "Chose Action 2: 0.4996964177292046 < 0.5003035822707949\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1648\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1648\n",
            "Iteration 1649\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996967859308672, action1_reward_count: 1649\n",
            "action2_reward: 1, action2_reward_avg: 0.5003032140691323, action2_reward_count: 1649\n",
            "Iteration 1650\n",
            "Chose Action 2: 0.4996967859308672 < 0.5003032140691323\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1650\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1650\n",
            "Iteration 1651\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996971532404603, action1_reward_count: 1651\n",
            "action2_reward: 1, action2_reward_avg: 0.5003028467595391, action2_reward_count: 1651\n",
            "Iteration 1652\n",
            "Chose Action 2: 0.4996971532404603 < 0.5003028467595391\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1652\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1652\n",
            "Iteration 1653\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.499697519661222, action1_reward_count: 1653\n",
            "action2_reward: 1, action2_reward_avg: 0.5003024803387773, action2_reward_count: 1653\n",
            "Iteration 1654\n",
            "Chose Action 2: 0.499697519661222 < 0.5003024803387773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1654\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1654\n",
            "Iteration 1655\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49969788519637465, action1_reward_count: 1655\n",
            "action2_reward: 1, action2_reward_avg: 0.5003021148036247, action2_reward_count: 1655\n",
            "Iteration 1656\n",
            "Chose Action 2: 0.49969788519637465 < 0.5003021148036247\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1656\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1656\n",
            "Iteration 1657\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996982498491249, action1_reward_count: 1657\n",
            "action2_reward: 1, action2_reward_avg: 0.5003017501508744, action2_reward_count: 1657\n",
            "Iteration 1658\n",
            "Chose Action 2: 0.4996982498491249 < 0.5003017501508744\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1658\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1658\n",
            "Iteration 1659\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49969861362266427, action1_reward_count: 1659\n",
            "action2_reward: 1, action2_reward_avg: 0.5003013863773351, action2_reward_count: 1659\n",
            "Iteration 1660\n",
            "Chose Action 2: 0.49969861362266427 < 0.5003013863773351\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1660\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1660\n",
            "Iteration 1661\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4996989765201686, action1_reward_count: 1661\n",
            "action2_reward: 1, action2_reward_avg: 0.5003010234798309, action2_reward_count: 1661\n",
            "Iteration 1662\n",
            "Chose Action 2: 0.4996989765201686 < 0.5003010234798309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1662\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1662\n",
            "Iteration 1663\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49969933854479853, action1_reward_count: 1663\n",
            "action2_reward: 1, action2_reward_avg: 0.5003006614552009, action2_reward_count: 1663\n",
            "Iteration 1664\n",
            "Chose Action 2: 0.49969933854479853 < 0.5003006614552009\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1664\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1664\n",
            "Iteration 1665\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4996996996996997, action1_reward_count: 1665\n",
            "action2_reward: 1, action2_reward_avg: 0.5003003003002997, action2_reward_count: 1665\n",
            "Iteration 1666\n",
            "Chose Action 2: 0.4996996996996997 < 0.5003003003002997\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1666\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1666\n",
            "Iteration 1667\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997000599880024, action1_reward_count: 1667\n",
            "action2_reward: 1, action2_reward_avg: 0.500299940011997, action2_reward_count: 1667\n",
            "Iteration 1668\n",
            "Chose Action 2: 0.4997000599880024 < 0.500299940011997\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1668\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1668\n",
            "Iteration 1669\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970041941282206, action1_reward_count: 1669\n",
            "action2_reward: 1, action2_reward_avg: 0.5002995805871773, action2_reward_count: 1669\n",
            "Iteration 1670\n",
            "Chose Action 2: 0.49970041941282206 < 0.5002995805871773\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1670\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1670\n",
            "Iteration 1671\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970077797725915, action1_reward_count: 1671\n",
            "action2_reward: 1, action2_reward_avg: 0.5002992220227402, action2_reward_count: 1671\n",
            "Iteration 1672\n",
            "Chose Action 2: 0.49970077797725915 < 0.5002992220227402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1672\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1672\n",
            "Iteration 1673\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997011356843993, action1_reward_count: 1673\n",
            "action2_reward: 1, action2_reward_avg: 0.5002988643156001, action2_reward_count: 1673\n",
            "Iteration 1674\n",
            "Chose Action 2: 0.4997011356843993 < 0.5002988643156001\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1674\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1674\n",
            "Iteration 1675\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49970149253731344, action1_reward_count: 1675\n",
            "action2_reward: 1, action2_reward_avg: 0.500298507462686, action2_reward_count: 1675\n",
            "Iteration 1676\n",
            "Chose Action 2: 0.49970149253731344 < 0.500298507462686\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1676\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1676\n",
            "Iteration 1677\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970184853905786, action1_reward_count: 1677\n",
            "action2_reward: 1, action2_reward_avg: 0.5002981514609416, action2_reward_count: 1677\n",
            "Iteration 1678\n",
            "Chose Action 2: 0.49970184853905786 < 0.5002981514609416\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1678\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1678\n",
            "Iteration 1679\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997022036926742, action1_reward_count: 1679\n",
            "action2_reward: 1, action2_reward_avg: 0.5002977963073252, action2_reward_count: 1679\n",
            "Iteration 1680\n",
            "Chose Action 2: 0.4997022036926742 < 0.5002977963073252\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1680\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1680\n",
            "Iteration 1681\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997025580011898, action1_reward_count: 1681\n",
            "action2_reward: 1, action2_reward_avg: 0.5002974419988097, action2_reward_count: 1681\n",
            "Iteration 1682\n",
            "Chose Action 2: 0.4997025580011898 < 0.5002974419988097\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1682\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1682\n",
            "Iteration 1683\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970291146761736, action1_reward_count: 1683\n",
            "action2_reward: 1, action2_reward_avg: 0.5002970885323821, action2_reward_count: 1683\n",
            "Iteration 1684\n",
            "Chose Action 2: 0.49970291146761736 < 0.5002970885323821\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1684\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1684\n",
            "Iteration 1685\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970326409495547, action1_reward_count: 1685\n",
            "action2_reward: 1, action2_reward_avg: 0.500296735905044, action2_reward_count: 1685\n",
            "Iteration 1686\n",
            "Chose Action 2: 0.49970326409495547 < 0.500296735905044\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1686\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1686\n",
            "Iteration 1687\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997036158861885, action1_reward_count: 1687\n",
            "action2_reward: 1, action2_reward_avg: 0.5002963841138109, action2_reward_count: 1687\n",
            "Iteration 1688\n",
            "Chose Action 2: 0.4997036158861885 < 0.5002963841138109\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1688\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1688\n",
            "Iteration 1689\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997039668442866, action1_reward_count: 1689\n",
            "action2_reward: 1, action2_reward_avg: 0.5002960331557129, action2_reward_count: 1689\n",
            "Iteration 1690\n",
            "Chose Action 2: 0.4997039668442866 < 0.5002960331557129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1690\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1690\n",
            "Iteration 1691\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997043169722058, action1_reward_count: 1691\n",
            "action2_reward: 1, action2_reward_avg: 0.5002956830277937, action2_reward_count: 1691\n",
            "Iteration 1692\n",
            "Chose Action 2: 0.4997043169722058 < 0.5002956830277937\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1692\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1692\n",
            "Iteration 1693\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49970466627288834, action1_reward_count: 1693\n",
            "action2_reward: 1, action2_reward_avg: 0.5002953337271111, action2_reward_count: 1693\n",
            "Iteration 1694\n",
            "Chose Action 2: 0.49970466627288834 < 0.5002953337271111\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1694\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1694\n",
            "Iteration 1695\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49970501474926254, action1_reward_count: 1695\n",
            "action2_reward: 1, action2_reward_avg: 0.5002949852507369, action2_reward_count: 1695\n",
            "Iteration 1696\n",
            "Chose Action 2: 0.49970501474926254 < 0.5002949852507369\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1696\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1696\n",
            "Iteration 1697\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997053624042428, action1_reward_count: 1697\n",
            "action2_reward: 1, action2_reward_avg: 0.5002946375957567, action2_reward_count: 1697\n",
            "Iteration 1698\n",
            "Chose Action 2: 0.4997053624042428 < 0.5002946375957567\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1698\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1698\n",
            "Iteration 1699\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997057092407298, action1_reward_count: 1699\n",
            "action2_reward: 1, action2_reward_avg: 0.5002942907592696, action2_reward_count: 1699\n",
            "Iteration 1700\n",
            "Chose Action 2: 0.4997057092407298 < 0.5002942907592696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1700\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1700\n",
            "Iteration 1701\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997060552616108, action1_reward_count: 1701\n",
            "action2_reward: 1, action2_reward_avg: 0.5002939447383886, action2_reward_count: 1701\n",
            "Iteration 1702\n",
            "Chose Action 2: 0.4997060552616108 < 0.5002939447383886\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1702\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1702\n",
            "Iteration 1703\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997064004697592, action1_reward_count: 1703\n",
            "action2_reward: 1, action2_reward_avg: 0.5002935995302402, action2_reward_count: 1703\n",
            "Iteration 1704\n",
            "Chose Action 2: 0.4997064004697592 < 0.5002935995302402\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1704\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1704\n",
            "Iteration 1705\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997067448680352, action1_reward_count: 1705\n",
            "action2_reward: 1, action2_reward_avg: 0.5002932551319642, action2_reward_count: 1705\n",
            "Iteration 1706\n",
            "Chose Action 2: 0.4997067448680352 < 0.5002932551319642\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1706\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1706\n",
            "Iteration 1707\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997070884592853, action1_reward_count: 1707\n",
            "action2_reward: 1, action2_reward_avg: 0.5002929115407141, action2_reward_count: 1707\n",
            "Iteration 1708\n",
            "Chose Action 2: 0.4997070884592853 < 0.5002929115407141\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1708\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1708\n",
            "Iteration 1709\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49970743124634287, action1_reward_count: 1709\n",
            "action2_reward: 1, action2_reward_avg: 0.5002925687536565, action2_reward_count: 1709\n",
            "Iteration 1710\n",
            "Chose Action 2: 0.49970743124634287 < 0.5002925687536565\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1710\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1710\n",
            "Iteration 1711\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970777323202803, action1_reward_count: 1711\n",
            "action2_reward: 1, action2_reward_avg: 0.5002922267679712, action2_reward_count: 1711\n",
            "Iteration 1712\n",
            "Chose Action 2: 0.49970777323202803 < 0.5002922267679712\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1712\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1712\n",
            "Iteration 1713\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4997081144191477, action1_reward_count: 1713\n",
            "action2_reward: 1, action2_reward_avg: 0.5002918855808516, action2_reward_count: 1713\n",
            "Iteration 1714\n",
            "Chose Action 2: 0.4997081144191477 < 0.5002918855808516\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1714\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1714\n",
            "Iteration 1715\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49970845481049564, action1_reward_count: 1715\n",
            "action2_reward: 1, action2_reward_avg: 0.5002915451895037, action2_reward_count: 1715\n",
            "Iteration 1716\n",
            "Chose Action 2: 0.49970845481049564 < 0.5002915451895037\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1716\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1716\n",
            "Iteration 1717\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49970879440885263, action1_reward_count: 1717\n",
            "action2_reward: 1, action2_reward_avg: 0.5002912055911467, action2_reward_count: 1717\n",
            "Iteration 1718\n",
            "Chose Action 2: 0.49970879440885263 < 0.5002912055911467\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1718\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1718\n",
            "Iteration 1719\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997091332169866, action1_reward_count: 1719\n",
            "action2_reward: 1, action2_reward_avg: 0.5002908667830127, action2_reward_count: 1719\n",
            "Iteration 1720\n",
            "Chose Action 2: 0.4997091332169866 < 0.5002908667830127\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1720\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1720\n",
            "Iteration 1721\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997094712376525, action1_reward_count: 1721\n",
            "action2_reward: 1, action2_reward_avg: 0.5002905287623468, action2_reward_count: 1721\n",
            "Iteration 1722\n",
            "Chose Action 2: 0.4997094712376525 < 0.5002905287623468\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1722\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1722\n",
            "Iteration 1723\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997098084735926, action1_reward_count: 1723\n",
            "action2_reward: 1, action2_reward_avg: 0.5002901915264067, action2_reward_count: 1723\n",
            "Iteration 1724\n",
            "Chose Action 2: 0.4997098084735926 < 0.5002901915264067\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1724\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1724\n",
            "Iteration 1725\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49971014492753624, action1_reward_count: 1725\n",
            "action2_reward: 1, action2_reward_avg: 0.5002898550724632, action2_reward_count: 1725\n",
            "Iteration 1726\n",
            "Chose Action 2: 0.49971014492753624 < 0.5002898550724632\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1726\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1726\n",
            "Iteration 1727\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971048060220036, action1_reward_count: 1727\n",
            "action2_reward: 1, action2_reward_avg: 0.5002895193977991, action2_reward_count: 1727\n",
            "Iteration 1728\n",
            "Chose Action 2: 0.49971048060220036 < 0.5002895193977991\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1728\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1728\n",
            "Iteration 1729\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997108155002892, action1_reward_count: 1729\n",
            "action2_reward: 1, action2_reward_avg: 0.5002891844997103, action2_reward_count: 1729\n",
            "Iteration 1730\n",
            "Chose Action 2: 0.4997108155002892 < 0.5002891844997103\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1730\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1730\n",
            "Iteration 1731\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49971114962449453, action1_reward_count: 1731\n",
            "action2_reward: 1, action2_reward_avg: 0.500288850375505, action2_reward_count: 1731\n",
            "Iteration 1732\n",
            "Chose Action 2: 0.49971114962449453 < 0.500288850375505\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1732\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1732\n",
            "Iteration 1733\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997114829774957, action1_reward_count: 1733\n",
            "action2_reward: 1, action2_reward_avg: 0.5002885170225039, action2_reward_count: 1733\n",
            "Iteration 1734\n",
            "Chose Action 2: 0.4997114829774957 < 0.5002885170225039\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1734\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1734\n",
            "Iteration 1735\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49971181556195965, action1_reward_count: 1735\n",
            "action2_reward: 1, action2_reward_avg: 0.5002881844380399, action2_reward_count: 1735\n",
            "Iteration 1736\n",
            "Chose Action 2: 0.49971181556195965 < 0.5002881844380399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1736\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1736\n",
            "Iteration 1737\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49971214738054115, action1_reward_count: 1737\n",
            "action2_reward: 1, action2_reward_avg: 0.5002878526194584, action2_reward_count: 1737\n",
            "Iteration 1738\n",
            "Chose Action 2: 0.49971214738054115 < 0.5002878526194584\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1738\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1738\n",
            "Iteration 1739\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997124784358827, action1_reward_count: 1739\n",
            "action2_reward: 1, action2_reward_avg: 0.5002875215641168, action2_reward_count: 1739\n",
            "Iteration 1740\n",
            "Chose Action 2: 0.4997124784358827 < 0.5002875215641168\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1740\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1740\n",
            "Iteration 1741\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997128087306146, action1_reward_count: 1741\n",
            "action2_reward: 1, action2_reward_avg: 0.5002871912693849, action2_reward_count: 1741\n",
            "Iteration 1742\n",
            "Chose Action 2: 0.4997128087306146 < 0.5002871912693849\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1742\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1742\n",
            "Iteration 1743\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49971313826735514, action1_reward_count: 1743\n",
            "action2_reward: 1, action2_reward_avg: 0.5002868617326444, action2_reward_count: 1743\n",
            "Iteration 1744\n",
            "Chose Action 2: 0.49971313826735514 < 0.5002868617326444\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1744\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1744\n",
            "Iteration 1745\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997134670487106, action1_reward_count: 1745\n",
            "action2_reward: 1, action2_reward_avg: 0.5002865329512889, action2_reward_count: 1745\n",
            "Iteration 1746\n",
            "Chose Action 2: 0.4997134670487106 < 0.5002865329512889\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1746\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1746\n",
            "Iteration 1747\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997137950772753, action1_reward_count: 1747\n",
            "action2_reward: 1, action2_reward_avg: 0.5002862049227241, action2_reward_count: 1747\n",
            "Iteration 1748\n",
            "Chose Action 2: 0.4997137950772753 < 0.5002862049227241\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1748\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1748\n",
            "Iteration 1749\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997141223556318, action1_reward_count: 1749\n",
            "action2_reward: 1, action2_reward_avg: 0.5002858776443676, action2_reward_count: 1749\n",
            "Iteration 1750\n",
            "Chose Action 2: 0.4997141223556318 < 0.5002858776443676\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1750\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1750\n",
            "Iteration 1751\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971444888635064, action1_reward_count: 1751\n",
            "action2_reward: 1, action2_reward_avg: 0.5002855511136487, action2_reward_count: 1751\n",
            "Iteration 1752\n",
            "Chose Action 2: 0.49971444888635064 < 0.5002855511136487\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1752\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1752\n",
            "Iteration 1753\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997147746719909, action1_reward_count: 1753\n",
            "action2_reward: 1, action2_reward_avg: 0.5002852253280085, action2_reward_count: 1753\n",
            "Iteration 1754\n",
            "Chose Action 2: 0.4997147746719909 < 0.5002852253280085\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1754\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1754\n",
            "Iteration 1755\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997150997150997, action1_reward_count: 1755\n",
            "action2_reward: 1, action2_reward_avg: 0.5002849002848996, action2_reward_count: 1755\n",
            "Iteration 1756\n",
            "Chose Action 2: 0.4997150997150997 < 0.5002849002848996\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1756\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1756\n",
            "Iteration 1757\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971542401821284, action1_reward_count: 1757\n",
            "action2_reward: 1, action2_reward_avg: 0.5002845759817864, action2_reward_count: 1757\n",
            "Iteration 1758\n",
            "Chose Action 2: 0.49971542401821284 < 0.5002845759817864\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1758\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1758\n",
            "Iteration 1759\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971574758385445, action1_reward_count: 1759\n",
            "action2_reward: 1, action2_reward_avg: 0.5002842524161448, action2_reward_count: 1759\n",
            "Iteration 1760\n",
            "Chose Action 2: 0.49971574758385445 < 0.5002842524161448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1760\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1760\n",
            "Iteration 1761\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.4997160704145372, action1_reward_count: 1761\n",
            "action2_reward: 1, action2_reward_avg: 0.5002839295854621, action2_reward_count: 1761\n",
            "Iteration 1762\n",
            "Chose Action 2: 0.4997160704145372 < 0.5002839295854621\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1762\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1762\n",
            "Iteration 1763\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49971639251276234, action1_reward_count: 1763\n",
            "action2_reward: 1, action2_reward_avg: 0.500283607487237, action2_reward_count: 1763\n",
            "Iteration 1764\n",
            "Chose Action 2: 0.49971639251276234 < 0.500283607487237\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1764\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1764\n",
            "Iteration 1765\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49971671388101985, action1_reward_count: 1765\n",
            "action2_reward: 1, action2_reward_avg: 0.5002832861189795, action2_reward_count: 1765\n",
            "Iteration 1766\n",
            "Chose Action 2: 0.49971671388101985 < 0.5002832861189795\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1766\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1766\n",
            "Iteration 1767\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971703452178834, action1_reward_count: 1767\n",
            "action2_reward: 1, action2_reward_avg: 0.500282965478211, action2_reward_count: 1767\n",
            "Iteration 1768\n",
            "Chose Action 2: 0.49971703452178834 < 0.500282965478211\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1768\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1768\n",
            "Iteration 1769\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971735443753534, action1_reward_count: 1769\n",
            "action2_reward: 1, action2_reward_avg: 0.500282645562464, action2_reward_count: 1769\n",
            "Iteration 1770\n",
            "Chose Action 2: 0.49971735443753534 < 0.500282645562464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1770\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1770\n",
            "Iteration 1771\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997176736307171, action1_reward_count: 1771\n",
            "action2_reward: 1, action2_reward_avg: 0.5002823263692823, action2_reward_count: 1771\n",
            "Iteration 1772\n",
            "Chose Action 2: 0.4997176736307171 < 0.5002823263692823\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1772\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1772\n",
            "Iteration 1773\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971799210377893, action1_reward_count: 1773\n",
            "action2_reward: 1, action2_reward_avg: 0.5002820078962205, action2_reward_count: 1773\n",
            "Iteration 1774\n",
            "Chose Action 2: 0.49971799210377893 < 0.5002820078962205\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1774\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1774\n",
            "Iteration 1775\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971830985915494, action1_reward_count: 1775\n",
            "action2_reward: 1, action2_reward_avg: 0.5002816901408444, action2_reward_count: 1775\n",
            "Iteration 1776\n",
            "Chose Action 2: 0.49971830985915494 < 0.5002816901408444\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1776\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1776\n",
            "Iteration 1777\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971862689926844, action1_reward_count: 1777\n",
            "action2_reward: 1, action2_reward_avg: 0.500281373100731, action2_reward_count: 1777\n",
            "Iteration 1778\n",
            "Chose Action 2: 0.49971862689926844 < 0.500281373100731\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1778\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1778\n",
            "Iteration 1779\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49971894322653176, action1_reward_count: 1779\n",
            "action2_reward: 1, action2_reward_avg: 0.5002810567734677, action2_reward_count: 1779\n",
            "Iteration 1780\n",
            "Chose Action 2: 0.49971894322653176 < 0.5002810567734677\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1780\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1780\n",
            "Iteration 1781\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49971925884334645, action1_reward_count: 1781\n",
            "action2_reward: 1, action2_reward_avg: 0.500280741156653, action2_reward_count: 1781\n",
            "Iteration 1782\n",
            "Chose Action 2: 0.49971925884334645 < 0.500280741156653\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1782\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1782\n",
            "Iteration 1783\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997195737521032, action1_reward_count: 1783\n",
            "action2_reward: 1, action2_reward_avg: 0.5002804262478963, action2_reward_count: 1783\n",
            "Iteration 1784\n",
            "Chose Action 2: 0.4997195737521032 < 0.5002804262478963\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1784\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1784\n",
            "Iteration 1785\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997198879551821, action1_reward_count: 1785\n",
            "action2_reward: 1, action2_reward_avg: 0.5002801120448174, action2_reward_count: 1785\n",
            "Iteration 1786\n",
            "Chose Action 2: 0.4997198879551821 < 0.5002801120448174\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1786\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1786\n",
            "Iteration 1787\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972020145495244, action1_reward_count: 1787\n",
            "action2_reward: 1, action2_reward_avg: 0.500279798545047, action2_reward_count: 1787\n",
            "Iteration 1788\n",
            "Chose Action 2: 0.49972020145495244 < 0.500279798545047\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1788\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1788\n",
            "Iteration 1789\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972051425377306, action1_reward_count: 1789\n",
            "action2_reward: 1, action2_reward_avg: 0.5002794857462264, action2_reward_count: 1789\n",
            "Iteration 1790\n",
            "Chose Action 2: 0.49972051425377306 < 0.5002794857462264\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1790\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1790\n",
            "Iteration 1791\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997208263539922, action1_reward_count: 1791\n",
            "action2_reward: 1, action2_reward_avg: 0.5002791736460073, action2_reward_count: 1791\n",
            "Iteration 1792\n",
            "Chose Action 2: 0.4997208263539922 < 0.5002791736460073\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1792\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1792\n",
            "Iteration 1793\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997211377579476, action1_reward_count: 1793\n",
            "action2_reward: 1, action2_reward_avg: 0.5002788622420519, action2_reward_count: 1793\n",
            "Iteration 1794\n",
            "Chose Action 2: 0.4997211377579476 < 0.5002788622420519\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1794\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1794\n",
            "Iteration 1795\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972144846796657, action1_reward_count: 1795\n",
            "action2_reward: 1, action2_reward_avg: 0.5002785515320328, action2_reward_count: 1795\n",
            "Iteration 1796\n",
            "Chose Action 2: 0.49972144846796657 < 0.5002785515320328\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1796\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1796\n",
            "Iteration 1797\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997217584863662, action1_reward_count: 1797\n",
            "action2_reward: 1, action2_reward_avg: 0.5002782415136332, action2_reward_count: 1797\n",
            "Iteration 1798\n",
            "Chose Action 2: 0.4997217584863662 < 0.5002782415136332\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1798\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1798\n",
            "Iteration 1799\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49972206781545303, action1_reward_count: 1799\n",
            "action2_reward: 1, action2_reward_avg: 0.5002779321845464, action2_reward_count: 1799\n",
            "Iteration 1800\n",
            "Chose Action 2: 0.49972206781545303 < 0.5002779321845464\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1800\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1800\n",
            "Iteration 1801\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997223764575236, action1_reward_count: 1801\n",
            "action2_reward: 1, action2_reward_avg: 0.5002776235424758, action2_reward_count: 1801\n",
            "Iteration 1802\n",
            "Chose Action 2: 0.4997223764575236 < 0.5002776235424758\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1802\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1802\n",
            "Iteration 1803\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997226844148641, action1_reward_count: 1803\n",
            "action2_reward: 1, action2_reward_avg: 0.5002773155851353, action2_reward_count: 1803\n",
            "Iteration 1804\n",
            "Chose Action 2: 0.4997226844148641 < 0.5002773155851353\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1804\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1804\n",
            "Iteration 1805\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997229916897507, action1_reward_count: 1805\n",
            "action2_reward: 1, action2_reward_avg: 0.5002770083102488, action2_reward_count: 1805\n",
            "Iteration 1806\n",
            "Chose Action 2: 0.4997229916897507 < 0.5002770083102488\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1806\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1806\n",
            "Iteration 1807\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997232982844494, action1_reward_count: 1807\n",
            "action2_reward: 1, action2_reward_avg: 0.5002767017155502, action2_reward_count: 1807\n",
            "Iteration 1808\n",
            "Chose Action 2: 0.4997232982844494 < 0.5002767017155502\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1808\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1808\n",
            "Iteration 1809\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49972360420121614, action1_reward_count: 1809\n",
            "action2_reward: 1, action2_reward_avg: 0.5002763957987835, action2_reward_count: 1809\n",
            "Iteration 1810\n",
            "Chose Action 2: 0.49972360420121614 < 0.5002763957987835\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1810\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1810\n",
            "Iteration 1811\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49972390944229705, action1_reward_count: 1811\n",
            "action2_reward: 1, action2_reward_avg: 0.5002760905577025, action2_reward_count: 1811\n",
            "Iteration 1812\n",
            "Chose Action 2: 0.49972390944229705 < 0.5002760905577025\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1812\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1812\n",
            "Iteration 1813\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997242140099283, action1_reward_count: 1813\n",
            "action2_reward: 1, action2_reward_avg: 0.5002757859900713, action2_reward_count: 1813\n",
            "Iteration 1814\n",
            "Chose Action 2: 0.4997242140099283 < 0.5002757859900713\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1814\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1814\n",
            "Iteration 1815\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997245179063361, action1_reward_count: 1815\n",
            "action2_reward: 1, action2_reward_avg: 0.5002754820936635, action2_reward_count: 1815\n",
            "Iteration 1816\n",
            "Chose Action 2: 0.4997245179063361 < 0.5002754820936635\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1816\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1816\n",
            "Iteration 1817\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49972482113373695, action1_reward_count: 1817\n",
            "action2_reward: 1, action2_reward_avg: 0.5002751788662626, action2_reward_count: 1817\n",
            "Iteration 1818\n",
            "Chose Action 2: 0.49972482113373695 < 0.5002751788662626\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1818\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1818\n",
            "Iteration 1819\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997251236943375, action1_reward_count: 1819\n",
            "action2_reward: 1, action2_reward_avg: 0.500274876305662, action2_reward_count: 1819\n",
            "Iteration 1820\n",
            "Chose Action 2: 0.4997251236943375 < 0.500274876305662\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1820\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1820\n",
            "Iteration 1821\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.499725425590335, action1_reward_count: 1821\n",
            "action2_reward: 1, action2_reward_avg: 0.5002745744096646, action2_reward_count: 1821\n",
            "Iteration 1822\n",
            "Chose Action 2: 0.499725425590335 < 0.5002745744096646\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1822\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1822\n",
            "Iteration 1823\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49972572682391664, action1_reward_count: 1823\n",
            "action2_reward: 1, action2_reward_avg: 0.500274273176083, action2_reward_count: 1823\n",
            "Iteration 1824\n",
            "Chose Action 2: 0.49972572682391664 < 0.500274273176083\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1824\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1824\n",
            "Iteration 1825\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997260273972603, action1_reward_count: 1825\n",
            "action2_reward: 1, action2_reward_avg: 0.5002739726027393, action2_reward_count: 1825\n",
            "Iteration 1826\n",
            "Chose Action 2: 0.4997260273972603 < 0.5002739726027393\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1826\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1826\n",
            "Iteration 1827\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997263273125342, action1_reward_count: 1827\n",
            "action2_reward: 1, action2_reward_avg: 0.5002736726874654, action2_reward_count: 1827\n",
            "Iteration 1828\n",
            "Chose Action 2: 0.4997263273125342 < 0.5002736726874654\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1828\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1828\n",
            "Iteration 1829\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997266265718972, action1_reward_count: 1829\n",
            "action2_reward: 1, action2_reward_avg: 0.5002733734281023, action2_reward_count: 1829\n",
            "Iteration 1830\n",
            "Chose Action 2: 0.4997266265718972 < 0.5002733734281023\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1830\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1830\n",
            "Iteration 1831\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997269251774986, action1_reward_count: 1831\n",
            "action2_reward: 1, action2_reward_avg: 0.5002730748225008, action2_reward_count: 1831\n",
            "Iteration 1832\n",
            "Chose Action 2: 0.4997269251774986 < 0.5002730748225008\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1832\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1832\n",
            "Iteration 1833\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972722313147844, action1_reward_count: 1833\n",
            "action2_reward: 1, action2_reward_avg: 0.500272776868521, action2_reward_count: 1833\n",
            "Iteration 1834\n",
            "Chose Action 2: 0.49972722313147844 < 0.500272776868521\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1834\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1834\n",
            "Iteration 1835\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997275204359673, action1_reward_count: 1835\n",
            "action2_reward: 1, action2_reward_avg: 0.5002724795640321, action2_reward_count: 1835\n",
            "Iteration 1836\n",
            "Chose Action 2: 0.4997275204359673 < 0.5002724795640321\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1836\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1836\n",
            "Iteration 1837\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49972781709308656, action1_reward_count: 1837\n",
            "action2_reward: 1, action2_reward_avg: 0.5002721829069129, action2_reward_count: 1837\n",
            "Iteration 1838\n",
            "Chose Action 2: 0.49972781709308656 < 0.5002721829069129\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1838\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1838\n",
            "Iteration 1839\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972811310494836, action1_reward_count: 1839\n",
            "action2_reward: 1, action2_reward_avg: 0.5002718868950511, action2_reward_count: 1839\n",
            "Iteration 1840\n",
            "Chose Action 2: 0.49972811310494836 < 0.5002718868950511\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1840\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1840\n",
            "Iteration 1841\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997284084736556, action1_reward_count: 1841\n",
            "action2_reward: 1, action2_reward_avg: 0.5002715915263438, action2_reward_count: 1841\n",
            "Iteration 1842\n",
            "Chose Action 2: 0.4997284084736556 < 0.5002715915263438\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1842\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1842\n",
            "Iteration 1843\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49972870320130225, action1_reward_count: 1843\n",
            "action2_reward: 1, action2_reward_avg: 0.5002712967986972, action2_reward_count: 1843\n",
            "Iteration 1844\n",
            "Chose Action 2: 0.49972870320130225 < 0.5002712967986972\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1844\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1844\n",
            "Iteration 1845\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997289972899729, action1_reward_count: 1845\n",
            "action2_reward: 1, action2_reward_avg: 0.5002710027100266, action2_reward_count: 1845\n",
            "Iteration 1846\n",
            "Chose Action 2: 0.4997289972899729 < 0.5002710027100266\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1846\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1846\n",
            "Iteration 1847\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997292907417434, action1_reward_count: 1847\n",
            "action2_reward: 1, action2_reward_avg: 0.5002707092582561, action2_reward_count: 1847\n",
            "Iteration 1848\n",
            "Chose Action 2: 0.4997292907417434 < 0.5002707092582561\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1848\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1848\n",
            "Iteration 1849\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49972958355868036, action1_reward_count: 1849\n",
            "action2_reward: 1, action2_reward_avg: 0.5002704164413191, action2_reward_count: 1849\n",
            "Iteration 1850\n",
            "Chose Action 2: 0.49972958355868036 < 0.5002704164413191\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1850\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1850\n",
            "Iteration 1851\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997298757428417, action1_reward_count: 1851\n",
            "action2_reward: 1, action2_reward_avg: 0.5002701242571578, action2_reward_count: 1851\n",
            "Iteration 1852\n",
            "Chose Action 2: 0.4997298757428417 < 0.5002701242571578\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1852\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1852\n",
            "Iteration 1853\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997301672962763, action1_reward_count: 1853\n",
            "action2_reward: 1, action2_reward_avg: 0.5002698327037232, action2_reward_count: 1853\n",
            "Iteration 1854\n",
            "Chose Action 2: 0.4997301672962763 < 0.5002698327037232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1854\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1854\n",
            "Iteration 1855\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973045822102424, action1_reward_count: 1855\n",
            "action2_reward: 1, action2_reward_avg: 0.5002695417789752, action2_reward_count: 1855\n",
            "Iteration 1856\n",
            "Chose Action 2: 0.49973045822102424 < 0.5002695417789752\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1856\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1856\n",
            "Iteration 1857\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973074851911686, action1_reward_count: 1857\n",
            "action2_reward: 1, action2_reward_avg: 0.5002692514808826, action2_reward_count: 1857\n",
            "Iteration 1858\n",
            "Chose Action 2: 0.49973074851911686 < 0.5002692514808826\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1858\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1858\n",
            "Iteration 1859\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973103819257664, action1_reward_count: 1859\n",
            "action2_reward: 1, action2_reward_avg: 0.5002689618074229, action2_reward_count: 1859\n",
            "Iteration 1860\n",
            "Chose Action 2: 0.49973103819257664 < 0.5002689618074229\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1860\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1860\n",
            "Iteration 1861\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997313272434175, action1_reward_count: 1861\n",
            "action2_reward: 1, action2_reward_avg: 0.5002686727565819, action2_reward_count: 1861\n",
            "Iteration 1862\n",
            "Chose Action 2: 0.4997313272434175 < 0.5002686727565819\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1862\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1862\n",
            "Iteration 1863\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973161567364466, action1_reward_count: 1863\n",
            "action2_reward: 1, action2_reward_avg: 0.5002683843263548, action2_reward_count: 1863\n",
            "Iteration 1864\n",
            "Chose Action 2: 0.49973161567364466 < 0.5002683843263548\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1864\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1864\n",
            "Iteration 1865\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997319034852547, action1_reward_count: 1865\n",
            "action2_reward: 1, action2_reward_avg: 0.5002680965147448, action2_reward_count: 1865\n",
            "Iteration 1866\n",
            "Chose Action 2: 0.4997319034852547 < 0.5002680965147448\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1866\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1866\n",
            "Iteration 1867\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973219068023567, action1_reward_count: 1867\n",
            "action2_reward: 1, action2_reward_avg: 0.5002678093197638, action2_reward_count: 1867\n",
            "Iteration 1868\n",
            "Chose Action 2: 0.49973219068023567 < 0.5002678093197638\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1868\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1868\n",
            "Iteration 1869\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973247726056713, action1_reward_count: 1869\n",
            "action2_reward: 1, action2_reward_avg: 0.5002675227394323, action2_reward_count: 1869\n",
            "Iteration 1870\n",
            "Chose Action 2: 0.49973247726056713 < 0.5002675227394323\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1870\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1870\n",
            "Iteration 1871\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997327632282202, action1_reward_count: 1871\n",
            "action2_reward: 1, action2_reward_avg: 0.5002672367717792, action2_reward_count: 1871\n",
            "Iteration 1872\n",
            "Chose Action 2: 0.4997327632282202 < 0.5002672367717792\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1872\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1872\n",
            "Iteration 1873\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997330485851575, action1_reward_count: 1873\n",
            "action2_reward: 1, action2_reward_avg: 0.5002669514148419, action2_reward_count: 1873\n",
            "Iteration 1874\n",
            "Chose Action 2: 0.4997330485851575 < 0.5002669514148419\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1874\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1874\n",
            "Iteration 1875\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997333333333333, action1_reward_count: 1875\n",
            "action2_reward: 1, action2_reward_avg: 0.5002666666666661, action2_reward_count: 1875\n",
            "Iteration 1876\n",
            "Chose Action 2: 0.4997333333333333 < 0.5002666666666661\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1876\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1876\n",
            "Iteration 1877\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973361747469364, action1_reward_count: 1877\n",
            "action2_reward: 1, action2_reward_avg: 0.5002663825253058, action2_reward_count: 1877\n",
            "Iteration 1878\n",
            "Chose Action 2: 0.49973361747469364 < 0.5002663825253058\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1878\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1878\n",
            "Iteration 1879\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973390101117615, action1_reward_count: 1879\n",
            "action2_reward: 1, action2_reward_avg: 0.5002660989888232, action2_reward_count: 1879\n",
            "Iteration 1880\n",
            "Chose Action 2: 0.49973390101117615 < 0.5002660989888232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1880\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1880\n",
            "Iteration 1881\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973418394471025, action1_reward_count: 1881\n",
            "action2_reward: 1, action2_reward_avg: 0.5002658160552891, action2_reward_count: 1881\n",
            "Iteration 1882\n",
            "Chose Action 2: 0.49973418394471025 < 0.5002658160552891\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1882\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1882\n",
            "Iteration 1883\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997344662772172, action1_reward_count: 1883\n",
            "action2_reward: 1, action2_reward_avg: 0.5002655337227822, action2_reward_count: 1883\n",
            "Iteration 1884\n",
            "Chose Action 2: 0.4997344662772172 < 0.5002655337227822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1884\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1884\n",
            "Iteration 1885\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997347480106101, action1_reward_count: 1885\n",
            "action2_reward: 1, action2_reward_avg: 0.5002652519893892, action2_reward_count: 1885\n",
            "Iteration 1886\n",
            "Chose Action 2: 0.4997347480106101 < 0.5002652519893892\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1886\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1886\n",
            "Iteration 1887\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49973502914679385, action1_reward_count: 1887\n",
            "action2_reward: 1, action2_reward_avg: 0.5002649708532054, action2_reward_count: 1887\n",
            "Iteration 1888\n",
            "Chose Action 2: 0.49973502914679385 < 0.5002649708532054\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1888\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999993, action2_reward_count: 1888\n",
            "Iteration 1889\n",
            "Chose Action 1: 0.5 >= 0.4999999999999993\n",
            "action1_reward: 0, action1_reward_avg: 0.49973530968766544, action1_reward_count: 1889\n",
            "action2_reward: 1, action2_reward_avg: 0.5002646903123339, action2_reward_count: 1889\n",
            "Iteration 1890\n",
            "Chose Action 2: 0.49973530968766544 < 0.5002646903123339\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1890\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1890\n",
            "Iteration 1891\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.4997355896351137, action1_reward_count: 1891\n",
            "action2_reward: 1, action2_reward_avg: 0.5002644103648857, action2_reward_count: 1891\n",
            "Iteration 1892\n",
            "Chose Action 2: 0.4997355896351137 < 0.5002644103648857\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1892\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1892\n",
            "Iteration 1893\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973586899101957, action1_reward_count: 1893\n",
            "action2_reward: 1, action2_reward_avg: 0.5002641310089798, action2_reward_count: 1893\n",
            "Iteration 1894\n",
            "Chose Action 2: 0.49973586899101957 < 0.5002641310089798\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1894\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1894\n",
            "Iteration 1895\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973614775725594, action1_reward_count: 1895\n",
            "action2_reward: 1, action2_reward_avg: 0.5002638522427435, action2_reward_count: 1895\n",
            "Iteration 1896\n",
            "Chose Action 2: 0.49973614775725594 < 0.5002638522427435\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1896\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1896\n",
            "Iteration 1897\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973642593568796, action1_reward_count: 1897\n",
            "action2_reward: 1, action2_reward_avg: 0.5002635740643115, action2_reward_count: 1897\n",
            "Iteration 1898\n",
            "Chose Action 2: 0.49973642593568796 < 0.5002635740643115\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1898\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1898\n",
            "Iteration 1899\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973670352817273, action1_reward_count: 1899\n",
            "action2_reward: 1, action2_reward_avg: 0.5002632964718268, action2_reward_count: 1899\n",
            "Iteration 1900\n",
            "Chose Action 2: 0.49973670352817273 < 0.5002632964718268\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1900\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1900\n",
            "Iteration 1901\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997369805365597, action1_reward_count: 1901\n",
            "action2_reward: 1, action2_reward_avg: 0.5002630194634398, action2_reward_count: 1901\n",
            "Iteration 1902\n",
            "Chose Action 2: 0.4997369805365597 < 0.5002630194634398\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1902\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1902\n",
            "Iteration 1903\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997372569626905, action1_reward_count: 1903\n",
            "action2_reward: 1, action2_reward_avg: 0.500262743037309, action2_reward_count: 1903\n",
            "Iteration 1904\n",
            "Chose Action 2: 0.4997372569626905 < 0.500262743037309\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1904\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1904\n",
            "Iteration 1905\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49973753280839894, action1_reward_count: 1905\n",
            "action2_reward: 1, action2_reward_avg: 0.5002624671916005, action2_reward_count: 1905\n",
            "Iteration 1906\n",
            "Chose Action 2: 0.49973753280839894 < 0.5002624671916005\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1906\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1906\n",
            "Iteration 1907\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973780807551127, action1_reward_count: 1907\n",
            "action2_reward: 1, action2_reward_avg: 0.5002621919244882, action2_reward_count: 1907\n",
            "Iteration 1908\n",
            "Chose Action 2: 0.49973780807551127 < 0.5002621919244882\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1908\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1908\n",
            "Iteration 1909\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973808276584597, action1_reward_count: 1909\n",
            "action2_reward: 1, action2_reward_avg: 0.5002619172341535, action2_reward_count: 1909\n",
            "Iteration 1910\n",
            "Chose Action 2: 0.49973808276584597 < 0.5002619172341535\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1910\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1910\n",
            "Iteration 1911\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973835688121404, action1_reward_count: 1911\n",
            "action2_reward: 1, action2_reward_avg: 0.5002616431187854, action2_reward_count: 1911\n",
            "Iteration 1912\n",
            "Chose Action 2: 0.49973835688121404 < 0.5002616431187854\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1912\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1912\n",
            "Iteration 1913\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997386304234187, action1_reward_count: 1913\n",
            "action2_reward: 1, action2_reward_avg: 0.5002613695765807, action2_reward_count: 1913\n",
            "Iteration 1914\n",
            "Chose Action 2: 0.4997386304234187 < 0.5002613695765807\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1914\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1914\n",
            "Iteration 1915\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49973890339425586, action1_reward_count: 1915\n",
            "action2_reward: 1, action2_reward_avg: 0.5002610966057436, action2_reward_count: 1915\n",
            "Iteration 1916\n",
            "Chose Action 2: 0.49973890339425586 < 0.5002610966057436\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1916\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1916\n",
            "Iteration 1917\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997391757955138, action1_reward_count: 1917\n",
            "action2_reward: 1, action2_reward_avg: 0.5002608242044856, action2_reward_count: 1917\n",
            "Iteration 1918\n",
            "Chose Action 2: 0.4997391757955138 < 0.5002608242044856\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1918\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1918\n",
            "Iteration 1919\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.49973944762897343, action1_reward_count: 1919\n",
            "action2_reward: 1, action2_reward_avg: 0.500260552371026, action2_reward_count: 1919\n",
            "Iteration 1920\n",
            "Chose Action 2: 0.49973944762897343 < 0.500260552371026\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1920\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1920\n",
            "Iteration 1921\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997397188964081, action1_reward_count: 1921\n",
            "action2_reward: 1, action2_reward_avg: 0.5002602811035912, action2_reward_count: 1921\n",
            "Iteration 1922\n",
            "Chose Action 2: 0.4997397188964081 < 0.5002602811035912\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1922\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1922\n",
            "Iteration 1923\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.499739989599584, action1_reward_count: 1923\n",
            "action2_reward: 1, action2_reward_avg: 0.5002600104004153, action2_reward_count: 1923\n",
            "Iteration 1924\n",
            "Chose Action 2: 0.499739989599584 < 0.5002600104004153\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1924\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999933, action2_reward_count: 1924\n",
            "Iteration 1925\n",
            "Chose Action 1: 0.5 >= 0.49999999999999933\n",
            "action1_reward: 0, action1_reward_avg: 0.49974025974025976, action1_reward_count: 1925\n",
            "action2_reward: 1, action2_reward_avg: 0.5002597402597396, action2_reward_count: 1925\n",
            "Iteration 1926\n",
            "Chose Action 2: 0.49974025974025976 < 0.5002597402597396\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1926\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1926\n",
            "Iteration 1927\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997405293201868, action1_reward_count: 1927\n",
            "action2_reward: 1, action2_reward_avg: 0.5002594706798126, action2_reward_count: 1927\n",
            "Iteration 1928\n",
            "Chose Action 2: 0.4997405293201868 < 0.5002594706798126\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1928\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999994, action2_reward_count: 1928\n",
            "Iteration 1929\n",
            "Chose Action 1: 0.5 >= 0.4999999999999994\n",
            "action1_reward: 0, action1_reward_avg: 0.4997407983411094, action1_reward_count: 1929\n",
            "action2_reward: 1, action2_reward_avg: 0.50025920165889, action2_reward_count: 1929\n",
            "Iteration 1930\n",
            "Chose Action 2: 0.4997407983411094 < 0.50025920165889\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1930\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1930\n",
            "Iteration 1931\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997410668047644, action1_reward_count: 1931\n",
            "action2_reward: 1, action2_reward_avg: 0.5002589331952351, action2_reward_count: 1931\n",
            "Iteration 1932\n",
            "Chose Action 2: 0.4997410668047644 < 0.5002589331952351\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1932\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1932\n",
            "Iteration 1933\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997413347128815, action1_reward_count: 1933\n",
            "action2_reward: 1, action2_reward_avg: 0.5002586652871179, action2_reward_count: 1933\n",
            "Iteration 1934\n",
            "Chose Action 2: 0.4997413347128815 < 0.5002586652871179\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1934\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1934\n",
            "Iteration 1935\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997416020671835, action1_reward_count: 1935\n",
            "action2_reward: 1, action2_reward_avg: 0.500258397932816, action2_reward_count: 1935\n",
            "Iteration 1936\n",
            "Chose Action 2: 0.4997416020671835 < 0.500258397932816\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1936\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1936\n",
            "Iteration 1937\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974186886938565, action1_reward_count: 1937\n",
            "action2_reward: 1, action2_reward_avg: 0.5002581311306139, action2_reward_count: 1937\n",
            "Iteration 1938\n",
            "Chose Action 2: 0.49974186886938565 < 0.5002581311306139\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1938\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1938\n",
            "Iteration 1939\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997421351211965, action1_reward_count: 1939\n",
            "action2_reward: 1, action2_reward_avg: 0.5002578648788031, action2_reward_count: 1939\n",
            "Iteration 1940\n",
            "Chose Action 2: 0.4997421351211965 < 0.5002578648788031\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1940\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1940\n",
            "Iteration 1941\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974240082431737, action1_reward_count: 1941\n",
            "action2_reward: 1, action2_reward_avg: 0.5002575991756822, action2_reward_count: 1941\n",
            "Iteration 1942\n",
            "Chose Action 2: 0.49974240082431737 < 0.5002575991756822\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1942\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1942\n",
            "Iteration 1943\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997426659804426, action1_reward_count: 1943\n",
            "action2_reward: 1, action2_reward_avg: 0.500257334019557, action2_reward_count: 1943\n",
            "Iteration 1944\n",
            "Chose Action 2: 0.4997426659804426 < 0.500257334019557\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1944\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1944\n",
            "Iteration 1945\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997429305912596, action1_reward_count: 1945\n",
            "action2_reward: 1, action2_reward_avg: 0.5002570694087399, action2_reward_count: 1945\n",
            "Iteration 1946\n",
            "Chose Action 2: 0.4997429305912596 < 0.5002570694087399\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1946\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1946\n",
            "Iteration 1947\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997431946584489, action1_reward_count: 1947\n",
            "action2_reward: 1, action2_reward_avg: 0.5002568053415507, action2_reward_count: 1947\n",
            "Iteration 1948\n",
            "Chose Action 2: 0.4997431946584489 < 0.5002568053415507\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1948\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1948\n",
            "Iteration 1949\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974345818368393, action1_reward_count: 1949\n",
            "action2_reward: 1, action2_reward_avg: 0.5002565418163156, action2_reward_count: 1949\n",
            "Iteration 1950\n",
            "Chose Action 2: 0.49974345818368393 < 0.5002565418163156\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1950\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1950\n",
            "Iteration 1951\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974372116863147, action1_reward_count: 1951\n",
            "action2_reward: 1, action2_reward_avg: 0.5002562788313681, action2_reward_count: 1951\n",
            "Iteration 1952\n",
            "Chose Action 2: 0.49974372116863147 < 0.5002562788313681\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1952\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1952\n",
            "Iteration 1953\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974398361495137, action1_reward_count: 1953\n",
            "action2_reward: 1, action2_reward_avg: 0.5002560163850482, action2_reward_count: 1953\n",
            "Iteration 1954\n",
            "Chose Action 2: 0.49974398361495137 < 0.5002560163850482\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1954\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1954\n",
            "Iteration 1955\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.4997442455242967, action1_reward_count: 1955\n",
            "action2_reward: 1, action2_reward_avg: 0.5002557544757029, action2_reward_count: 1955\n",
            "Iteration 1956\n",
            "Chose Action 2: 0.4997442455242967 < 0.5002557544757029\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1956\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1956\n",
            "Iteration 1957\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.49974450689831373, action1_reward_count: 1957\n",
            "action2_reward: 1, action2_reward_avg: 0.5002554931016858, action2_reward_count: 1957\n",
            "Iteration 1958\n",
            "Chose Action 2: 0.49974450689831373 < 0.5002554931016858\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1958\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1958\n",
            "Iteration 1959\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997447677386422, action1_reward_count: 1959\n",
            "action2_reward: 1, action2_reward_avg: 0.5002552322613574, action2_reward_count: 1959\n",
            "Iteration 1960\n",
            "Chose Action 2: 0.4997447677386422 < 0.5002552322613574\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1960\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1960\n",
            "Iteration 1961\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974502804691484, action1_reward_count: 1961\n",
            "action2_reward: 1, action2_reward_avg: 0.5002549719530848, action2_reward_count: 1961\n",
            "Iteration 1962\n",
            "Chose Action 2: 0.49974502804691484 < 0.5002549719530848\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1962\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999996, action2_reward_count: 1962\n",
            "Iteration 1963\n",
            "Chose Action 1: 0.5 >= 0.4999999999999996\n",
            "action1_reward: 0, action1_reward_avg: 0.499745287824758, action1_reward_count: 1963\n",
            "action2_reward: 1, action2_reward_avg: 0.5002547121752415, action2_reward_count: 1963\n",
            "Iteration 1964\n",
            "Chose Action 2: 0.499745287824758 < 0.5002547121752415\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1964\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1964\n",
            "Iteration 1965\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997455470737914, action1_reward_count: 1965\n",
            "action2_reward: 1, action2_reward_avg: 0.5002544529262082, action2_reward_count: 1965\n",
            "Iteration 1966\n",
            "Chose Action 2: 0.4997455470737914 < 0.5002544529262082\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1966\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1966\n",
            "Iteration 1967\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997458057956279, action1_reward_count: 1967\n",
            "action2_reward: 1, action2_reward_avg: 0.5002541942043717, action2_reward_count: 1967\n",
            "Iteration 1968\n",
            "Chose Action 2: 0.4997458057956279 < 0.5002541942043717\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1968\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1968\n",
            "Iteration 1969\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974606399187405, action1_reward_count: 1969\n",
            "action2_reward: 1, action2_reward_avg: 0.5002539360081255, action2_reward_count: 1969\n",
            "Iteration 1970\n",
            "Chose Action 2: 0.49974606399187405 < 0.5002539360081255\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1970\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1970\n",
            "Iteration 1971\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997463216641299, action1_reward_count: 1971\n",
            "action2_reward: 1, action2_reward_avg: 0.5002536783358696, action2_reward_count: 1971\n",
            "Iteration 1972\n",
            "Chose Action 2: 0.4997463216641299 < 0.5002536783358696\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1972\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1972\n",
            "Iteration 1973\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.4997465788139889, action1_reward_count: 1973\n",
            "action2_reward: 1, action2_reward_avg: 0.5002534211860107, action2_reward_count: 1973\n",
            "Iteration 1974\n",
            "Chose Action 2: 0.4997465788139889 < 0.5002534211860107\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1974\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1974\n",
            "Iteration 1975\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.499746835443038, action1_reward_count: 1975\n",
            "action2_reward: 1, action2_reward_avg: 0.5002531645569616, action2_reward_count: 1975\n",
            "Iteration 1976\n",
            "Chose Action 2: 0.499746835443038 < 0.5002531645569616\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1976\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999956, action2_reward_count: 1976\n",
            "Iteration 1977\n",
            "Chose Action 1: 0.5 >= 0.49999999999999956\n",
            "action1_reward: 0, action1_reward_avg: 0.49974709155285785, action1_reward_count: 1977\n",
            "action2_reward: 1, action2_reward_avg: 0.5002529084471417, action2_reward_count: 1977\n",
            "Iteration 1978\n",
            "Chose Action 2: 0.49974709155285785 < 0.5002529084471417\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1978\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1978\n",
            "Iteration 1979\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.4997473471450227, action1_reward_count: 1979\n",
            "action2_reward: 1, action2_reward_avg: 0.5002526528549768, action2_reward_count: 1979\n",
            "Iteration 1980\n",
            "Chose Action 2: 0.4997473471450227 < 0.5002526528549768\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1980\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1980\n",
            "Iteration 1981\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974760222110043, action1_reward_count: 1981\n",
            "action2_reward: 1, action2_reward_avg: 0.5002523977788991, action2_reward_count: 1981\n",
            "Iteration 1982\n",
            "Chose Action 2: 0.49974760222110043 < 0.5002523977788991\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1982\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1982\n",
            "Iteration 1983\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974785678265254, action1_reward_count: 1983\n",
            "action2_reward: 1, action2_reward_avg: 0.5002521432173469, action2_reward_count: 1983\n",
            "Iteration 1984\n",
            "Chose Action 2: 0.49974785678265254 < 0.5002521432173469\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1984\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1984\n",
            "Iteration 1985\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974811083123427, action1_reward_count: 1985\n",
            "action2_reward: 1, action2_reward_avg: 0.5002518891687652, action2_reward_count: 1985\n",
            "Iteration 1986\n",
            "Chose Action 2: 0.49974811083123427 < 0.5002518891687652\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1986\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1986\n",
            "Iteration 1987\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974836436839454, action1_reward_count: 1987\n",
            "action2_reward: 1, action2_reward_avg: 0.5002516356316049, action2_reward_count: 1987\n",
            "Iteration 1988\n",
            "Chose Action 2: 0.49974836436839454 < 0.5002516356316049\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1988\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1988\n",
            "Iteration 1989\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997486173956762, action1_reward_count: 1989\n",
            "action2_reward: 1, action2_reward_avg: 0.5002513826043232, action2_reward_count: 1989\n",
            "Iteration 1990\n",
            "Chose Action 2: 0.4997486173956762 < 0.5002513826043232\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1990\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1990\n",
            "Iteration 1991\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974886991461576, action1_reward_count: 1991\n",
            "action2_reward: 1, action2_reward_avg: 0.5002511300853837, action2_reward_count: 1991\n",
            "Iteration 1992\n",
            "Chose Action 2: 0.49974886991461576 < 0.5002511300853837\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1992\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1992\n",
            "Iteration 1993\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.4997491219267436, action1_reward_count: 1993\n",
            "action2_reward: 1, action2_reward_avg: 0.5002508780732559, action2_reward_count: 1993\n",
            "Iteration 1994\n",
            "Chose Action 2: 0.4997491219267436 < 0.5002508780732559\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1994\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1994\n",
            "Iteration 1995\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.49974937343358394, action1_reward_count: 1995\n",
            "action2_reward: 1, action2_reward_avg: 0.5002506265664155, action2_reward_count: 1995\n",
            "Iteration 1996\n",
            "Chose Action 2: 0.49974937343358394 < 0.5002506265664155\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1996\n",
            "action2_reward: 0, action2_reward_avg: 0.49999999999999944, action2_reward_count: 1996\n",
            "Iteration 1997\n",
            "Chose Action 1: 0.5 >= 0.49999999999999944\n",
            "action1_reward: 0, action1_reward_avg: 0.499749624436655, action1_reward_count: 1997\n",
            "action2_reward: 1, action2_reward_avg: 0.5002503755633445, action2_reward_count: 1997\n",
            "Iteration 1998\n",
            "Chose Action 2: 0.499749624436655 < 0.5002503755633445\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 1998\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 1998\n",
            "Iteration 1999\n",
            "Chose Action 1: 0.5 >= 0.4999999999999995\n",
            "action1_reward: 0, action1_reward_avg: 0.49974987493746875, action1_reward_count: 1999\n",
            "action2_reward: 1, action2_reward_avg: 0.5002501250625307, action2_reward_count: 1999\n",
            "Iteration 2000\n",
            "Chose Action 2: 0.49974987493746875 < 0.5002501250625307\n",
            "action1_reward: 1, action1_reward_avg: 0.5, action1_reward_count: 2000\n",
            "action2_reward: 0, action2_reward_avg: 0.4999999999999995, action2_reward_count: 2000\n"
          ]
        }
      ]
    }
  ]
}